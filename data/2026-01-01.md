<div id=toc></div>

# Table of Contents

- [cs.ET](#cs.ET) [Total: 4]
- [cs.HC](#cs.HC) [Total: 6]
- [cs.GR](#cs.GR) [Total: 4]


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [1] [An Electronic Ising Machine](https://arxiv.org/abs/2512.23720)
*Matt Bowring,Ben Anderdson,Ben Tiffany*

Main category: cs.ET

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We develop a custom printed circuit board (PCB) as a low-power and high-speed accelerator for NP-Hard graph problems. Based on the annealing principle, it uses an analog computing architecture of coupled nonlinear electronic oscillators. Using an energy-based representation of the input problem, the system is shown to naturally follow the gradient towards stable phase alignments that encode solutions. We introduce the motivational theory, give an overview of our detailed circuit design, simulations, and experiments, and provide insight on the emerging development of novel physics-based computing devices.

</details>


### [2] [Biochemical Computing Mode for Sequential Logic](https://arxiv.org/abs/2512.23734)
*Han Huang,Chengzhi Ma,Yuxin Zhao,Qingyao Wang,Xinglong Xiao,Xiulin Shu,Zhifeng Hao*

Main category: cs.ET

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent years have witnessed the growing scholarly interest in the next-generation general-purpose computers. Various innovative computing modes have been proposed, such as optical, quantum phenomena, and DNA-based modes. Sequential logic circuits are a critical factor that enables these modes to function as general-purpose computers, given their essential role in facilitating continuous computation and memory storage through their ability to store states. However, compared to computability, it is often overlooked due to the difficulty of its implementation. In this paper, we first demonstrate sequential mapping, a crucial necessary condition for electronic computers to realize sequential logic circuits, and highlight this distinctive property of general-purpose computers in the context of logic gate circuits. To achieve computational functionalities comparable to those of electronic computers, we utilize the control effect of enzymes on enzymatic reactions to design a logic gate model that is composed of small molecules and driven by enzymes, subsequently propose a biochemical computing mode. Furthermore, we mathematically analyze the static and dynamic input-output properties of biochemical logic gate components and prove that the biochemical computing mode satisfies sequential mapping similar to electronic computers. When combined with the storage characteristics of NOT-AND gates, it can realize sequential logic circuits. The findings can serve as a theoretical foundation for developing general-purpose biochemical computers.

</details>


### [3] [Ovonic switches enable energy-efficient dendrite-like computing](https://arxiv.org/abs/2512.23736)
*Unhyeon Kang,Jaesang Lee,Seungmin Oh,Hanchan Song,Jongkil Park,Jaewook Kim,Seongsik Park,Hyun Jae Jang,Sangbum Kim,Su-in Yi,Suhas Kumar,Suyoun Lee*

Main category: cs.ET

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Over the last decade, dendrites within individual biological neurons, which were previously thought to generally perform information pooling and networking, have now been shown to express complex temporal dynamics, Boolean-like logic, arithmetic, signal discrimination, and edge detection for image and sound recognition. Mimicking this rich functional density could offer a powerful primitive for neuromorphic computing, which has sought to replace the aging digital computing paradigms using biological inspirations. Here, using electrically driven Ovonic threshold switching in Sb-Te-doped GeSe, we demonstrate a single two-terminal component capable of self-sustained dynamics and universal Boolean logic, in addition to XOR operations (which is traditionally thought to require a network of active components). We then employ logic-driven dynamics in a single component to detect and estimate the gradients of edges in images, a task that otherwise requires elaborate circuits. A network of Ovonic switches exhibits properties of a half adder and a full adder, in addition to discriminative logic accommodating inhibitory and excitatory signals. We show that this computational primitive is not only seemingly simpler, but also offers many orders of magnitude improved energy efficiency compared to prevailing digital solutions. As such, this work paves the path for potentially emulating dendrites for efficient post-digital neuromorphic computing.

</details>


### [4] [Exploring the Potential of Spiking Neural Networks in UWB Channel Estimation](https://arxiv.org/abs/2512.23975)
*Youdong Zhang,Xu He,Xiaolin Meng*

Main category: cs.ET

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Although existing deep learning-based Ultra-Wide Band (UWB) channel estimation methods achieve high accuracy, their computational intensity clashes sharply with the resource constraints of low-cost edge devices. Motivated by this, this letter explores the potential of Spiking Neural Networks (SNNs) for this task and develops a fully unsupervised SNN solution. To enable a comprehensive performance analysis, we devise an extensive set of comparative strategies and evaluate them on a compelling public benchmark. Experimental results show that our unsupervised approach still attains 80% test accuracy, on par with several supervised deep learning-based strategies. Moreover, compared with complex deep learning methods, our SNN implementation is inherently suited to neuromorphic deployment and offers a drastic reduction in model complexity, bringing significant advantages for future neuromorphic practice.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [5] [Seeking Late Night Life Lines: Experiences of Conversational AI Use in Mental Health Crisis](https://arxiv.org/abs/2512.23859)
*Leah Hope Ajmani,Arka Ghosh,Benjamin Kaveladze,Eugenia Kim,Keertana Namuduri,Theresa Nguyen,Ebele Okoli,Jessica Schleider,Denae Ford,Jina Suh*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Online, people often recount their experiences turning to conversational AI agents (e.g., ChatGPT, Claude, Copilot) for mental health support -- going so far as to replace their therapists. These anecdotes suggest that AI agents have great potential to offer accessible mental health support. However, it's unclear how to meet this potential in extreme mental health crisis use cases. In this work, we explore the first-person experience of turning to a conversational AI agent in a mental health crisis. From a testimonial survey (n = 53) of lived experiences, we find that people use AI agents to fill the in-between spaces of human support; they turn to AI due to lack of access to mental health professionals or fears of burdening others. At the same time, our interviews with mental health experts (n = 16) suggest that human-human connection is an essential positive action when managing a mental health crisis. Using the stages of change model, our results suggest that a responsible AI crisis intervention is one that increases the user's preparedness to take a positive action while de-escalating any intended negative action. We discuss the implications of designing conversational AI agents as bridges towards human-human connection rather than ends in themselves.

</details>


### [6] [Deletion Considered Harmful](https://arxiv.org/abs/2512.23907)
*Paul Englefield,Russell Beale*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In a world of information overload, understanding how we can most effectively manage information is crucial to success. We set out to understand how people view deletion, the removal of material no longer needed: does it help by reducing clutter and improving the signal to noise ratio, or does the effort required to decide to delete something make it not worthwhile? How does deletion relate to other strategies like filing; do people who spend extensive time in filing also prune their materials too? We studied the behaviour of 51 knowledge workers though a series of questionnaires and interviews to evaluate a range of tactics they used aimed at organizing, filing, and retrieving digital resources. Our study reveals that deletion is consistently under-adopted compared to other tactics such as Filing, Coverage, Ontology, and Timeliness. Moreover, the empirical data indicate that deletion is actually detrimental to retrieval success and satisfaction. In this paper, we examine the practice of deletion, review the related literature, and present detailed statistical results and clustering outcomes that underscore its adverse effects.

</details>


### [7] [External Human-Machine Interface based on Intent Recognition: Framework Design and Experimental Validation](https://arxiv.org/abs/2512.24166)
*Boya Sun,Haotian Shi,Ying Ni,Shaocheng Jia,Haoyang Liang*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Increasing autonomous vehicles (AVs) in transportation systems makes effective interactions between AVs and pedestrians indispensable. External human--machine interface (eHMI), which employs visual or auditory cues to explicitly convey vehicle behaviors can compensate for the loss of human-like interactions and enhance AV--pedestrian cooperation. To facilitate faster intent convergence between pedestrian and AVs, this study incorporates an adaptive interaction mechanism into eHMI based on pedestrian intent recognition, namely IR-eHMI. IR-eHMI dynamically detects and infers the behavioral intentions of both pedestrians and AVs through identifying their cooperation states. The proposed interaction framework is implemented and evaluated on a virtual reality (VR) experimental platform to demonstrate its effectiveness through statistical analysis. Experimental results show that IR-eHMI significantly improves crossing efficiency, reduces gaze distraction while maintaining interaction safety compared to traditional fixed-distance eHMI. This adaptive and explicit interaction mode introduces an innovative procedural paradigm for AV--pedestrian cooperation.

</details>


### [8] [A Framing and Analysis of Applicative Tangible Interfaces](https://arxiv.org/abs/2512.24237)
*Guillaume Riviere*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The investigation of tangible user interfaces commenced approximately thirty years ago. Questions on its commercial potential become more pressing as the field becomes mature. To take the field one step further -- as the emergence of components contributed to the commercial development of graphical user interfaces -- this article suggests that applicative tangible user interfaces could also be split into components. These components are composed of the aggregation, combination, or coupling of physical items and fulfil four roles that are described through a new interaction model. This article successfully distributed among these four components' roles all of the 159 physical items from a representative collection of 35 applications. Further examination of these applicative tangible interfaces coincides with four research phases in the field and identifies three main paths for future research to fully realize the potential of tangible user interfaces.

</details>


### [9] [ReflecToMeet: An AI-Assisted Reflection Based System to Enhance Collaborative Preparedness](https://arxiv.org/abs/2512.24632)
*Md Nazmus Sakib,Naga Manogna Rayasam,Ishika Tarin,Sanorita Dey*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In collaborative settings, difficulties in sustaining a consistent pace and engagement often lead to task drift, reducing preparedness and overall effectiveness between meetings. To address this challenge, we conducted a formative study and developed ReflecToMeet, an AI assisted system that integrates theory driven reflective prompts with mechanisms for sharing teammates reflections. Informed by ten formative interviews, the system was evaluated in a mixed method study across three conditions: deeper reflection, regular reflection, and a control condition with unstructured reflection. Participants in the control condition demonstrated less deliberate thought and weaker collaboration, which led to stress and misalignment during team meetings. In contrast, structured reflection supported greater organization and steadier progress. The deeper reflection condition further facilitated confidence, teamwork, and idea generation, although it imposed a higher cognitive load. We conclude by discussing design implications for AI agents that facilitate reflection to enhance collaboration and broader considerations for AI assisted systems aimed at sustaining collaborative goals.

</details>


### [10] [Vibe Coding, Interface Flattening](https://arxiv.org/abs/2512.24939)
*Hongrui Jin*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large language models are reshaping programming by enabling 'vibe coding': the development of softwares through natural-language interaction with model-driven toolchains. This article argues that vibe coding is best understood as interface flattening, a reconfiguration in which previously distinct modalities (GUI, CLI, and API) appear to converge into a single conversational surface, even as the underlying chain of translation from intention to machinic effect lengthens and thickens. Drawing on Friedrich Kittler's materialist media theory and Alexander Galloway's account of interfaces as sites of protocol control, the paper situates programming as a historically localised interface arrangement rather than an essential relation to computation. Through a materialist reconstruction of the contemporary vibe-coding stack, it shows how remote compute infrastructures, latency and connectivity, structured outputs, function/tool calling, and interoperability standards such as the Model Context Protocol relocate control and meaning-making power to model and protocol providers. The apparent democratisation of technical capability therefore depends on new dependencies and new literacies. By foregrounding the tension between experiential flattening and infrastructural thickening, I demonstrate how LLM-mediated development redistributes symbolic labour/power, obscures responsibility, and privatises competencies previously dispersed across programming communities, contributing a critical lens on the political economy of AI-mediated human-computer interaction.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [11] [PartMotionEdit: Fine-Grained Text-Driven 3D Human Motion Editing via Part-Level Modulation](https://arxiv.org/abs/2512.24200)
*Yujie Yang,Zhichao Zhang,Jiazhou Chen,Zichao Wu*

Main category: cs.GR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Existing text-driven 3D human motion editing methods have demonstrated significant progress, but are still difficult to precisely control over detailed, part-specific motions due to their global modeling nature. In this paper, we propose PartMotionEdit, a novel fine-grained motion editing framework that operates via part-level semantic modulation. The core of PartMotionEdit is a Part-aware Motion Modulation (PMM) module, which builds upon a predefined five-part body decomposition. PMM dynamically predicts time-varying modulation weights for each body part, enabling precise and interpretable editing of local motions. To guide the training of PMM, we also introduce a part-level similarity curve supervision mechanism enhanced with dual-layer normalization. This mechanism assists PMM in learning semantically consistent and editable distributions across all body parts. Furthermore, we design a Bidirectional Motion Interaction (BMI) module. It leverages bidirectional cross-modal attention to achieve more accurate semantic alignment between textual instructions and motion semantics. Extensive quantitative and qualitative evaluations on a well-known benchmark demonstrate that PartMotionEdit outperforms the state-of-the-art methods.

</details>


### [12] [BATISNet: Instance Segmentation of Tooth Point Clouds with Boundary Awareness](https://arxiv.org/abs/2512.24201)
*Yating Cai,Yanghui Xu,Zehua Hu,Jiazhou Chen,Jing Huang*

Main category: cs.GR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Accurate segmentation of the tooth point cloud is of great significance for diagnosis clinical assisting and treatment planning. Existing methods mostly employ semantic segmentation, focusing on the semantic feature between different types of teeth. However, due to the tightly packed structure of teeth, unclear boundaries, and the diversity of complex cases such as missing teeth, malposed teeth, semantic segmentation often struggles to achieve satisfactory results when dealing with complex dental cases. To address these issues, this paper propose BATISNet, a boundary-aware instance network for tooth point cloud segmentation. This network model consists of a feature extraction backbone and an instance segmentation module. It not only focuses on extracting the semantic features of different types of teeth but also learns the instance features of individual teeth. It helps achieve more robust and accurate tooth instance segmentation in complex clinical scenarios such as missing teeth and malposed teeth. Additionally, to further enhance the completeness and accuracy of tooth boundary segmentation, a boundary-aware loss function is designed to specifically supervise the boundary segmentation between instances. It mitigates effectively tooth adhesion and boundary ambiguity issues. Extensive experimental results show that BATISNet outperforms existing methods in tooth integrity segmentation, providing more reliable and detailed data support for practical clinical applications.

</details>


### [13] [The Uncanny Valley in medical simulation-based training: a visual summary](https://arxiv.org/abs/2512.24240)
*Eleni Grigoriou,Manos Kamarianakis,George Papagiannakis*

Main category: cs.GR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The purpose of this review article is to provide a bibliographical as well as evidence-based visual guide regarding the effect of ``Uncanny Valley'' (UV) and how it profoundly influences medical virtual reality simulation-based training. The phenomenon, where increasingly realistic virtual humans elicit discomfort due to subtle imperfections, is crucial to understand and address in the context of medical training, where realism and immersion are key to effective learning.
  Our research team, consisting of experts in computer graphics, virtual reality, and medical education, brings a diverse and multidisciplinary perspective to this subject. Our collective experience spans developing advanced computer graphics systems, VR character simulation, and innovative educational technologies. We have collaborated across institutions and industries to push the boundaries of VR applications in medical training.

</details>


### [14] [PhysTalk: Language-driven Real-time Physics in 3D Gaussian Scenes](https://arxiv.org/abs/2512.24986)
*Luca Collorone,Mert Kiray,Indro Spinelli,Fabio Galasso,Benjamin Busam*

Main category: cs.GR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Realistic visual simulations are omnipresent, yet their creation requires computing time, rendering, and expert animation knowledge. Open-vocabulary visual effects generation from text inputs emerges as a promising solution that can unlock immense creative potential. However, current pipelines lack both physical realism and effective language interfaces, requiring slow offline optimization. In contrast, PhysTalk takes a 3D Gaussian Splatting (3DGS) scene as input and translates arbitrary user prompts into real time, physics based, interactive 4D animations. A large language model (LLM) generates executable code that directly modifies 3DGS parameters through lightweight proxies and particle dynamics. Notably, PhysTalk is the first framework to couple 3DGS directly with a physics simulator without relying on time consuming mesh extraction. While remaining open vocabulary, this design enables interactive 3D Gaussian animation via collision aware, physics based manipulation of arbitrary, multi material objects. Finally, PhysTalk is train-free and computationally lightweight: this makes 4D animation broadly accessible and shifts these workflows from a "render and wait" paradigm toward an interactive dialogue with a modern, physics-informed pipeline.

</details>
