{"id": "2602.16662", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2602.16662", "abs": "https://arxiv.org/abs/2602.16662", "authors": ["Richard Willis", "Jianing Zhao", "Yali Du", "Joel Z. Leibo"], "title": "Evaluating Collective Behaviour of Hundreds of LLM Agents", "comment": null, "summary": "As autonomous agents powered by LLM are increasingly deployed in society, understanding their collective behaviour in social dilemmas becomes critical. We introduce an evaluation framework where LLMs generate strategies encoded as algorithms, enabling inspection prior to deployment and scaling to populations of hundreds of agents -- substantially larger than in previous work. We find that more recent models tend to produce worse societal outcomes compared to older models when agents prioritise individual gain over collective benefits. Using cultural evolution to model user selection of agents, our simulations reveal a significant risk of convergence to poor societal equilibria, particularly when the relative benefit of cooperation diminishes and population sizes increase. We release our code as an evaluation suite for developers to assess the emergent collective behaviour of their models."}
{"id": "2602.16678", "categories": ["cs.MA", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.16678", "abs": "https://arxiv.org/abs/2602.16678", "authors": ["Harrison Perone", "Christopher W. Hays"], "title": "Consensus Based Task Allocation for Angles-Only Local Catalog Maintenance of Satellite Systems", "comment": "14 pages, 4 figures. Submitted to the 48th Rocky Mountain American Astronautical Society's Guidance, Navigation and Control Conference", "summary": "In order for close proximity satellites to safely perform their missions, the relative states of all satellites and pieces of debris must be well understood. This presents a problem for ground based tracking and orbit determination since it may not be practical to achieve the required accuracy. Using space-based sensors allows for more accurate relative state estimates, especially if multiple satellites are allowed to communicate. Of interest to this work is the case where several communicating satellites each need to maintain a local catalog of communicating and non-communicating objects using angles-only limited field of view (FOV) measurements. However, this introduces the problem of efficiently scheduling and coordinating observations among the agents. This paper presents a decentralized task allocation algorithm to address this problem and quantifies its performance in terms of fuel usage and overall catalog uncertainty via numerical simulation. It was found that the new method significantly outperforms the uncertainty-fuel Pareto frontier formed by current approaches."}
{"id": "2602.15831", "categories": ["cs.HC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.15831", "abs": "https://arxiv.org/abs/2602.15831", "authors": ["Zhiyuan Liang", "Enfang Cui", "Qian Wei", "Rui She", "Tianzheng Li", "Minxin Guo", "Yujun Cheng"], "title": "A2H: Agent-to-Human Protocol for AI Agent", "comment": null, "summary": "AI agents are increasingly deployed as autonomous systems capable of planning, tool use, and multi-agent collaboration across complex tasks. However, existing agent-related protocols focus on agent-to-agent interactions, leaving humans as external observers rather than integrated participants within the agent systems. This limitation arises from the lack of a standardized mechanism for agents to discover, address, and interact with humans across heterogeneous messaging platforms. In this paper, we propose the A2H (Agent-to-Human) protocol, a unified protocol that enables humans to be registered, discovered, and communicated with by AI agents as resolvable entities within agent systems. A2H contributes three key components: (1) Human Card for registering human identities via resolvable domain names, making them discoverable to agents; (2) Formal Communication Schema defines when, why, and how agents contact with human;(3) Unified Messaging Abstraction standardizes diverse communication medias and transforms complex JSON outputs into human-friendly formats. This work establishes a foundational protocol for integrating humans into agent ecosystems, advancing AI agents from isolated autonomous systems toward truly human-connected intelligent infrastructures."}
{"id": "2602.16161", "categories": ["cs.MM", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16161", "abs": "https://arxiv.org/abs/2602.16161", "authors": ["Rong Fu", "Ziming Wang", "Shuo Yin", "Wenxin Zhang", "Haiyun Wei", "Kun Liu", "Xianda Li", "Zeli Su", "Simon Fong"], "title": "Emotion Collider: Dual Hyperbolic Mirror Manifolds for Sentiment Recovery via Anti Emotion Reflection", "comment": "25 pages, 14 figures", "summary": "Emotional expression underpins natural communication and effective human-computer interaction. We present Emotion Collider (EC-Net), a hyperbolic hypergraph framework for multimodal emotion and sentiment modeling. EC-Net represents modality hierarchies using Poincare-ball embeddings and performs fusion through a hypergraph mechanism that passes messages bidirectionally between nodes and hyperedges. To sharpen class separation, contrastive learning is formulated in hyperbolic space with decoupled radial and angular objectives. High-order semantic relations across time steps and modalities are preserved via adaptive hyperedge construction. Empirical results on standard multimodal emotion benchmarks show that EC-Net produces robust, semantically coherent representations and consistently improves accuracy, particularly when modalities are partially available or contaminated by noise. These findings indicate that explicit hierarchical geometry combined with hypergraph fusion is effective for resilient multimodal affect understanding."}
{"id": "2602.16317", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2602.16317", "abs": "https://arxiv.org/abs/2602.16317", "authors": ["Maksim Elistratov", "Marina Barannikov", "Gregory Ivanov", "Valentin Khrulkov", "Anton Konushin", "Andrey Kuznetsov", "Dmitrii Zhemchuzhnikov"], "title": "CADEvolve: Creating Realistic CAD via Program Evolution", "comment": null, "summary": "Computer-Aided Design (CAD) delivers rapid, editable modeling for engineering and manufacturing. Recent AI progress now makes full automation feasible for various CAD tasks. However, progress is bottlenecked by data: public corpora mostly contain sketch-extrude sequences, lack complex operations, multi-operation composition and design intent, and thus hinder effective fine-tuning. Attempts to bypass this with frozen VLMs often yield simple or invalid programs due to limited 3D grounding in current foundation models. We present CADEvolve, an evolution-based pipeline and dataset that starts from simple primitives and, via VLM-guided edits and validations, incrementally grows CAD programs toward industrial-grade complexity. The result is 8k complex parts expressed as executable CadQuery parametric generators. After multi-stage post-processing and augmentation, we obtain a unified dataset of 1.3m scripts paired with rendered geometry and exercising the full CadQuery operation set. A VLM fine-tuned on CADEvolve achieves state-of-the-art results on the Image2CAD task across the DeepCAD, Fusion 360, and MCB benchmarks."}
{"id": "2602.15831", "categories": ["cs.HC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.15831", "abs": "https://arxiv.org/abs/2602.15831", "authors": ["Zhiyuan Liang", "Enfang Cui", "Qian Wei", "Rui She", "Tianzheng Li", "Minxin Guo", "Yujun Cheng"], "title": "A2H: Agent-to-Human Protocol for AI Agent", "comment": null, "summary": "AI agents are increasingly deployed as autonomous systems capable of planning, tool use, and multi-agent collaboration across complex tasks. However, existing agent-related protocols focus on agent-to-agent interactions, leaving humans as external observers rather than integrated participants within the agent systems. This limitation arises from the lack of a standardized mechanism for agents to discover, address, and interact with humans across heterogeneous messaging platforms. In this paper, we propose the A2H (Agent-to-Human) protocol, a unified protocol that enables humans to be registered, discovered, and communicated with by AI agents as resolvable entities within agent systems. A2H contributes three key components: (1) Human Card for registering human identities via resolvable domain names, making them discoverable to agents; (2) Formal Communication Schema defines when, why, and how agents contact with human;(3) Unified Messaging Abstraction standardizes diverse communication medias and transforms complex JSON outputs into human-friendly formats. This work establishes a foundational protocol for integrating humans into agent ecosystems, advancing AI agents from isolated autonomous systems toward truly human-connected intelligent infrastructures."}
{"id": "2602.16611", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.16611", "abs": "https://arxiv.org/abs/2602.16611", "authors": ["Santiago Jimenez-Navarro", "Belen Masia", "Ana Serrano"], "title": "Style-Aware Gloss Control for Generative Non-Photorealistic Rendering", "comment": null, "summary": "Humans can infer material characteristics of objects from their visual appearance, and this ability extends to artistic depictions, where similar perceptual strategies guide the interpretation of paintings or drawings. Among the factors that define material appearance, gloss, along with color, is widely regarded as one of the most important, and recent studies indicate that humans can perceive gloss independently of the artistic style used to depict an object. To investigate how gloss and artistic style are represented in learned models, we train an unsupervised generative model on a newly curated dataset of painterly objects designed to systematically vary such factors. Our analysis reveals a hierarchical latent space in which gloss is disentangled from other appearance factors, allowing for a detailed study of how gloss is represented and varies across artistic styles. Building on this representation, we introduce a lightweight adapter that connects our style- and gloss-aware latent space to a latent-diffusion model, enabling the synthesis of non-photorealistic images with fine-grained control of these factors. We compare our approach with previous models and observe improved disentanglement and controllability of the learned factors."}
{"id": "2602.15832", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15832", "abs": "https://arxiv.org/abs/2602.15832", "authors": ["Weiwen Su", "Yuhan Zhou", "Zihan Wang", "Naoki Yoshinaga", "Masashi Toyoda"], "title": "What Persona Are We Missing? Identifying Unknown Relevant Personas for Faithful User Simulation", "comment": null, "summary": "Existing user simulations, where models generate user-like responses in dialogue, often lack verification that sufficient user personas are provided, questioning the validity of the simulations. To address this core concern, this work explores the task of identifying relevant but unknown personas of the simulation target for a given simulation context. We introduce PICQ, a novel dataset of context-aware choice questions, annotated with unknown personas (e.g., ''Is the user price-sensitive?'') that may influence user choices, and propose a multi-faceted evaluation scheme assessing fidelity, influence, and inaccessibility. Our benchmark of leading LLMs reveals a complex ''Fidelity vs. Insight'' dilemma governed by model scale: while influence generally scales with model size, fidelity to human patterns follows an inverted U-shaped curve. We trace this phenomenon to cognitive differences, particularly the human tendency for ''cognitive economy.'' Our work provides the first comprehensive benchmark for this crucial task, offering a new lens for understanding the divergent cognitive models of humans and advanced LLMs."}
{"id": "2602.15833", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.15833", "abs": "https://arxiv.org/abs/2602.15833", "authors": ["Paolo Bottoni", "Susanna Cifani", "Kamen Kanev", "Daniel Moraru", "Atsushi Nakamura", "Marco Raoul Marini"], "title": "Towards a More Realistic VR Experience: Merging Haptic Gloves with Precision Gloves", "comment": "3 pages, 2 figures. Presented as Abstract P3-24 at the 10th International Symposium on Biomedical Engineering (ISBE2025) and the International Workshop on Nanodevice Technologies 2025 (IWNT2025), October 30-31, 2025, Higashihiroshima, Japan", "summary": "Virtual reality (VR) glove technology is increasingly important for professional training, industrial applications, and teleoperation in hazardous environments, since it enables more natural and immersive interactions than controllers. However, current solutions face a trade-off: high-precision gloves lack haptic feedback, while haptic gloves suffer from poor accuracy. Existing studies have mainly focused on developing new glove prototypes or optimizing only one type of glove, without addressing the integration of both features. Our work presents a novel hybrid approach that combines a high-precision glove with a haptic glove, creating a system that delivers both precision and haptics."}
{"id": "2602.15835", "categories": ["cs.HC", "cs.CL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.15835", "abs": "https://arxiv.org/abs/2602.15835", "authors": ["Mikio Nakano", "Hironori Takeuchi", "Kazunori Komatani"], "title": "A Methodology for Identifying Evaluation Items for Practical Dialogue Systems Based on Business-Dialogue System Alignment Models", "comment": "This paper has been accepted for presentation at International Workshop on Spoken Dialogue Systems Technology 2025 (IWSDS 2025)", "summary": "This paper proposes a methodology for identifying evaluation items for practical dialogue systems. Traditionally, user satisfaction and user experiences have been the primary metrics for evaluating dialogue systems. However, there are various other evaluation items to consider when developing and operating practical dialogue systems, and such evaluation items are expected to lead to new research topics. So far, there has been no methodology for identifying these evaluation items. We propose identifying evaluation items based on business-dialogue system alignment models, which are applications of business-IT alignment models used in the development and operation of practical IT systems. We also present a generic model that facilitates the construction of a business-dialogue system alignment model for each dialogue system."}
{"id": "2602.15839", "categories": ["cs.HC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.15839", "abs": "https://arxiv.org/abs/2602.15839", "authors": ["Ruiyong Zhang"], "title": "EmoTrack: An application to Facilitate User Reflection on Their Online Behaviours", "comment": "Master's thesis", "summary": "With the rapid growth of the internet, all online activities can have both positive and negative effects on human mental health. Online engagement is complex and efforts to regulate online use face challenges in distinguishing between beneficial and harmful content and behaviours. An alternative approach is to help young people develop the skills they need to manage online safety while preserving the benefits of online interactions. This dissertation presents the entire development process and evaluation of an multi-platform application, called EmoTrack that aims to help young people reflect on their online behaviour. It was developed to record their online activities and cultivate strategies for more positive and mindful engagement online. EmoTrack is a personal informatics system, and it is designed to help people track and reflect on their engagement with YouTube videos. The system was evaluated with thirteen participants and it was found that EmoTrack can facilitate them to reflect on their video watching behaviour and the impact on their mood, with reports of different levels of reflections from R0 to R3."}
{"id": "2602.15865", "categories": ["cs.HC", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.15865", "abs": "https://arxiv.org/abs/2602.15865", "authors": ["Most. Sharmin Sultana Samu", "Nafisa Khan", "Kazi Toufique Elahi", "Tasnuva Binte Rahman", "Md. Rakibul Islam", "Farig Sadeque"], "title": "AI as Teammate or Tool? A Review of Human-AI Interaction in Decision Support", "comment": "Preprint", "summary": "The integration of Artificial Intelligence (AI) necessitates determining whether systems function as tools or collaborative teammates. In this study, by synthesizing Human-AI Interaction (HAI) literature, we analyze this distinction across four dimensions: interaction design, trust calibration, collaborative frameworks and healthcare applications. Our analysis reveals that static interfaces and miscalibrated trust limit AI efficacy. Performance hinges on aligning transparency with cognitive workflows, yet a fluency trap often inflates trust without improving decision-making. Consequently, an overemphasis on explainability leaves systems largely passive. Our findings show that current AI systems remain largely passive due to an overreliance on explainability-centric designs and that transitioning AI to an active teammate requires adaptive, context-aware interactions that support shared mental models and the dynamic negotiation of authority between humans and AI."}
{"id": "2602.16013", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.16013", "abs": "https://arxiv.org/abs/2602.16013", "authors": ["Ryo Ohara", "Chi-Lan Yang", "Yuji Hatada", "Takuji Narumi", "Hideaki Kuzuoka"], "title": "Punchlines Unbound: Comedy Practices in Social Virtual Reality", "comment": null, "summary": "Social VR platforms serve as an emergent venue for live performance, enabling co-presence and real-time interaction among distributed performers and audiences within shared virtual environments. Live performances, such as comedy, rely on subtle social cues between performers and audiences, which are missing in VR. However, it remains unclear how comedians utilize avatar-mediated cues in social VR. We conducted semi-structured interviews and observations with 23 virtual comedians on VRChat. Results revealed that virtual comedians transformed their limited nonverbal expressiveness into performative opportunities through intentional control and exaggeration. Additionally, a distinctive culture emerged around context-appropriate emoji reactions from audiences, while challenges such as audio latency and moderation against trolling were highlighted. Our findings advance understanding of how performers creatively adapt to expressive constraints in avatar-mediated settings. We further demonstrate how challenges in performer-audience interaction and moderation provide design insights for systems enhancing feedback visibility and sustain community norms without restricting creative expression."}
{"id": "2602.16033", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16033", "abs": "https://arxiv.org/abs/2602.16033", "authors": ["Ruiwei Xiao", "Runlong Ye", "Xinying Hou", "Jessica Wen", "Harsh Kumar", "Michael Liut", "John Stamper"], "title": "Transforming GenAI Policy to Prompting Instruction: An RCT of Scalable Prompting Interventions in a CS1 Course", "comment": "11 pages, 3 figures", "summary": "Despite universal GenAI adoption, students cannot distinguish task performance from actual learning and lack skills to leverage AI for learning, leading to worse exam performance when AI use remains unreflective. Yet few interventions teaching students to prompt AI as a tutor rather than solution provider have been validated at scale through randomized controlled trials (RCTs). To bridge this gap, we conducted a semester-long RCT (N=979) with four ICAP framework-based instructional conditions varying in engagement intensity with a pre-test, immediate and delayed post-test and surveys. Mixed methods analysis results showed: (1) All conditions significantly improved prompting skills, with gains increasing progressively from Condition 1 to Condition 4, validating ICAP's cognitive engagement hierarchy; (2) for students with similar pre-test scores, higher learning gain in immediate post-test predict higher final exam score, though no direct between-group differences emerged; (3) Our interventions are suitable and scalable solutions for diverse educational contexts, resources and learners. Together, this study makes empirical and theoretical contributions: (1) theoretically, we provided one of the first large-scale RCTs examining how cognitive engagement shapes learning in prompting literacy and clarifying the relationship between learning-oriented prompting skills and broader academic performance; (2) empirically, we offered timely design guidance for transforming GenAI classroom policies into scalable, actionable prompting literacy instruction to advance learning in the era of Generative AI."}
{"id": "2602.16047", "categories": ["cs.HC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.16047", "abs": "https://arxiv.org/abs/2602.16047", "authors": ["Sikao Guo", "Edoardo Sarti", "Frédéric Cazals"], "title": "A Unified, Cross-Platform Framework for Automatic GUI and Plugin Generation in Structural Bioinformatics and Beyond", "comment": "10 pages, 4 figures", "summary": "We present a workflow and associated toolkit to automate the creation of graphical user interfaces (GUI) for executables run from command line interfaces (CLI). The workflow consists of three phases, namely (Step 1) the plugin design, (Step 2) the formal (platform independent) specification of the GUI, and (Step 3) the plugin code generation for the targeted platforms. Our architecture is aligned with the Model--View--Presenter (MVP) pattern: steps one and two build the Model and View descriptions, while step three implements the Presenter layer that binds inputs, invokes the CLI, and updates outputs. Once Step one has been (manually) completed, steps two and three are fully automated. The decoupled MVP design and platform-specific generator modules enable reuse of logic, portability across ecosystems, and significant reductions in engineering effort for complex interactive applications.\n  We primarily use our workflow to generate GUI in structural bioinformatics for CLI executables from the Structural Bioinformatics Library (SBL), targeting three platforms, namely VMD, Pymol and Web servers.\n  The workflow can be used as a guideline, while its implementation available in the package Plugin_manager from the SBL, see https://sbl.inria.fr/doc/Plugin_manager-user-manual.html."}
{"id": "2602.16070", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.16070", "abs": "https://arxiv.org/abs/2602.16070", "authors": ["Weijun Zhang", "Xinru Tang"], "title": "Access in the Shadow of Ableism: An Autoethnography of a Blind Student's Higher Education Experience in China", "comment": null, "summary": "The HCI research community has witnessed a growing body of research on accessibility and disability driven by efforts to improve access. Yet, the concept of access reveals its limitations when examined within broader ableist structures. Drawing on an autoethnographic method, this study shares the co-first author Zhang's experiences at two higher-education institutions in China, including a specialized program exclusively for blind and low-vision students and a mainstream university where he was the first blind student admitted. Our analysis revealed tensions around access in both institutions: they either marginalized blind students within society at large or imposed pressures to conform to sighted norms. Both institutions were further constrained by systemic issues, including limited accessible resources, pervasive ableist cultures, and the lack of formalized policies. In response to these tensions, we conceptualize access as a contradictory construct and argue for understanding accessibility as an ongoing, exploratory practice within ableist structures."}
{"id": "2602.16112", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.16112", "abs": "https://arxiv.org/abs/2602.16112", "authors": ["Rachael Zehrung", "Yunan Chen"], "title": "Hiding in Plain Sight: Understanding the Everyday Practices and Challenges of Car Dwellers", "comment": "ACM CHI 2026, 13 pages, 1 figure", "summary": "Vehicle dwelling has increased significantly in recent years. While HCI research has explored vehicle dwelling through the lens of digital nomadism and vanlife, it has largely overlooked the complexities of vehicle dwelling as a form of housing insecurity, as well as the unique constraints of living in smaller vehicles. Drawing on a qualitative analysis of posts and comments from an online community, we examine car dwellers' infrastructuring work to manage daily life under social, spatial, and infrastructural constraints. We further explore the motivations and identity negotiations of car dwellers, whose experiences fall between homelessness and nomadism, and highlight how developing infrastructural competence can shape identity. We discuss implications for future HCI research on mobility and dwelling under conditions of uneven access to infrastructure and provide design recommendations for technologies that better account for car dwellers' diverse needs, circumstances, and identities."}
{"id": "2602.16123", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.16123", "abs": "https://arxiv.org/abs/2602.16123", "authors": ["Daniel J. Noh", "Deborah A. Fields", "Yasmin B. Kafai", "Danaé Metaxa"], "title": "\"You Can Actually Do Something\": Shifts in High School Computer Science Teachers' Conceptions of AI/ML Systems and Algorithmic Justice", "comment": null, "summary": "The recent proliferation of artificial intelligence and machine learning (AI/ML) systems highlights the need for all people to develop effective competencies to interact with and examine AI/ML systems. We study shifts in five experienced high school CS teachers' understanding of AI/ML systems after one year of participatory design, where they co-developed lessons on AI auditing, a systematic method to query AI/ML systems. Drawing on individual and group interviews, we found that teachers' perspectives became more situated, grounding their understanding in everyday contexts; more critical, reflecting growing awareness of harms; and more agentic, highlighting possibilities for action. Further, across all three perspectives, teachers consistently framed algorithmic justice through their role as educators, situating their concerns within their school communities. In the discussion, we consider the ways teachers' perspectives shifted, how AI auditing can shape these shifts, and the implications of these findings on AI literacy for both teachers and students."}
{"id": "2602.16140", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16140", "abs": "https://arxiv.org/abs/2602.16140", "authors": ["Wooyoung Jung", "Kahyun Jeon", "Prosper Babon-Ayeng"], "title": "Human-AI Collaboration in Large Language Model-Integrated Building Energy Management Systems: The Role of User Domain Knowledge and AI Literacy", "comment": "39 pages, 11 figures", "summary": "This study aimed to comprehend how user domain knowledge and artificial intelligence (AI) literacy impact the effective use of human-AI interactive building energy management system (BEMS). While prior studies have investigated the potential of integrating large language models (LLMs) into BEMS or building energy modeling, very few studies have examined how user interact with such systems. We conducted a systematic role-playing experiment, where 85 human subjects interacted with an advanced generative pre-trained transformer (OpenAI GPT-4o). Participants were tasked with identifying the top five behavioral changes that could reduce home energy use with the GPT model that functioned as an LLM-integrated BEMS. Then, the collected prompt-response data and participant conclusions were analyzed using an analytical framework that hierarchically assessed and scored human-AI interactions and their home energy analysis approaches. Also, participants were classified into four groups based on their self-evaluated domain knowledge of building energy use and AI literacy, and Kruskal-Wallis H tests with post-hoc pairwise comparisons were conducted across 20 quantifiable metrics. Key takeaways include: most participants employed concise prompts (median: 16.2 words) and relied heavily on GPT's analytical capabilities; and notably, only 1 of 20 metrics, appliance identification rate, showed statistically significant group differences (p=0.037), driven by AI literacy rather than domain knowledge, suggesting an equalizing effect of LLMs across expertise levels. This study provides foundational insights into human-AI collaboration dynamics and promising development directions in the context of LLM-integrated BEMS and contributes to realizing human-centric LLM-integrated energy systems."}
{"id": "2602.16157", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.16157", "abs": "https://arxiv.org/abs/2602.16157", "authors": ["Xinyue Gui", "Ding Xia", "Mark Colley", "Yuan Li", "Vishal Chauhan", "Anubhav Anubhav", "Zhongyi Zhou", "Ehsan Javanmardi", "Stela Hanbyeol Seo", "Chia-Ming Chang", "Manabu Tsukada", "Takeo Igarashi"], "title": "Peeking Ahead of the Field Study: Exploring VLM Personas as Support Tools for Embodied Studies in HCI", "comment": "Accepted to CHI 2026", "summary": "Field studies are irreplaceable but costly, time-consuming, and error-prone, which need careful preparation. Inspired by rapid-prototyping in manufacturing, we propose a fast, low-cost evaluation method using Vision-Language Model (VLM) personas to simulate outcomes comparable to field results. While LLMs show human-like reasoning and language capabilities, autonomous vehicle (AV)-pedestrian interaction requires spatial awareness, emotional empathy, and behavioral generation. This raises our research question: To what extent can VLM personas mimic human responses in field studies? We conducted parallel studies: 1) one real-world study with 20 participants, and 2) one video-study using 20 VLM personas, both on a street-crossing task. We compared their responses and interviewed five HCI researchers on potential applications. Results show that VLM personas mimic human response patterns (e.g., average crossing times of 5.25 s vs. 5.07 s) lack the behavioral variability and depth. They show promise for formative studies, field study preparation, and human data augmentation."}
{"id": "2602.16251", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.16251", "abs": "https://arxiv.org/abs/2602.16251", "authors": ["Hyoungwook Jin", "Minju Yoo", "Jieun Han", "Zixin Chen", "So-Yeon Ahn", "Xu Wang"], "title": "RelianceScope: An Analytical Framework for Examining Students' Reliance on Generative AI Chatbots in Problem Solving", "comment": null, "summary": "Generative AI chatbots enable personalized problem-solving, but effective learning requires students to self-regulate both how they seek help and how they use AI-generated responses. Considering engagement modes across these two actions reveals nuanced reliance patterns: for example, a student may actively engage in help-seeking by clearly specifying areas of need, yet engage passively in response-use by copying AI outputs, or vice versa. However, existing research lacks systematic tools for jointly capturing engagement across help-seeking and response-use, limiting the analysis of such reliance behaviors. We introduce RelianceScope, an analytical framework that characterizes students' reliance on chatbots during problem-solving. RelianceScope (1) operationalizes reliance into nine patterns based on combinations of engagement modes in help-seeking and response-use, and (2) situates these patterns within a knowledge-context lens that accounts for students' prior knowledge and the instructional significance of knowledge components. Rather than prescribing optimal AI use, the framework enables fine-grained analysis of reliance in open-ended student-AI interactions. As an illustrative application, we applied RelianceScope to analyze chat and code-edit logs from 79 college students in a web programming course. Results show that active help-seeking is associated with active response-use, whereas reliance patterns remain similar across knowledge mastery levels. Students often struggled to articulate their knowledge gaps and to adapt AI responses. Using our annotated dataset as a benchmark, we further demonstrate that large language models can reliably detect reliance during help-seeking and response-use. We conclude by discussing the implications of RelianceScope and the design guidelines for AI-supported educational systems."}
{"id": "2602.16279", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.16279", "abs": "https://arxiv.org/abs/2602.16279", "authors": ["Michael T. Knierim", "Thimo Schulz", "Moritz Schiller", "Jwan Shaban", "Mario Nadj", "Max L. Wilson", "Alexander Maedche"], "title": "Flow on Social Media? Rarer Than You'd Think", "comment": null, "summary": "Researchers often attribute social media's appeal to its ability to elicit flow experiences of deep absorption and effortless engagement. Yet prolonged use has also been linked to distraction, fatigue, and lower mood. This paradox remains poorly understood, in part because prior studies rely on habitual or one-shot reports that ask participants to directly attribute flow to social media. To address this gap, we conducted a five-day field study with 40 participants, combining objective smartphone app tracking with daily reconstructions of flow-inducing activities. Across 673 reported flow occurrences, participants rarely associated flow with social media (2 percent). Instead, heavier social media use predicted fewer daily flow occurrences. We further examine this relationship through the effects of social media use on fatigue, mood, and motivation. Altogether, our findings suggest that flow and social media may not align as closely as assumed - and might even compete - underscoring the need for further research."}
{"id": "2602.16302", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.16302", "abs": "https://arxiv.org/abs/2602.16302", "authors": ["Arianna Rossi", "Simon Parkin"], "title": "\"What I'm Interested in is Something that Violates the Law\": Regulatory Practitioner Views on Automated Detection of Deceptive Design Patterns", "comment": "Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems (CHI '26), April 13--17, 2026, Barcelona, Spain", "summary": "Although deceptive design patterns are subject to growing regulatory oversight, enforcement races to keep up with the scale of the problem. One promising solution is automated detection tools, many of which are developed within academia. We interviewed nine experienced practitioners working within or alongside regulatory bodies to understand their work against deceptive design patterns, including the use of supporting tools and the prospect of automation. Computing technologies have their place in regulatory practice, but not as envisioned in research. For example, investigations require utmost transparency and accountability in all the activities we identify as accompanying dark pattern detection, which many existing tools cannot provide. Moreover, tools need to map interfaces to legal violations to be of use. We thus recommend conducting user requirement research to maximize research impact, supporting ancillary activities beyond detection, and establishing practical tech adoption pathways that account for the needs of both scientific and regulatory activities."}
{"id": "2602.16323", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.16323", "abs": "https://arxiv.org/abs/2602.16323", "authors": ["Jindu Wang", "Runze Cai", "Shuchang Xu", "Tianrui Hu", "Huamin Qu", "Shengdong Zhao", "Ling-Ping Yuan"], "title": "Wearable AR for Restorative Breaks: How Interactive Narrative Experiences Support Relaxation for Young Adults", "comment": null, "summary": "Young adults often take breaks from screen-intensive work by consuming digital content on mobile phones, which undermines rest through visual fatigue and inactivity. We introduce a design framework that embeds light break activities into media content on AR smart glasses, balancing engagement and recovery. The framework employs three strategies: (1) seamlessly guiding users by embedding activity cues aligned with media elements; (2) transitioning to audio-centric formats to reduce visual load while sustaining immersion; and (3) structuring sessions with \"rise-peak-closure\" pacing for smooth transitions. In a within-subjects study (N = 16) comparing passive viewing, reminder-based breaks, and non-narrative activities, InteractiveBreak instantiated from our framework seamlessly guided activities, sustained engagement, and enhanced break quality. These findings demonstrate wearable AR's potential to support restorative relaxation by transforming breaks into engaging and meaningful experiences."}
