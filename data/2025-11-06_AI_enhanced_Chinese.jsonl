{"id": "2511.02837", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02837", "abs": "https://arxiv.org/abs/2511.02837", "authors": ["Sotirios Konstantakos", "Sotirios Asparagkathos", "Moatasim Mahmoud", "Stamatia Rizou", "Enrico Quagliarini", "Gabriele Bernardini"], "title": "An extended reality-based framework for user risk training in urban built environment", "comment": null, "summary": "In the context of increasing urban risks, particularly from climate\nchange-induced flooding, this paper presents an extended Reality (XR)-based\nframework to improve user risk training within urban built environments. The\nframework is designed to improve risk awareness and preparedness among various\nstakeholders, including citizens, local authorities, and emergency responders.\nUsing immersive XR technologies, the training experience simulates real-world\nemergency scenarios, contributing to active participation and a deeper\nunderstanding of potential hazards and especially for floods. The framework\nhighlights the importance of stakeholder participation in its development,\nensuring that training modules are customized to address the specific needs of\ndifferent user groups. The iterative approach of the framework supports ongoing\nrefinement through user feedback and performance data, thus improving the\noverall effectiveness of risk training initiatives. This work outlines the\nmethodological phases involved in the framework's implementation, including i)\nuser flow mapping, ii) scenario selection, and iii) performance evaluation,\nwith a focus on the pilot application in Senigallia, Italy. The findings\nunderscore the potential of XR technologies to transform urban risk training,\npromoting a culture of preparedness and resilience against urban hazards.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.02838", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2511.02838", "abs": "https://arxiv.org/abs/2511.02838", "authors": ["Goran Bubas"], "title": "How ChatGPT and Gemini View the Elements of Communication Competence of Large Language Models: A Pilot Study", "comment": "Proceedings of the 36th Central European Conference on Information\n  and Intelligent Systems, Varazdin, Croatia", "summary": "A concise overview is provided of selected theoretical models of\ncommunication competence in the fields of linguistics, interpersonal\ncommunication, second language use, and human-robot interaction. The following\npractical research consisted of two case studies with the goals of\ninvestigating how advanced AI tools like ChatGPT and Gemini interpret elements\nof two communication competence theories in the context of Large Language Model\n(LLM) interactions with users. The focus was on these theoretical approaches:\n(1) an integrated linguistic-interpersonal model and (2) an interpersonal\n\"human-humanoid\" interaction model. The conclusion is that both approaches are\nsuitable for a better understanding of LLM-user interaction.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.02839", "categories": ["cs.HC", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.02839", "abs": "https://arxiv.org/abs/2511.02839", "authors": ["Antonio Verdone", "Aidan Cardall", "Fardeen Siddiqui", "Motaz Nashawaty", "Danielle Rigau", "Youngjoon Kwon", "Mira Yousef", "Shalin Patel", "Alex Kieturakis", "Eric Kim", "Laura Heacock", "Beatriu Reig", "Yiqiu Shen"], "title": "Evaluating Generative AI as an Educational Tool for Radiology Resident Report Drafting", "comment": null, "summary": "Objective: Radiology residents require timely, personalized feedback to\ndevelop accurate image analysis and reporting skills. Increasing clinical\nworkload often limits attendings' ability to provide guidance. This study\nevaluates a HIPAA-compliant GPT-4o system that delivers automated feedback on\nbreast imaging reports drafted by residents in real clinical settings.\n  Methods: We analyzed 5,000 resident-attending report pairs from routine\npractice at a multi-site U.S. health system. GPT-4o was prompted with clinical\ninstructions to identify common errors and provide feedback. A reader study\nusing 100 report pairs was conducted. Four attending radiologists and four\nresidents independently reviewed each pair, determined whether predefined error\ntypes were present, and rated GPT-4o's feedback as helpful or not. Agreement\nbetween GPT and readers was assessed using percent match. Inter-reader\nreliability was measured with Krippendorff's alpha. Educational value was\nmeasured as the proportion of cases rated helpful.\n  Results: Three common error types were identified: (1) omission or addition\nof key findings, (2) incorrect use or omission of technical descriptors, and\n(3) final assessment inconsistent with findings. GPT-4o showed strong agreement\nwith attending consensus: 90.5%, 78.3%, and 90.4% across error types.\nInter-reader reliability showed moderate variability ({\\alpha} = 0.767, 0.595,\n0.567), and replacing a human reader with GPT-4o did not significantly affect\nagreement ({\\Delta} = -0.004 to 0.002). GPT's feedback was rated helpful in\nmost cases: 89.8%, 83.0%, and 92.0%.\n  Discussion: ChatGPT-4o can reliably identify key educational errors. It may\nserve as a scalable tool to support radiology education.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.03147", "categories": ["cs.GR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03147", "abs": "https://arxiv.org/abs/2511.03147", "authors": ["Haotian Yin", "Przemyslaw Musialski"], "title": "Scheduling the Off-Diagonal Weingarten Loss of Neural SDFs for CAD Models", "comment": "Lecture Notes in Computer Science (LNCS), 20th International\n  Symposium on Visual Computing 2025, 12 pages, 4 figures, preprint", "summary": "Neural signed distance functions (SDFs) have become a powerful representation\nfor geometric reconstruction from point clouds, yet they often require both\ngradient- and curvature-based regularization to suppress spurious warp and\npreserve structural fidelity. FlatCAD introduced the Off-Diagonal Weingarten\n(ODW) loss as an efficient second-order prior for CAD surfaces, approximating\nfull-Hessian regularization at roughly half the computational cost. However,\nFlatCAD applies a fixed ODW weight throughout training, which is suboptimal:\nstrong regularization stabilizes early optimization but suppresses detail\nrecovery in later stages. We present scheduling strategies for the ODW loss\nthat assign a high initial weight to stabilize optimization and progressively\ndecay it to permit fine-scale refinement. We investigate constant, linear,\nquintic, and step interpolation schedules, as well as an increasing warm-up\nvariant. Experiments on the ABC CAD dataset demonstrate that time-varying\nschedules consistently outperform fixed weights. Our method achieves up to a\n35% improvement in Chamfer Distance over the FlatCAD baseline, establishing\nscheduling as a simple yet effective extension of curvature regularization for\nrobust CAD reconstruction.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.02840", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2511.02840", "abs": "https://arxiv.org/abs/2511.02840", "authors": ["Saizo Aoyagi"], "title": "Interview Survey on Attractivenesses of Place Re-creation Toward Developing a Virtual Twin Design Theory", "comment": "The final draft for Humaninterface 2025, in Japanese language", "summary": "It is often seen that real-world locations are re-created using models,\nmetaverse technology, or computer graphics. Although the surface-level purposes\nof these re-creations vary, the author hypothesizes that there exists an\nunderlying common attractiveness that remains unclear. This research aims to\nclarify the attractiveness and its structures of place re-creations through an\ninterview study with qualitative analysis. The interviews used examples of\nphysical re-creations, such as the model in Komazawa University's Zen Culture\nHistory Museum and some dioramas of Tokyo, as well as computer-generated\nre-creations of Shibuya using platforms like Minecraft and Project Plateau's 3D\ncity model. Using insights gained from this investigation, this study seeks to\nestablish a theoretical framework for designing virtual twins.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.03617", "categories": ["cs.GR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03617", "abs": "https://arxiv.org/abs/2511.03617", "authors": ["Timo Brand", "Henry F\u00f6rster", "Stephen G. Kobourov", "Jacob Miller"], "title": "Visualization Biases MLLM's Decision Making in Network Data Tasks", "comment": "This manuscript was presented at VIS x GenAI, a workshop co-located\n  with IEEE VIS 2025", "summary": "We evaluate how visualizations can influence the judgment of MLLMs about the\npresence or absence of bridges in a network. We show that the inclusion of\nvisualization improves confidence over a structured text-based input that could\ntheoretically be helpful for answering the question. On the other hand, we\nobserve that standard visualization techniques create a strong bias towards\naccepting or refuting the presence of a bridge -- independently of whether or\nnot a bridge actually exists in the network. While our results indicate that\nthe inclusion of visualization techniques can effectively influence the MLLM's\njudgment without compromising its self-reported confidence, they also imply\nthat practitioners must be careful of allowing users to include visualizations\nin generative AI applications so as to avoid undesired hallucinations.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.03094", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2511.03094", "abs": "https://arxiv.org/abs/2511.03094", "authors": ["Longling Geng", "Edward Y. Chang"], "title": "ALAS: Transactional and Dynamic Multi-Agent LLM Planning", "comment": null, "summary": "Large language models enable flexible multi-agent planning but remain fragile\nin practice: verification is often circular, state changes are not tracked for\nrepair, and small faults trigger costly global recomputation. We present ALAS,\na stateful, disruption-aware framework that separates planning from\nnon-circular validation, records a versioned execution log for grounded checks\nand restore points, and performs localized repair that preserves work in\nprogress. The validator operates independently of the planning LLM with fresh,\nbounded context, avoiding self-check loops and mid-context attrition. The\nrepair protocol edits only the minimal affected region under explicit policies\n(retry, catch, timeout, backoff, idempotency keys, compensation, loop guards)\ndefined in a canonical workflow IR that maps to Amazon States Language and Argo\nWorkflows. On job-shop scheduling suites (DMU, TA) across five classical\nbenchmarks, ALAS matches or exceeds strong single-LLM and multi-agent\nbaselines, achieving 83.7% success, reducing token usage by 60%, and running\n1.82times faster under comparable settings. A minimal reliability study shows\nthat the validator detects injected structural faults with low overhead, and\nthat localized repair contains runtime perturbations with a bounded edit radius\nand less makespan degradation than global recompute. Results indicate that the\ncombination of validator isolation, versioned execution logs, and localized\nrepair provides measurable efficiency, feasibility, and scalability for\nmulti-agent LLM planning. Code and seeds will be released.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.03227", "categories": ["cs.HC", "cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2511.03227", "abs": "https://arxiv.org/abs/2511.03227", "authors": ["Alexander Htet Kyaw", "Lenin Ravindranath Sivalingam"], "title": "Node-Based Editing for Multimodal Generation of Text, Audio, Image, and Vide", "comment": "Accepted to NeurIPS 2025, Conference on Neural Information Processing\n  Systems, Workshop on Generative and Protective AI for Content Creation", "summary": "We present a node-based storytelling system for multimodal content\ngeneration. The system represents stories as graphs of nodes that can be\nexpanded, edited, and iteratively refined through direct user edits and\nnatural-language prompts. Each node can integrate text, images, audio, and\nvideo, allowing creators to compose multimodal narratives. A task selection\nagent routes between specialized generative tasks that handle story generation,\nnode structure reasoning, node diagram formatting, and context generation. The\ninterface supports targeted editing of individual nodes, automatic branching\nfor parallel storylines, and node-based iterative refinement. Our results\ndemonstrate that node-based editing supports control over narrative structure\nand iterative generation of text, images, audio, and video. We report\nquantitative outcomes on automatic story outline generation and qualitative\nobservations of editing workflows. Finally, we discuss current limitations such\nas scalability to longer narratives and consistency across multiple nodes, and\noutline future work toward human-in-the-loop and user-centered creative AI\ntools.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.02842", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02842", "abs": "https://arxiv.org/abs/2511.02842", "authors": ["Jiawei Zheng", "Gokcen Yilmaz", "Ji Han", "Saeema Ahmed-Kristensen"], "title": "Digital Transformation Chatbot (DTchatbot): Integrating Large Language Model-based Chatbot in Acquiring Digital Transformation Needs", "comment": "Accepted by the International Conference on Human-Computer\n  Interaction", "summary": "Many organisations pursue digital transformation to enhance operational\nefficiency, reduce manual efforts, and optimise processes by automation and\ndigital tools. To achieve this, a comprehensive understanding of their unique\nneeds is required. However, traditional methods, such as expert interviews,\nwhile effective, face several challenges, including scheduling conflicts,\nresource constraints, inconsistency, etc. To tackle these issues, we\ninvestigate the use of a Large Language Model (LLM)-powered chatbot to acquire\norganisations' digital transformation needs. Specifically, the chatbot\nintegrates workflow-based instruction with LLM's planning and reasoning\ncapabilities, enabling it to function as a virtual expert and conduct\ninterviews. We detail the chatbot's features and its implementation. Our\npreliminary evaluation indicates that the chatbot performs as designed,\neffectively following predefined workflows and supporting user interactions\nwith areas for improvement. We conclude by discussing the implications of\nemploying chatbots to elicit user information, emphasizing their potential and\nlimitations.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.03348", "categories": ["cs.MA", "68T05"], "pdf": "https://arxiv.org/pdf/2511.03348", "abs": "https://arxiv.org/abs/2511.03348", "authors": ["Changxi Zhu", "Mehdi Dastani", "Shihan Wang"], "title": "Learning Communication Skills in Multi-task Multi-agent Deep Reinforcement Learning", "comment": "20 pages, 10 figures", "summary": "In multi-agent deep reinforcement learning (MADRL), agents can communicate\nwith one another to perform a task in a coordinated manner. When multiple tasks\nare involved, agents can also leverage knowledge from one task to improve\nlearning in other tasks. In this paper, we propose Multi-task Communication\nSkills (MCS), a MADRL with communication method that learns and performs\nmultiple tasks simultaneously, with agents interacting through learnable\ncommunication protocols. MCS employs a Transformer encoder to encode\ntask-specific observations into a shared message space, capturing shared\ncommunication skills among agents. To enhance coordination among agents, we\nintroduce a prediction network that correlates messages with the actions of\nsender agents in each task. We adapt three multi-agent benchmark environments\nto multi-task settings, where the number of agents as well as the observation\nand action spaces vary across tasks. Experimental results demonstrate that MCS\nachieves better performance than multi-task MADRL baselines without\ncommunication, as well as single-task MADRL baselines with and without\ncommunication.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.02949", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2511.02949", "abs": "https://arxiv.org/abs/2511.02949", "authors": ["Zhendong Wang", "Chenyang Meng", "Jun Yang", "Jiayuan Wang", "Yin Li", "Linshan Jiang", "Jin Zhang"], "title": "NF-SecRIS: RIS-Assisted Near-Field Physical Layer Security via Secure Location Modulation", "comment": null, "summary": "The 6G wireless networks impose extremely high requirements on physical layer\nsecure communication. However, the existing solutions usually can only achieve\none-dimensional physical layer security (PLS) in the angle dimension, and\ncannot achieve PLS in the range dimension. In this paper, we propose the\nNF-SecRIS system, the first range-angle-dependent (2D) PLS near-field\ncommunication system based on ultra-large-scale reconfigurable intelligent\nsurface (RIS). We propose the secure location modulation scheme to synthesize\nthe near-field spatial-temporal coding pattern of RIS with extremely low\ncomplexity. It ensures that only legitimate user can receive the raw\nconstellations, while potential eavesdroppers at other ranges or angles can\nonly receive the obfuscated constellations. NF-SecRIS operates without\nrequiring synchronization with either transmitter or receiver. We implement a\nprototype of NF-SecRIS and conduct comprehensive experiments with multiple\nmodulation schemes. The results show that the bit error rate (BER) of\nlegitimate user is below 10^{-4}, while eavesdroppers at other ranges or angles\nsuffer from BER exceeding 40%. It validates the implementation of 2D PLS in\nnear-field communications.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.02891", "categories": ["cs.HC", "cs.SE", "A.1; H.5.2"], "pdf": "https://arxiv.org/pdf/2511.02891", "abs": "https://arxiv.org/abs/2511.02891", "authors": ["Lingyu Zhao", "Yuankai He"], "title": "A Survey of Driver Distraction and Inattention in Popular Commercial Software-Defined Vehicles", "comment": "12 pages, 12 figures, 1 table", "summary": "As the automotive industry embraces software-defined vehicles (SDVs), the\nrole of user interface (UI) design in ensuring driver safety has become\nincreasingly significant. In crashes related to distracted driving, over 90%\ndid not involve cellphone use but were related to UI controls. However, many of\nthe existing UI SDV implementations do not consider Drive Distraction and\nInattention (DDI), which is reflected in many popular commercial vehicles. This\npaper investigates the impact of UI designs on driver distraction and\ninattention within the context of SDVs. Through a survey of popular commercial\nvehicles, we identify UI features that potentially increase cognitive load and\nevaluate design strategies to mitigate these risks. This survey highlights the\nneed for UI designs that balance advanced software functionalities with\ndriver-cognitive ergonomics. Findings aim to provide valuable guidance to\nresearchers and OEMs to contribute to the field of automotive UI, contributing\nto the broader discussion on enhancing vehicular safety in the software-centric\nautomotive era.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.03434", "categories": ["cs.HC", "cs.AI", "cs.MA", "cs.NI", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.03434", "abs": "https://arxiv.org/abs/2511.03434", "authors": ["Botao 'Amber' Hu", "Helena Rong"], "title": "Inter-Agent Trust Models: A Comparative Study of Brief, Claim, Proof, Stake, Reputation and Constraint in Agentic Web Protocol Design-A2A, AP2, ERC-8004, and Beyond", "comment": "Submitted to AAAI 2026 Workshop on Trust and Control in Agentic AI\n  (TrustAgent)", "summary": "As the \"agentic web\" takes shape-billions of AI agents (often LLM-powered)\nautonomously transacting and collaborating-trust shifts from human oversight to\nprotocol design. In 2025, several inter-agent protocols crystallized this\nshift, including Google's Agent-to-Agent (A2A), Agent Payments Protocol (AP2),\nand Ethereum's ERC-8004 \"Trustless Agents,\" yet their underlying trust\nassumptions remain under-examined. This paper presents a comparative study of\ntrust models in inter-agent protocol design: Brief (self- or third-party\nverifiable claims), Claim (self-proclaimed capabilities and identity, e.g.\nAgentCard), Proof (cryptographic verification, including zero-knowledge proofs\nand trusted execution environment attestations), Stake (bonded collateral with\nslashing and insurance), Reputation (crowd feedback and graph-based trust\nsignals), and Constraint (sandboxing and capability bounding). For each, we\nanalyze assumptions, attack surfaces, and design trade-offs, with particular\nemphasis on LLM-specific fragilities-prompt injection,\nsycophancy/nudge-susceptibility, hallucination, deception, and\nmisalignment-that render purely reputational or claim-only approaches brittle.\nOur findings indicate no single mechanism suffices. We argue for\ntrustless-by-default architectures anchored in Proof and Stake to gate\nhigh-impact actions, augmented by Brief for identity and discovery and\nReputation overlays for flexibility and social signals. We comparatively\nevaluate A2A, AP2, ERC-8004 and related historical variations in academic\nresearch under metrics spanning security, privacy, latency/cost, and social\nrobustness (Sybil/collusion/whitewashing resistance). We conclude with hybrid\ntrust model recommendations that mitigate reputation gaming and misinformed LLM\nbehavior, and we distill actionable design guidelines for safer, interoperable,\nand scalable agent economies.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.03119", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2511.03119", "abs": "https://arxiv.org/abs/2511.03119", "authors": ["Seyed Mohamad Ali Tousi", "G. N. DeSouza"], "title": "QAGT-MLP: An Attention-Based Graph Transformer for Small and Large-Scale Quantum Error Mitigation", "comment": null, "summary": "Noisy quantum devices demand error-mitigation techniques to be accurate yet\nsimple and efficient in terms of number of shots and processing time. Many\nestablished approaches (e.g., extrapolation and quasi-probability cancellation)\nimpose substantial execution or calibration overheads, while existing\nlearning-based methods have difficulty scaling to large and deep circuits. In\nthis research, we introduce QAGT-MLP: an attention-based graph transformer\ntailored for small- and large-scale quantum error mitigation (QEM). QAGT-MLP\nencodes each quantum circuit as a graph whose nodes represent gate instances\nand whose edges capture qubit connectivity and causal adjacency. A dual-path\nattention module extracts features around measured qubits at two scales or\ncontexts: 1) graph-wide global structural context; and 2) fine-grained local\nlightcone context. These learned representations are concatenated with\ncircuit-level descriptor features and the circuit noisy expected values, then\nthey are passed to a lightweight MLP to predict the noise-mitigated values. On\nlarge-scale 100-qubit Trotterized 1D Transverse-Field Ising Models -- TFIM\ncircuits -- the proposed QAGT-MLP outperformed state-of-the-art learning\nbaselines in terms of mean error and error variability, demonstrating strong\nvalidity and applicability in real-world QEM scenarios under matched shot\nbudgets. By using attention to fuse global structures with local lightcone\nneighborhoods, QAGT-MLP achieves high mitigation quality without the increasing\nnoise scaling or resource demand required by classical QEM pipelines, while\nstill offering a scalable and practical path to QEM in modern and future\nquantum workloads.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.02979", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02979", "abs": "https://arxiv.org/abs/2511.02979", "authors": ["Esther Sun", "Zichu Wu"], "title": "Systematizing LLM Persona Design: A Four-Quadrant Technical Taxonomy for AI Companion Applications", "comment": "Submitted to Neurips 2025 workshop: LLM Persona Workshop", "summary": "The design and application of LLM-based personas in AI companionship is a\nrapidly expanding but fragmented field, spanning from virtual emotional compan-\nions and game NPCs to embodied functional robots. This diversity in objectives,\nmodality, and technical stacks creates an urgent need for a unified framework.\nTo address this gap, this paper systematizes the field by proposing a\nFour-Quadrant Technical Taxonomy for AI companion applications. The framework\nis structured along two critical axes: Virtual vs. Embodied and Emotional\nCompanionship vs. Functional Augmentation. Quadrant I (Virtual Companionship)\nexplores virtual idols, romantic companions, and story characters, introducing\na four-layer technical framework to analyze their challenges in maintaining\nlong-term emotional consistency. Quadrant II (Functional Virtual Assistants)\nanalyzes AI applica- tions in work, gaming, and mental health, highlighting the\nshift from \"feeling\" to \"thinking and acting\" and pinpointing key technologies\nlike enterprise RAG and on-device inference. Quadrants III & IV (Embodied\nIntelligence) shift from the virtual to the physical world, analyzing home\nrobots and vertical-domain assistants, revealing core challenges in symbol\ngrounding, data privacy, and ethical liability. This taxonomy provides not only\na systematic map for researchers and developers to navigate the complex persona\ndesign space but also a basis for policymakers to identify and address the\nunique risks inherent in different application scenarios.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.03706", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2511.03706", "abs": "https://arxiv.org/abs/2511.03706", "authors": ["Yu-Erh Pan", "Ayesha Siddika Nipu"], "title": "LLM-enhanced Air Quality Monitoring Interface via Model Context Protocol", "comment": "International Symposium on Advanced Electrical and Communication\n  Technologies, ISAECT 2025", "summary": "Air quality monitoring is central to environmental sustainability and public\nhealth, yet traditional systems remain difficult for non-expert users to\ninterpret due to complex visualizations, limited interactivity, and high\ndeployment costs. Recent advances in Large Language Models (LLMs) offer new\nopportunities to make sensor data more accessible, but their tendency to\nproduce hallucinations limits reliability in safety-critical domains. To\naddress these challenges, we present an LLM-enhanced Air Monitoring Interface\n(AMI) that integrates real-time sensor data with a conversational interface via\nthe Model Context Protocol (MCP). Our system grounds LLM outputs in live\nenvironmental data, enabling accurate, context-aware responses while reducing\nhallucination risk. The architecture combines a Django-based backend, a\nresponsive user dashboard, and a secure MCP server that exposes system\nfunctions as discoverable tools, allowing the LLM to act as an active operator\nrather than a passive responder. Expert evaluation demonstrated high factual\naccuracy (4.78), completeness (4.82), and minimal hallucinations (4.84), on a\nscale of 5, supported by inter-rater reliability analysis. These results\nhighlight the potential of combining LLMs with standardized tool protocols to\ncreate reliable, secure, and user-friendly interfaces for real-time\nenvironmental monitoring.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.03117", "categories": ["cs.HC", "H.5.2"], "pdf": "https://arxiv.org/pdf/2511.03117", "abs": "https://arxiv.org/abs/2511.03117", "authors": ["Yibo Meng", "Ruiqi Chen", "Xin Chen", "Zhiming Liu", "Yan Guan"], "title": "Tracing Generative AI in Digital Art: A Longitudinal Study of Chinese Painters' Attitudes, Practices, and Identity Negotiation", "comment": "In Submission", "summary": "This study presents a five-year longitudinal mixed-methods study of 17\nChinese digital painters, examining how their attitudes and practices evolved\nin response to generative AI. Our findings reveal a trajectory from resistance\nand defensiveness, to pragmatic adoption, and ultimately to reflective\nreconstruction, shaped by strong peer pressures and shifting emotional\nexperiences. Persistent concerns around copyright and creative labor highlight\nthe ongoing negotiation of identity and values. This work contributes by\noffering rare longitudinal empirical data, advancing a theoretical lens of\n\"identity and value negotiation,\" and providing design implications for future\nhuman-AI collaborative systems.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.03131", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2511.03131", "abs": "https://arxiv.org/abs/2511.03131", "authors": ["Zeda Xu", "Nikolas Martelaro", "Christopher McComb"], "title": "Ceci N'est Pas un Drone: Investigating the Impact of Design Representation on Design Decision Making When Using GenAI", "comment": null, "summary": "With generative AI-powered design tools, designers and engineers can\nefficiently generate large numbers of design ideas. However, efficient\nexploration of these ideas requires designers to select a smaller group of\npotential solutions for further development. Therefore, the ability to judge\nand evaluate designs is critical for the successful use of generative design\ntools. Different design representation modalities can potentially affect\ndesigners' judgments. This work investigates how different design modalities,\nincluding visual rendering, numerical performance data, and a combination of\nboth, affect designers' design selections from AI-generated design concepts for\nUncrewed Aerial Vehicles. We found that different design modalities do affect\ndesigners' choices. Unexpectedly, we found that providing only numerical design\nperformance data can lead to the best ability to select optimal designs. We\nalso found that participants prefer visually conventional designs with\naxis-symmetry. The findings of this work provide insights into the interaction\nbetween human users and generative design systems.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.03143", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03143", "abs": "https://arxiv.org/abs/2511.03143", "authors": ["Erfan Shayegani", "Jina Suh", "Andy Wilson", "Nagu Rangan", "Javier Hernandez"], "title": "From Measurement to Expertise: Empathetic Expert Adapters for Context-Based Empathy in Conversational AI Agents", "comment": null, "summary": "Empathy is a critical factor in fostering positive user experiences in\nconversational AI. While models can display empathy, it is often generic rather\nthan tailored to specific tasks and contexts. In this work, we introduce a\nnovel framework for developing and evaluating context-specific empathetic large\nlanguage models (LLMs). We first analyze a real-world conversational dataset\nconsisting of 672 multi-turn conversations across 8 tasks, revealing\nsignificant differences in terms of expected and experienced empathy before and\nafter the conversations, respectively. To help minimize this gap, we develop a\nsynthetic multi-turn conversational generation pipeline and steer responses\ntoward our defined empathy patterns based on the context that more closely\nmatches users' expectations. We then train empathetic expert adapters for\ncontext-specific empathy that specialize in varying empathy levels based on the\nrecognized task. Our empirical results demonstrate a significant gap reduction\nof 72.66% between perceived and desired empathy with scores increasing by an\naverage factor of 2.43 as measured by our metrics and reward models.\nAdditionally, our trained empathetic expert adapters demonstrate superior\neffectiveness in preserving empathy patterns throughout conversation turns,\noutperforming system prompts, which tend to dramatically diminish in impact as\nconversations lengthen.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.03174", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.03174", "abs": "https://arxiv.org/abs/2511.03174", "authors": ["Jiawei Zhou", "Lei Zhang", "Mei Li", "Benjamin D Horne", "Munmun De Choudhury"], "title": "AI as We Describe It: How Large Language Models and Their Applications in Health are Represented Across Channels of Public Discourse", "comment": null, "summary": "Representation shapes public attitudes and behaviors. With the arrival and\nrapid adoption of LLMs, the way these systems are introduced will negotiate\nsocietal expectations for their role in high-stakes domains like health. Yet it\nremains unclear whether current narratives present a balanced view. We analyzed\nfive prominent discourse channels (news, research press, YouTube, TikTok, and\nReddit) over a two-year period on lexical style, informational content, and\nsymbolic representation. Discussions were generally positive and episodic, with\npositivity increasing over time. Risk communication was unthorough and often\nreduced to information quality incidents, while explanations of LLMs'\ngenerative nature were rare. Compared with professional outlets, TikTok and\nReddit highlighted wellbeing applications and showed greater variations in tone\nand anthropomorphism but little attention to risks. We discuss implications for\npublic discourse as a diagnostic tool in identifying literacy and governance\ngaps, and for communication and design strategies to support more informed LLM\nengagement.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.03198", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2511.03198", "abs": "https://arxiv.org/abs/2511.03198", "authors": ["Jiawei Zhou", "Amy Z. Chen", "Darshi Shah", "Laura M. Schwab-Reese", "Munmun De Choudhury"], "title": "Large Language Models as Information Sources: Distinctive Characteristics and Types of Low-Quality Information", "comment": null, "summary": "Recent advances in large language models (LLMs) have brought public and\nscholarly attention to their potential in generating low-quality information.\nWhile widely acknowledged as a risk, low-quality information remains a vaguely\ndefined concept, and little is known about how it manifests in LLM outputs or\nhow these outputs differ from those of traditional information sources. In this\nstudy, we focus on two key questions: What types of low-quality information are\nproduced by LLMs, and what makes them distinct than human-generated\ncounterparts? We conducted focus groups with public health professionals and\nindividuals with lived experience in three critical health contexts (vaccines,\nopioid use disorder, and intimate partner violence) where high-quality\ninformation is essential and misinformation, bias, and insensitivity are\nprevalent concerns. We identified a typology of LLM-generated low-quality\ninformation and a set of distinctive LLM characteristics compared to\ntraditional information sources. Our findings show that low-quality information\nextends beyond factual inaccuracies into types such as misprioritization and\nexaggeration, and that LLM affordances fundamentally differs from previous\ntechnologies. This work offers typologies on LLM distinctive characteristics\nand low-quality information types as a starting point for future efforts to\nunderstand LLM-generated low-quality information and mitigate related\ninformational harms. We call for conceptual and methodological discussions of\ninformation quality to move beyond truthfulness, in order to address the\naffordances of emerging technologies and the evolving dynamics of information\nbehaviors.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.03375", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2511.03375", "abs": "https://arxiv.org/abs/2511.03375", "authors": ["Mengyao Guo", "Kexin Nie", "Ze Gao", "Black Sun", "Xueyang Wang", "Jinda Han", "Xingting Wu"], "title": "I Prompt, it Generates, we Negotiate. Exploring Text-Image Intertextuality in Human-AI Co-Creation of Visual Narratives with VLMs", "comment": "38 pages, 23 figures", "summary": "Creating meaningful visual narratives through human-AI collaboration requires\nunderstanding how text-image intertextuality emerges when textual intentions\nmeet AI-generated visuals. We conducted a three-phase qualitative study with 15\nparticipants using GPT-4o to investigate how novices navigate sequential visual\nnarratives. Our findings show that users develop strategies to harness AI's\nsemantic surplus by recognizing meaningful visual content beyond literal\ndescriptions, iteratively refining prompts, and constructing narrative\nsignificance through complementary text-image relationships. We identified four\ndistinct collaboration patterns and, through fsQCA's analysis, discovered three\npathways to successful intertextual collaboration: Educational Collaborator,\nTechnical Expert, and Visual Thinker. However, participants faced challenges,\nincluding cultural representation gaps, visual consistency issues, and\ndifficulties translating narrative concepts into visual prompts. These findings\ncontribute to HCI research by providing an empirical account of\n\\textit{text-image intertextuality} in human-AI co-creation and proposing\ndesign implications for role-based AI assistants that better support iterative,\nhuman-led creative processes in visual storytelling.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.03478", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2511.03478", "abs": "https://arxiv.org/abs/2511.03478", "authors": ["Jeongah Lee", "Ali Sarvghad"], "title": "SVG Decomposition for Enhancing Large Multimodal Models Visualization Comprehension: A Study with Floor Plans", "comment": "10 pages, 2 figures", "summary": "Large multimodal models (LMMs) are increasingly capable of interpreting\nvisualizations, yet they continue to struggle with spatial reasoning. One\nproposed strategy is decomposition, which breaks down complex visualizations\ninto structured components. In this work, we examine the efficacy of scalable\nvector graphics (SVGs) as a decomposition strategy for improving LMMs'\nperformance on floor plans comprehension. Floor plans serve as a valuable\ntestbed because they combine geometry, topology, and semantics, and their\nreliable comprehension has real-world applications, such as accessibility for\nblind and low-vision individuals. We conducted an exploratory study with three\nLMMs (GPT-4o, Claude 3.7 Sonnet, and Llama 3.2 11B Vision Instruct) across 75\nfloor plans. Results show that combining SVG with raster input (SVG+PNG)\nimproves performance on spatial understanding tasks but often hinders spatial\nreasoning, particularly in pathfinding. These findings highlight both the\npromise and limitations of decomposition as a strategy for advancing spatial\nvisualization comprehension.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.03534", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2511.03534", "abs": "https://arxiv.org/abs/2511.03534", "authors": ["Zhaoxin Chang", "Fusang Zhang", "Jie Xiong", "Ziyu Li", "Badii Jouaber", "Daqing Zhang"], "title": "PnPSelect: Plug-and-play IoT Device Selection Using Ultra-wideband Signals", "comment": null, "summary": "In recent years, the number of Internet of Things (IoT) devices in smart\nhomes has rapidly increased. A key challenge affecting user experience is how\nto enable users to efficiently and intuitively select the devices they wish to\ncontrol. This paper proposes PnPSelect, a plug-and-play IoT device selection\nsolution utilizing Ultra-wideband (UWB) technology on commercial devices.\nUnlike previous works, PnPSelect does not require the installation of dedicated\nhardware on each IoT device, thereby reducing deployment costs and\ncomplexities, and achieving true plug-and-play functionality. To enable\nintuitive device selection, we introduce a pointing direction estimation method\nthat utilizes UWB readings from a single anchor to infer the user pointing\ndirection. Additionally, we propose a lightweight device localization method\nthat allows users to register new IoT devices by simply pointing at them from\ntwo distinct positions, eliminating the need for manual measurements. We\nimplement PnPSelect on commercial smartphones and smartwatches and conduct\nextensive evaluations in both controlled laboratory settings and real-world\nenvironments. Our results demonstrate high accuracy, robustness, and\nadaptability, making PnPSelect a practical and scalable solution for\nnext-generation smart home interactions.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.03585", "categories": ["cs.HC", "68T07", "H.5.2; J.5"], "pdf": "https://arxiv.org/pdf/2511.03585", "abs": "https://arxiv.org/abs/2511.03585", "authors": ["Jia Kaixin", "Zhu Kewen", "Deng Huanghuang", "Qiu Yiwu", "Ding Shiying", "Ding Chenyang", "Li Zejian"], "title": "Knowledge Graph for Intelligent Generation of Artistic Image Creation: Constructing a New Annotation Hierarchy", "comment": "24 pages, in Chinese language", "summary": "Our study aims to establish a unified, systematic, and referable knowledge\nframework for the annotation of art image datasets, addressing issues of\nambiguous definitions and inconsistent results caused by the lack of common\nstandards during the annotation process. To achieve this goal, a hierarchical\nand systematic art image knowledge graph was constructed. It was developed\nbased on the composition principles of art images, incorporating the Structured\nTheory of Visual Knowledge proposed by Academician Yunhe Pan in On Visual\nKnowledge-which states that visual knowledge must achieve precise expression of\nspatial forms and dynamic relationships through \"prototype-category\" and\n\"hierarchical structure\". Through in-depth review of Chinese and Western art\ntheories and pioneering integration of the Chinese cultural perspective, this\ngraph took shape. The core visual language of art images was deconstructed by\nthis knowledge graph. Meanwhile, the unique spatial theory and symbolic system\nof Chinese painting were compared with and supplemented by Western art\ntheories. This graph converts qualitative artistic concepts into a clear\nstructured framework. It not only conforms to the cognitive law that \"visual\nknowledge takes precedence over verbal knowledge\" in humans but also provides\nan interpretable and inferential visual knowledge foundation for AI art\ngeneration and cross-cultural art analysis. It ensures the high quality and\nconsistency of annotated data, thus offering key support for art intelligence\nresearch in the AI 2.0 era.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.03673", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2511.03673", "abs": "https://arxiv.org/abs/2511.03673", "authors": ["Shubham Rohal", "Shijia Pan"], "title": "OriFeel: Origami-Inspired Actuation for Force-Based Tactile Feedback on Ambient Surfaces", "comment": null, "summary": "People are constantly in touch with surfaces in their lives, such as a sofa,\narmrest, and table, making them natural tactile interfaces. Despite the recent\nadvancements in shape-changing surfaces, current available solutions are often\nchallenging to retrofit into ambient surfaces due to their bulky form factor or\nhigh power requirements. We present \\name, a foldable structure-enabled tactile\nfeedback mechanism that leverages the structural properties of Miura-Ori fold\nto enable on-surface force actuation. The foldable structure allows the\nsurfaces to provide perpendicular force via lateral actuation, resulting in a\nslim form factor that can be actuated via cable-based design using a servo\nmotor. We evaluate the system with a real-world prototype and a user study. The\nuser study shows that users can effectively distinguish multiple intensity\nlevels.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
