{"id": "2602.11740", "categories": ["cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.11740", "abs": "https://arxiv.org/abs/2602.11740", "authors": ["Ayhan Alp Aydeniz", "Robert Loftin", "Kagan Tumer"], "title": "Counterfactual Conditional Likelihood Rewards for Multiagent Exploration", "comment": "9 pages, 5 figures", "summary": "Efficient exploration is critical for multiagent systems to discover coordinated strategies, particularly in open-ended domains such as search and rescue or planetary surveying. However, when exploration is encouraged only at the individual agent level, it often leads to redundancy, as agents act without awareness of how their teammates are exploring. In this work, we introduce Counterfactual Conditional Likelihood (CCL) rewards, which score each agent's exploration by isolating its unique contribution to team exploration. Unlike prior methods that reward agents solely for the novelty of their individual observations, CCL emphasizes observations that are informative with respect to the joint exploration of the team. Experiments in continuous multiagent domains show that CCL rewards accelerate learning for domains with sparse team rewards, where most joint actions yield zero rewards, and are particularly effective in tasks that require tight coordination among agents."}
{"id": "2602.11754", "categories": ["cs.MA", "cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2602.11754", "abs": "https://arxiv.org/abs/2602.11754", "authors": ["Keita Nishimoto", "Kimitaka Asatani", "Ichiro Sakata"], "title": "Cooperation Breakdown in LLM Agents Under Communication Delays", "comment": null, "summary": "LLM-based multi-agent systems (LLM-MAS), in which autonomous AI agents cooperate to solve tasks, are gaining increasing attention. For such systems to be deployed in society, agents must be able to establish cooperation and coordination under real-world computational and communication constraints. We propose the FLCOA framework (Five Layers for Cooperation/Coordination among Autonomous Agents) to conceptualize how cooperation and coordination emerge in groups of autonomous agents, and highlight that the influence of lower-layer factors - especially computational and communication resources - has been largely overlooked. To examine the effect of communication delay, we introduce a Continuous Prisoner's Dilemma with Communication Delay and conduct simulations with LLM-based agents. As delay increases, agents begin to exploit slower responses even without explicit instructions. Interestingly, excessive delay reduces cycles of exploitation, yielding a U-shaped relationship between delay magnitude and mutual cooperation. These results suggest that fostering cooperation requires attention not only to high-level institutional design but also to lower-layer factors such as communication delay and resource allocation, pointing to new directions for MAS research."}
{"id": "2602.11977", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2602.11977", "abs": "https://arxiv.org/abs/2602.11977", "authors": ["Michael Otte", "Roderich Groß"], "title": "Multi-Defender Single-Attacker Perimeter Defense Game on a Cylinder: Special Case in which the Attacker Starts at the Boundary", "comment": "4 pages, 3 figures", "summary": "We describe a multi-agent perimeter defense game played on a cylinder. A team of n slow-moving defenders must prevent a single fast-moving attacker from crossing the boundary of a defensive perimeter. We describe the conditions necessary for the attacker to win in the special case that the intruder starts close to the boundary and in a region that is currently defended."}
{"id": "2602.12102", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2602.12102", "abs": "https://arxiv.org/abs/2602.12102", "authors": ["Zhijian Gao", "Shuxin Li", "Bo An"], "title": "DEpiABS: Differentiable Epidemic Agent-Based Simulator", "comment": "17 pages, 9 figures, to be published in AAMAS 2026", "summary": "The COVID-19 pandemic highlighted the limitations of existing epidemic simulation tools. These tools provide information that guides non-pharmaceutical interventions (NPIs), yet many struggle to capture complex dynamics while remaining computationally practical and interpretable. We introduce DEpiABS, a scalable, differentiable agent-based model (DABM) that balances mechanistic detail, computational efficiency and interpretability. DEpiABS captures individual-level heterogeneity in health status, behaviour, and resource constraints, while also modelling epidemic processes like viral mutation and reinfection dynamics. The model is fully differentiable, enabling fast simulation and gradient-based parameter calibration. Building on this foundation, we introduce a z-score-based scaling method that maps small-scale simulations to any real-world population sizes with negligible loss in output granularity, reducing the computational burden when modelling large populations. We validate DEpiABS through sensitivity analysis and calibration to COVID-19 and flu data from ten regions of varying scales. Compared to the baseline, DEpiABS is more detailed, fully interpretable, and has reduced the average normal deviation in forecasting from 0.97 to 0.92 on COVID-19 mortality data and from 0.41 to 0.32 on influenza-like-illness data. Critically, these improvements are achieved without relying on auxiliary data, making DEpiABS a reliable, generalisable, and data-efficient framework for future epidemic response modelling."}
{"id": "2602.11517", "categories": ["cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.11517", "abs": "https://arxiv.org/abs/2602.11517", "authors": ["Renan Favero", "Lily Elefteriadou"], "title": "Calibration and Evaluation of Car-Following Models for Autonomous Shuttles Using a Novel Multi-Criteria Framework", "comment": null, "summary": "Autonomous shuttles (AS) are fully autonomous transit vehicles with operating characteristics distinct from conventional autonomous vehicles (AV). Developing dedicated car-following models for AS is critical to understanding their traffic impacts; however, few studies have calibrated such models with field data. More advanced machine learning (ML) techniques have not yet been applied to AS trajectories, leaving the potential of ML for capturing AS dynamics unexplored and constraining the development of dedicated AS models. Furthermore, there is a lack of a unified framework for systematically evaluating and comparing the performance of car-following models to replicate real trajectories. Existing car-following studies often rely on disparate metrics, which limit reproducibility and performance comparability.\n  This study addresses these gaps through two main contributions: (1) the calibration of a diverse set of car-following models using real-world AS trajectory data, including eight machine learning algorithms and two physics-based models; and (2) the introduction of a multi-criteria evaluation framework that integrates measures of prediction accuracy, trajectory stability, and statistical similarity, which provides a generalizable methodology for a systematic assessment of car-following models.\n  Results indicated that the proposed calibrated XGBoost model achieved the best overall performance. Sequential model type, such as LSTM and CNN, captured long-term positional stability but were less responsive to short-term dynamics. LSTM and CNN captured long-term positional stability but were less responsive to short-term dynamics. Traditional models (IDM, ACC) and kernel methods showed lower accuracy and stability than most ML models tested."}
{"id": "2602.11158", "categories": ["cs.HC", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.11158", "abs": "https://arxiv.org/abs/2602.11158", "authors": ["Juliana Gerard", "Morgan Macleod", "Kelly Norwood", "Aisling Reid", "Muskaan Singh"], "title": "Methodological Variation in Studying Staff and Student Perceptions of AI", "comment": "29 pages, 3 figures", "summary": "In this paper, we compare methodological approaches for comparing student and staff perceptions, and ask: how much do these measures vary across different approaches? We focus on the case of AI perceptions, which are generally assessed via a single quantitative or qualitative measure, or with a mixed methods approach that compares two distinct data sources - e.g. a quantitative questionnaire with qualitative comments. To compare different approaches, we collect two forms of qualitative data: standalone comments and structured focus groups. We conduct two analyses for each data source: with a sentiment and stance analysis, we measure overall negativity/positivity of the comments and focus group conversations, respectively. Meanwhile, word clouds from the comments and a thematic analysis of the focus groups provide further detail on the content of this qualitative data - particularly the thematic analysis, which includes both similarities and differences between students and staff. We show that different analyses can produce different results - for a single data source. This variation stems from the construct being evaluated - an overall measure of positivity/negativity can produce a different picture from more detailed content-based analyses. We discuss the implications of this variation for institutional contexts, and for the comparisons from previous studies."}
{"id": "2602.11433", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2602.11433", "abs": "https://arxiv.org/abs/2602.11433", "authors": ["Pengfei Wang", "Jian Liu", "Qiujie Dong", "Shiqing Xin", "Yuanfeng Zhou", "Changhe Tu", "Caiming Zhang", "Wenping Wang"], "title": "Filmsticking++: Rapid Film Sticking for Explicit Surface Reconstruction", "comment": "15 pages, 15 figures", "summary": "Explicit surface reconstruction aims to generate a surface mesh that exactly interpolates a given point cloud. This requirement is crucial when the point cloud must lie non-negotiably on the final surface to preserve sharp features and fine geometric details. However, the task becomes substantially challenging with low-quality point clouds, due to inherent reconstruction ambiguities compounded by combinatorial complexity. A previous method using filmsticking technique by iteratively compute restricted Voronoi diagram to address these issues, ensures to produce a watertight manifold, setting a new benchmark as the state-of-the-art (SOTA) technique. Unfortunately, RVD-based filmsticking is inability to interpolate all points in the case of deep internal cavities, resulting in very likely is the generation of faulty topology. The cause of this issue is that RVD-based filmsticking has inherent limitations due to Euclidean distance metrics. In this paper, we extend the filmsticking technique, named Filmsticking++. Filmsticking++ reconstructing an explicit surface from points without normals. On one hand, Filmsticking++ break through the inherent limitations of Euclidean distance by employing a weighted-distance-based Restricted Power Diagram, which guarantees that all points are interpolated. On the other hand, we observe that as the guiding surface increasingly approximates the target shape, the external medial axis is gradually expelled outside the guiding surface. Building on this observation, we propose placing virtual sites inside the guiding surface to accelerate the expulsion of the external medial axis from its interior. To summarize, contrary to the SOTA method, Filmsticking++ demonstrates multiple benefits, including decreases computational cost, improved robustness and scalability."}
{"id": "2602.12243", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2602.12243", "abs": "https://arxiv.org/abs/2602.12243", "authors": ["Sanket A. Salunkhe", "George P. Kontoudis"], "title": "Federated Gaussian Process Learning via Pseudo-Representations for Large-Scale Multi-Robot Systems", "comment": "Accepted at 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026)", "summary": "Multi-robot systems require scalable and federated methods to model complex environments under computational and communication constraints. Gaussian Processes (GPs) offer robust probabilistic modeling, but suffer from cubic computational complexity, limiting their applicability in large-scale deployments. To address this challenge, we introduce the pxpGP, a novel distributed GP framework tailored for both centralized and decentralized large-scale multi-robot networks. Our approach leverages sparse variational inference to generate a local compact pseudo-representation. We introduce a sparse variational optimization scheme that bounds local pseudo-datasets and formulate a global scaled proximal-inexact consensus alternating direction method of multipliers (ADMM) with adaptive parameter updates and warm-start initialization. Experiments on synthetic and real-world datasets demonstrate that pxpGP and its decentralized variant, dec-pxpGP, outperform existing distributed GP methods in hyperparameter estimation and prediction accuracy, particularly in large-scale networks."}
{"id": "2602.11710", "categories": ["cs.HC", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.11710", "abs": "https://arxiv.org/abs/2602.11710", "authors": ["Zhidian Lin", "Allison Jing", "Ziyuan Qu", "Fabio Zambetta", "Ryan M. Kelly"], "title": "Mapping the Landscape of Affective Extended Reality: A Scoping Review of Biodata-Driven Systems for Understanding and Sharing Emotions", "comment": "30 pages, 18 figures, 8 tables", "summary": "This paper introduces the notion of affective extended reality (XR) to characterise XR systems that use biodata to enable understanding of emotions. The HCI literature contains many such systems, but they have not yet been mapped into a coherent whole. To address this, we conducted a scoping review of 82 papers that explore the nexus of biodata, emotions, and XR. We analyse the technologies used in these systems, the interaction techniques employed, and the methods used to evaluate their effectiveness. Through our analysis, we contribute a mapping of the current landscape of affective XR, revealing diversity in the goals for enabling emotion sharing. We demonstrate how HCI researchers have explored the design of the interaction flows in XR biofeedback systems, highlighting key design dimensions and challenges in understanding emotions. We discuss underused approaches for emotion sharing and highlight opportunities for future research on affective XR."}
{"id": "2602.11160", "categories": ["cs.HC", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.11160", "abs": "https://arxiv.org/abs/2602.11160", "authors": ["Alexanne Worm", "Florian Marchal", "Sylvain Castagnos"], "title": "BIRD: A Museum Open Dataset Combining Behavior Patterns and Identity Types to Better Model Visitors' Experience", "comment": null, "summary": "Lack of data is a recurring problem in Artificial Intelligence, as it is essential for training and validating models. This is particularly true in the field of cultural heritage, where the number of open datasets is relatively limited and where the data collected does not always allow for holistic modeling of visitors' experience due to the fact that data are ad hoc (i.e. restricted to the sole characteristics required for the evaluation of a specific model). To overcome this lack, we conducted a study between February and March 2019 aimed at obtaining comprehensive and detailed information about visitors, their visit experience and their feedback. We equipped 51 participants with eye-tracking glasses, leaving them free to explore the 3 floors of the museum for an average of 57 minutes, and to discover an exhibition of more than 400 artworks. On this basis, we built an open dataset combining contextual data (demographic data, preferences, visiting habits, motivations, social context. . . ), behavioral data (spatiotemporal trajectories, gaze data) and feedback (satisfaction, fatigue, liked artworks, verbatim. . . ). Our analysis made it possible to re-enact visitor identities combining the majority of characteristics found in the literature and to reproduce the Veron and Levasseur profiles. This dataset will ultimately make it possible to improve the quality of recommended paths in museums by personalizing the number of points of interest (POIs), the time spent at these different POIs, and the amount of information to be provided to each visitor based on their level of interest."}
{"id": "2602.11577", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2602.11577", "abs": "https://arxiv.org/abs/2602.11577", "authors": ["Chang Luo", "Nobuyuki Umetani"], "title": "LeafFit: Plant Assets Creation from 3D Gaussian Splatting", "comment": "Our source code is publicly available at https://github.com/netbeifeng/leaf_fit", "summary": "We propose LeafFit, a pipeline that converts 3D Gaussian Splatting (3DGS) of individual plants into editable, instanced mesh assets. While 3DGS faithfully captures complex foliage, its high memory footprint and lack of mesh topology make it incompatible with traditional game production workflows. We address this by leveraging the repetition of leaf shapes; our method segments leaves from the unstructured 3DGS, with optional user interaction included as a fallback. A representative leaf group is selected and converted into a thin, sharp mesh to serve as a template; this template is then fitted to all other leaves via differentiable Moving Least Squares (MLS) deformation. At runtime, the deformation is evaluated efficiently on-the-fly using a vertex shader to minimize storage requirements. Experiments demonstrate that LeafFit achieves higher segmentation quality and deformation accuracy than recent baselines while significantly reducing data size and enabling parameter-level editing."}
{"id": "2602.11161", "categories": ["cs.HC", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.11161", "abs": "https://arxiv.org/abs/2602.11161", "authors": ["Svetlana Churina", "Kokil Jaidka", "Anab Maulana Barik", "Harshit Aneja", "Cai Yang", "Wynne Hsu", "Mong Li Lee"], "title": "Althea: Human-AI Collaboration for Fact-Checking and Critical Reasoning", "comment": null, "summary": "The web's information ecosystem demands fact-checking systems that are both scalable and epistemically trustworthy. Automated approaches offer efficiency but often lack transparency, while human verification remains slow and inconsistent. We introduce Althea, a retrieval-augmented system that integrates question generation, evidence retrieval, and structured reasoning to support user-driven evaluation of online claims. On the AVeriTeC benchmark, Althea achieves a Macro-F1 of 0.44, outperforming standard verification pipelines and improving discrimination between supported and refuted claims. We further evaluate Althea through a controlled user study and a longitudinal survey experiment (N = 642), comparing three interaction modes that vary in the degree of scaffolding: an Exploratory mode with guided reasoning, a Summary mode providing synthesized verdicts, and a Self-search mode that offers procedural guidance without algorithmic intervention. Results show that guided interaction produces the strongest immediate gains in accuracy and confidence, while self-directed search yields the most persistent improvements over time. This pattern suggests that performance gains are not driven solely by effort or exposure, but by how cognitive work is structured and internalized."}
{"id": "2602.11638", "categories": ["cs.GR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.11638", "abs": "https://arxiv.org/abs/2602.11638", "authors": ["Hao Qin", "Yukai Sun", "Meng Wang", "Ming Kong", "Mengxu Lu", "Qiang Zhu"], "title": "Variation-aware Flexible 3D Gaussian Editing", "comment": null, "summary": "Indirect editing methods for 3D Gaussian Splatting (3DGS) have recently witnessed significant advancements. These approaches operate by first applying edits in the rendered 2D space and subsequently projecting the modifications back into 3D. However, this paradigm inevitably introduces cross-view inconsistencies and constrains both the flexibility and efficiency of the editing process. To address these challenges, we present VF-Editor, which enables native editing of Gaussian primitives by predicting attribute variations in a feedforward manner. To accurately and efficiently estimate these variations, we design a novel variation predictor distilled from 2D editing knowledge. The predictor encodes the input to generate a variation field and employs two learnable, parallel decoding functions to iteratively infer attribute changes for each 3D Gaussian. Thanks to its unified design, VF-Editor can seamlessly distill editing knowledge from diverse 2D editors and strategies into a single predictor, allowing for flexible and effective knowledge transfer into the 3D domain. Extensive experiments on both public and private datasets reveal the inherent limitations of indirect editing pipelines and validate the effectiveness and flexibility of our approach."}
{"id": "2602.11230", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.11230", "abs": "https://arxiv.org/abs/2602.11230", "authors": ["Jaime Banks", "Jon Stromer-Galley", "Samiksha Singh", "Collin Capano"], "title": "DiSCoKit: An Open-Source Toolkit for Deploying Live LLM Experiences in Survey Research", "comment": null, "summary": "Advancing social-scientific research of human-AI interaction dynamics and outcomes often requires researchers to deliver experiences with live large-language models (LLMs) to participants through online survey platforms. However, technical and practical challenges (from logging chat data to manipulating AI behaviors for experimental designs) often inhibit survey-based deployment of AI stimuli. We developed DiSCoKit--an open-source toolkit for deploying live LLM experiences (e.g., ones based on models delivered through Microsoft Azure portal) through JavaScript-enabled survey platforms (e.g., Qualtrics). This paper introduces that toolkit, explaining its scientific impetus, describes its architecture and operation, as well as its deployment possibilities and limitations."}
{"id": "2602.11693", "categories": ["cs.GR", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.11693", "abs": "https://arxiv.org/abs/2602.11693", "authors": ["Zehao Xia", "Yiqun Wang", "Zhengda Lu", "Kai Liu", "Jun Xiao", "Peter Wonka"], "title": "OMEGA-Avatar: One-shot Modeling of 360° Gaussian Avatars", "comment": "Project page: https://omega-avatar.github.io/OMEGA-Avatar/", "summary": "Creating high-fidelity, animatable 3D avatars from a single image remains a formidable challenge. We identified three desirable attributes of avatar generation: 1) the method should be feed-forward, 2) model a 360° full-head, and 3) should be animation-ready. However, current work addresses only two of the three points simultaneously. To address these limitations, we propose OMEGA-Avatar, the first feed-forward framework that simultaneously generates a generalizable, 360°-complete, and animatable 3D Gaussian head from a single image. Starting from a feed-forward and animatable framework, we address the 360° full-head avatar generation problem with two novel components. First, to overcome poor hair modeling in full-head avatar generation, we introduce a semantic-aware mesh deformation module that integrates multi-view normals to optimize a FLAME head with hair while preserving its topology structure. Second, to enable effective feed-forward decoding of full-head features, we propose a multi-view feature splatting module that constructs a shared canonical UV representation from features across multiple views through differentiable bilinear splatting, hierarchical UV mapping, and visibility-aware fusion. This approach preserves both global structural coherence and local high-frequency details across all viewpoints, ensuring 360° consistency without per-instance optimization. Extensive experiments demonstrate that OMEGA-Avatar achieves state-of-the-art performance, significantly outperforming existing baselines in 360° full-head completeness while robustly preserving identity across different viewpoints."}
{"id": "2602.11311", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.11311", "abs": "https://arxiv.org/abs/2602.11311", "authors": ["Caitlin Morris", "Pattie Maes"], "title": "Same Feedback, Different Source: How AI vs. Human Feedback Shapes Learner Engagement", "comment": "7 pages, 5 figures", "summary": "When learners receive feedback, what they believe about its source may shape how they engage with it. As AI is used alongside human instructors, understanding these attribution effects is essential for designing effective hybrid AI-human educational systems. We designed a creative coding interface that isolates source attribution while controlling for content: all participants receive identical LLM-generated feedback, but half see it attributed to AI and half to a human teaching assistant (TA). We found two key results. First, perceived feedback source affected engagement: learners in the TA condition spent significantly more time and effort (d = 0.88-1.56) despite receiving identical feedback. Second, perceptions differed: AI-attributed feedback ratings were predicted by prior trust in AI (r = 0.85), while TA-attributed ratings were predicted by perceived genuineness (r = 0.65). These findings suggest that feedback source shapes both engagement and evaluation, with implications for hybrid educational system design."}
{"id": "2602.12105", "categories": ["cs.GR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.12105", "abs": "https://arxiv.org/abs/2602.12105", "authors": ["Ana Dodik", "Ahmed H. Mahmoud", "Justin Solomon"], "title": "Iskra: A System for Inverse Geometry Processing", "comment": null, "summary": "We propose a system for differentiating through solutions to geometry processing problems. Our system differentiates a broad class of geometric algorithms, exploiting existing fast problem-specific schemes common to geometry processing, including local-global and ADMM solvers. It is compatible with machine learning frameworks, opening doors to new classes of inverse geometry processing applications. We marry the scatter-gather approach to mesh processing with tensor-based workflows and rely on the adjoint method applied to user-specified imperative code to generate an efficient backward pass behind the scenes. We demonstrate our approach by differentiating through mean curvature flow, spectral conformal parameterization, geodesic distance computation, and as-rigid-as-possible deformation, examining usability and performance on these applications. Our system allows practitioners to differentiate through existing geometry processing algorithms without needing to reformulate them, resulting in low implementation effort, fast runtimes, and lower memory requirements than differentiable optimization tools not tailored to geometry processing."}
{"id": "2602.11342", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.11342", "abs": "https://arxiv.org/abs/2602.11342", "authors": ["Qiaosi Wang", "Jini Kim", "Avanita Sharma", "Alicia", "Lee", "Jodi Forlizzi", "Hong Shen"], "title": "Situated, Dynamic, and Subjective: Envisioning the Design of Theory-of-Mind-Enabled Everyday AI with Industry Practitioners", "comment": "16 pages, preprint for ACM CHI 2026 Conference", "summary": "Theory of Mind (ToM) -- the ability to infer what others are thinking (e.g., intentions) from observable cues -- is traditionally considered fundamental to human social interactions. This has sparked growing efforts in building and benchmarking AI's ToM capability, yet little is known about how such capability could translate into the design and experience of everyday user-facing AI products and services. We conducted 13 co-design sessions with 26 U.S.-based AI practitioners to envision, reflect, and distill design recommendations for ToM-enabled everyday AI products and services that are both future-looking and grounded in the realities of AI design and development practices. Analysis revealed three interrelated design recommendations: ToM-enabled AI should 1) be situated in the social context that shape users' mental states, 2) be responsive to the dynamic nature of mental states, and 3) be attuned to subjective individual differences. We surface design tensions within each recommendation that reveal a broader gap between practitioners' envisioned futures of ToM-enabled AI and the realities of current AI design and development practices. These findings point toward the need to move beyond static, inference-driven approach to ToM and toward designing ToM as a pervasive capability that supports continuous human-AI interaction loops."}
{"id": "2602.11367", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.11367", "abs": "https://arxiv.org/abs/2602.11367", "authors": ["Matthew Prock", "Ziv Epstein", "Hope Schroeder", "Amy Smith", "Cassandra Lee", "Vana Goblot", "Farnaz Jahanbakhsh"], "title": "Interpretive Cultures: Resonance, randomness, and negotiated meaning for AI-assisted tarot divination", "comment": null, "summary": "While generative AI tools are increasingly adopted for creative and analytical tasks, their role in interpretive practices, where meaning is subjective, plural, and non-causal, remains poorly understood. This paper examines AI-assisted tarot reading, a divinatory practice in which users pose a query, draw cards through a randomized process, and ask AI systems to interpret the resulting symbols. Drawing on interviews with tarot practitioners and Hartmut Rosa's Theory of Resonance, we investigate how users seek, negotiate, and evaluate resonant interpretations in a context where no causal relationship exists between the query and the data being interpreted. We identify distinct ways practitioners incorporate AI into their interpretive workflows, including using AI to navigate uncertainty and self-doubt, explore alternative perspectives, and streamline or extend existing divinatory practices. Based on these findings, we offer design recommendations for AI systems that support interpretive meaning-making without collapsing ambiguity or foreclosing user agency."}
{"id": "2602.11483", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.11483", "abs": "https://arxiv.org/abs/2602.11483", "authors": ["Stephan Vonschallen", "Friederike Eyssel", "Theresa Schmiedel"], "title": "Understanding Persuasive Interactions between Generative Social Agents and Humans: The Knowledge-based Persuasion Model (KPM)", "comment": null, "summary": "Generative social agents (GSAs) use artificial intelligence to autonomously communicate with human users in a natural and adaptive manner. Currently, there is a lack of theorizing regarding interactions with GSAs, and likewise, few guidelines exist for studying how they influence user attitudes and behaviors. Consequently, we propose the Knowledge-based Persuasion Model (KPM) as a novel theoretical framework. According to the KPM, a GSA's self, user, and context-related knowledge drives its persuasive behavior, which in turn shapes the attitudes and behaviors of a responding human user. By synthesizing existing research, the model offers a structured approach to studying interactions with GSAs, supporting the development of agents that motivate rather than manipulate humans. Accordingly, the KPM encourages the integration of responsible GSAs that adhere to social norms and ethical standards with the goal of increasing user wellbeing. Implications of the KPM for research and application domains such as healthcare and education are discussed."}
{"id": "2602.11492", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.11492", "abs": "https://arxiv.org/abs/2602.11492", "authors": ["Ryota Takamido", "Chiharu Suzuki", "Hiroki Nakamoto"], "title": "Data-driven modelling of low-dimensional dynamical structures underlying complex full-body human movement", "comment": null, "summary": "One of the central challenges in the study of human motor control and learning is the degrees-of-freedom problem. Although the dynamical systems approach (DSA) has provided valuable insights into addressing this issue, its application has largely been confined to cyclic or simplified motor movements. To overcome this limitation, the present study employs neural ordinary differential equations (NODEs) to model the time evolution of non-cyclic full-body movements as a low-dimensional latent dynamical system. Given the temporal complexity full-body kinematic chains, baseball pitching was selected as a representative target movement to examine whether DSA could be extended to more complex, ecologically valid human movements. Results of the verification experiment demonstrated that the time evolution of a complex pitching motion could be accurately predicted (R^2 > 0.45) using the NODE-based dynamical model. Notably, approximately 50% of the variance in the latter half of the pitching motion was explained using only the initial ~8% of the temporal sequence, underscoring how subsequent movement evolves from initial conditions according to ODE-defined dynamics in latent space. These findings indicate the potential to extend the DSA to more complex and ecologically valid forms of human movement."}
{"id": "2602.11507", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.11507", "abs": "https://arxiv.org/abs/2602.11507", "authors": ["Ryuji Matsuo", "Hailong Liu", "Toshihiro Hiraoka", "Takahiro Wada"], "title": "An Educational Human Machine Interface Providing Request-to-Intervene Trigger and Reason Explanation for Enhancing the Driver's Comprehension of ADS's System Limitations", "comment": null, "summary": "Level 3 automated driving systems (ADS) have attracted significant attention and are being commercialized. A level 3 ADS prompts the driver to take control by issuing a request to intervene (RtI) when its operational design domains (ODD) are exceeded. However, complex traffic situations can cause drivers to perceive multiple potential triggers of RtI simultaneously, causing hesitation or confusion during take-over. Therefore, drivers need to clearly understand the ADS's system limitations to ensure safe take-over. This study proposes a voice-based educational human machine interface~(HMI) for providing RtI trigger cues and reason to help drivers understand ADS's system limitations. The results of a between-group experiment using a driving simulator showed that incorporating effective trigger cues and reason into the RtI was related to improved driver comprehension of the ADS's system limitations. Moreover, most participants, instructed via the proposed method, could proactively take over control of the ADS in cases where RtI fails; meanwhile, their number of collisions was lower compared with the other RtI HMI conditions. Therefore, using the proposed method to continually enhance the driver's understanding of the system limitations of ADS through the proposed method is associated with safer and more effective real-time interactions with ADS."}
{"id": "2602.11522", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.11522", "abs": "https://arxiv.org/abs/2602.11522", "authors": ["Dennis Kim", "Roya Daneshi", "Bruce Draper", "Sarath Sreedharan"], "title": "Implications of AI Involvement for Trust in Expert Advisory Workflows Under Epistemic Dependence", "comment": null, "summary": "The increasing integration of AI-powered tools into expert workflows, such as medicine, law, and finance, raises a critical question: how does AI involvement influence a user's trust in the human expert, the AI system, and their combination? To investigate this, we conducted a user study (N=77) featuring a simulated course-planning task. We compared various conditions that differed in both the presence of AI and the specific mode of human-AI collaboration. Our results indicate that while the advisor's ability to create a correct schedule is important, the user's perception of expertise and trust is also influenced by how the expert utilized the AI assistant. These findings raise important considerations for the design of human-AI hybrid teams, particularly when the adoption of recommendations depends on the end-user's perception of the recommender's expertise."}
{"id": "2602.11567", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.11567", "abs": "https://arxiv.org/abs/2602.11567", "authors": ["Chang Liu", "Qinyi Zhou", "Xinjie Shen", "Xingyu Bruce Liu", "Tongshuang Wu", "Xiang 'Anthony' Chen"], "title": "Behavioral Indicators of Overreliance During Interaction with Conversational Language Models", "comment": "conditionally accepted by ACM CHI 2026", "summary": "LLMs are now embedded in a wide range of everyday scenarios. However, their inherent hallucinations risk hiding misinformation in fluent responses, raising concerns about overreliance on AI. Detecting overreliance is challenging, as it often arises in complex, dynamic contexts and cannot be easily captured by post-hoc task outcomes. In this work, we aim to investigate how users' behavioral patterns correlate with overreliance. We collected interaction logs from 77 participants working with an LLM injected plausible misinformation across three real-world tasks and we assessed overreliance by whether participants detected and corrected these errors. By semantically encoding and clustering segments of user interactions, we identified five behavioral patterns linked to overreliance: users with low overreliance show careful task comprehension and fine-grained navigation; users with high overreliance show frequent copy-paste, skipping initial comprehension, repeated LLM references, coarse locating, and accepting misinformation despite hesitation. We discuss design implications for mitigation."}
{"id": "2602.11663", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.11663", "abs": "https://arxiv.org/abs/2602.11663", "authors": ["Yifan Zhao", "Yuxin Fang", "Yihuan Chen", "RAY LC"], "title": "\"I Was Told to Come Back and Share This\": Social Media-Based Near-Death Experience Disclosures as Expressions of Spiritual Beliefs", "comment": "19 pages, 5 figures, CHI 2026 full paper", "summary": "People who experienced near-death events often turn to personal expression as a way of processing trauma and articulating beliefs. While scholars have examined how individuals share near-death experiences (NDEs), limited research has explored how these narratives are communicated collaboratively on today's social media platforms. We analyzed 200 randomly sampled TikTok videos tagged with #nde and related hashtags. Content analysis revealed that individuals often use NDE narratives to articulate personal meaning, with spiritual and religious themes appearing in the majority of posts and serving as a means of exploring and making sense of personal spiritual perspectives. Consistent with this, analyses of comment sections reveal that videos containing spiritual themes tend to attract more engagement and foster deeper conversations around faith and meaning. Our findings offer insights into how online platforms facilitate community-level engagement with spirituality, and suggest implications for design of spaces that support shared expression and connection in specialized communities."}
{"id": "2602.11710", "categories": ["cs.HC", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.11710", "abs": "https://arxiv.org/abs/2602.11710", "authors": ["Zhidian Lin", "Allison Jing", "Ziyuan Qu", "Fabio Zambetta", "Ryan M. Kelly"], "title": "Mapping the Landscape of Affective Extended Reality: A Scoping Review of Biodata-Driven Systems for Understanding and Sharing Emotions", "comment": "30 pages, 18 figures, 8 tables", "summary": "This paper introduces the notion of affective extended reality (XR) to characterise XR systems that use biodata to enable understanding of emotions. The HCI literature contains many such systems, but they have not yet been mapped into a coherent whole. To address this, we conducted a scoping review of 82 papers that explore the nexus of biodata, emotions, and XR. We analyse the technologies used in these systems, the interaction techniques employed, and the methods used to evaluate their effectiveness. Through our analysis, we contribute a mapping of the current landscape of affective XR, revealing diversity in the goals for enabling emotion sharing. We demonstrate how HCI researchers have explored the design of the interaction flows in XR biofeedback systems, highlighting key design dimensions and challenges in understanding emotions. We discuss underused approaches for emotion sharing and highlight opportunities for future research on affective XR."}
{"id": "2602.11753", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.11753", "abs": "https://arxiv.org/abs/2602.11753", "authors": ["Danqing Shi"], "title": "Building Intelligent User Interfaces for Human-AI Alignment", "comment": null, "summary": "Aligning AI systems with human values fundamentally relies on effective human feedback. While significant research has addressed training algorithms, the role of user interface is often overlooked and only treated as an implementation detail rather than a critical factor of alignment. This paper addresses this gap by introducing a reference model that offers a systematic framework for analyzing where and how user interface contributions can improve human-AI alignment. The structured taxonomy of the reference model is demonstrated through two case studies and a preliminary investigation featuring six user interfaces. This work highlights opportunities to advance alignment through human-computer interaction."}
{"id": "2602.11775", "categories": ["cs.HC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.11775", "abs": "https://arxiv.org/abs/2602.11775", "authors": ["Mersedeh Sadeghi", "Simon Scholz", "Max Unterbusch", "Andreas Vogelsang"], "title": "V-SHiNE: A Virtual Smart Home Framework for Explainability Evaluation", "comment": null, "summary": "Explanations are essential for helping users interpret and trust autonomous smart-home decisions, yet evaluating their quality and impact remains methodologically difficult in this domain. V-SHiNE addresses this gap: a browser-based smarthome simulation framework for scalable and realistic assessment of explanations. It allows researchers to configure environments, simulate behaviors, and plug in custom explanation engines, with flexible delivery modes and rich interaction logging. A study with 159 participants demonstrates its feasibility. V-SHiNE provides a lightweight, reproducible platform for advancing user-centered evaluation of explainable intelligent systems"}
{"id": "2602.11855", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.11855", "abs": "https://arxiv.org/abs/2602.11855", "authors": ["Ayato Kitadai", "Takumi Ito", "Yumiko Nagoh", "Hiroki Takahashi", "Masanori Fujita", "Sangjic Lee", "Fumiaki Miyahara", "Tetsu Natsume", "Nariaki Nishino"], "title": "Decision Support System for Technology Opportunity Discovery: An Application of the Schwartz Theory of Basic Values", "comment": "24 pages, 5 figures", "summary": "Discovering technology opportunities (TOD) remains a critical challenge for innovation management, especially in early-stage development where consumer needs are often unclear. Existing methods frequently fail to systematically incorporate end-user perspectives, resulting in a misalignment between technological potentials and market relevance. This study proposes a novel decision support framework that bridges this gap by linking technological feasibility with fundamental human values. The framework integrates two distinct lenses: the engineering-based Technology Readiness Levels (TRL) and Schwartz's theory of basic human values. By combining these, the approach enables a structured exploration of how emerging technologies may satisfy diverse user motivations. To illustrate the framework's feasibility and insight potential, we conducted exploratory workshops with general consumers and internal experts at Sony Computer Science Laboratories, Inc., analyzing four real-world technologies (two commercial successes and two failures). Two consistent patterns emerged: (1) internal experts identified a wider value landscape than consumers (vision gap), and (2) successful technologies exhibited a broader range of associated human values (value breadth), suggesting strategic foresight may underpin market success. This study contributes both a practical tool for early-stage R\\&D decision-making and a theoretical link between value theory and innovation outcomes. While exploratory in scope, the findings highlight the promise of value-centric evaluation as a foundation for more human-centered technology opportunity discovery."}
{"id": "2602.11924", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.11924", "abs": "https://arxiv.org/abs/2602.11924", "authors": ["Shreya Chappidi", "Jatinder Singh", "Andra V. Krauze"], "title": "Who Does What? Archetypes of Roles Assigned to LLMs During Human-AI Decision-Making", "comment": "Accepted to ACM CHI 2026", "summary": "LLMs are increasingly supporting decision-making across high-stakes domains, requiring critical reflection on the socio-technical factors that shape how humans and LLMs are assigned roles and interact during human-in-the-loop decision-making. This paper introduces the concept of human-LLM archetypes -- defined as re-curring socio-technical interaction patterns that structure the roles of humans and LLMs in collaborative decision-making. We describe 17 human-LLM archetypes derived from a scoping literature review and thematic analysis of 113 LLM-supported decision-making papers. Then, we evaluate these diverse archetypes across real-world clinical diagnostic cases to examine the potential effects of adopting distinct human-LLM archetypes on LLM outputs and decision outcomes. Finally, we present relevant tradeoffs and design choices across human-LLM archetypes, including decision control, social hierarchies, cognitive forcing strategies, and information requirements. Through our analysis, we show that selection of human-LLM interaction archetype can influence LLM outputs and decisions, bringing important risks and considerations for the designers of human-AI decision-making systems"}
{"id": "2602.11962", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.11962", "abs": "https://arxiv.org/abs/2602.11962", "authors": ["Qile Wang", "Prerana Khatiwada", "Carolina Coimbra Vieira", "Benjamin E. Bagozzi", "Kenneth E. Barner", "Matthew Louis Mauriello"], "title": "Wisdom of the LLM Crowd: A Large Scale Benchmark of Multi-Label U.S. Election-Related Harmful Social Media Content", "comment": null, "summary": "The spread of election misinformation and harmful political content conveys misleading narratives and poses a serious threat to democratic integrity. Detecting harmful content at early stages is essential for understanding and potentially mitigating its downstream spread. In this study, we introduce USE24-XD, a large-scale dataset of nearly 100k posts collected from X (formerly Twitter) during the 2024 U.S. presidential election cycle, enriched with spatio-temporal metadata. To substantially reduce the cost of manual annotation while enabling scalable categorization, we employ six large language models (LLMs) to systematically annotate posts across five nuanced categories: Conspiracy, Sensationalism, Hate Speech, Speculation, and Satire. We validate LLM annotations with crowdsourcing (n = 34) and benchmark them against human annotators. Inter-rater reliability analyses show comparable agreement patterns between LLMs and humans, with LLMs exhibiting higher internal consistency and achieving up to 0.90 recall on Speculation. We apply a wisdom-of-the-crowd approach across LLMs to aggregate annotations and curate a robust multi-label dataset. 60% of posts receive at least one label. We further analyze how human annotator demographics, including political ideology and affiliation, shape labeling behavior, highlighting systematic sources of subjectivity in judgments of harmful content. The USE24-XD dataset is publicly released to support future research."}
{"id": "2602.12136", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.12136", "abs": "https://arxiv.org/abs/2602.12136", "authors": ["Kaisa Vaananen", "Niels van Berkel", "Donald McMillan", "Thomas Olsson"], "title": "Embodied AI Agents for Team Collaboration in Co-located Blue-Collar Work", "comment": "4 pages, 1 figure, a short synopsis of this paper has been submitted to CHI 2026 workshop on Embodying Relationships, Designing TUIs for Co-Located Human-Human Dynamics", "summary": "Blue-collar work is often highly collaborative, embodied, and situated in shared physical environments, yet most research on collaborative AI has focused on white-collar work. This position paper explores how the embodied nature of AI agents can support team collaboration and communication in co-located blue-collar workplaces. From the context of our newly started CAI-BLUE research project, we present two speculative scenarios from industrial and maintenance contexts that illustrate how embodied AI agents can support shared situational awareness and facilitate inclusive communication across experience levels. We outline open questions related to embodied AI agent design around worker inclusion, agency, transformation of blue-collar collaboration practices over time, and forms of acceptable AI embodiments. We argue that embodiment is not just an aesthetic choice but should become a socio-material design strategy of AI systems in blue-collar workplaces."}
{"id": "2602.12207", "categories": ["cs.HC", "cs.AI", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.12207", "abs": "https://arxiv.org/abs/2602.12207", "authors": ["Emma Hoes", "K. Jonathan Klueser", "Fabrizio Gilardi"], "title": "VIRENA: Virtual Arena for Research, Education, and Democratic Innovation", "comment": "VIRENA is under active development and currently in use at the University of Zurich, supported by the DIZH Innovation Program: 2nd Founder-Call. This preprint will be updated as new features are released. For the latest version and to inquire about demos or pilot collaborations, contact the authors", "summary": "Digital platforms shape how people communicate, deliberate, and form opinions. Studying these dynamics has become increasingly difficult due to restricted data access, ethical constraints on real-world experiments, and limitations of existing research tools. VIRENA (Virtual Arena) is a platform that enables controlled experimentation in realistic social media environments. Multiple participants interact simultaneously in realistic replicas of feed-based platforms (Instagram, Facebook, Reddit) and messaging apps (WhatsApp, Messenger). Large language model-powered AI agents participate alongside humans with configurable personas and realistic behavior. Researchers can manipulate content moderation approaches, pre-schedule stimulus content, and run experiments across conditions through a visual interface requiring no programming skills. VIRENA makes possible research designs that were previously impractical: studying human--AI interaction in realistic social contexts, experimentally comparing moderation interventions, and observing group deliberation as it unfolds. Built on open-source technologies that ensure data remain under institutional control and comply with data protection requirements, VIRENA is currently in use at the University of Zurich and available for pilot collaborations. Designed for researchers, educators, and public organizations alike, VIRENA's no-code interface makes controlled social media simulation accessible across disciplines and sectors. This paper documents its design, architecture, and capabilities."}
