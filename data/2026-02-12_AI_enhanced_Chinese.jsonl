{"id": "2602.10712", "categories": ["cs.GR", "astro-ph.EP", "astro-ph.IM"], "pdf": "https://arxiv.org/pdf/2602.10712", "abs": "https://arxiv.org/abs/2602.10712", "authors": ["Charles Constant", "Elizabeth Bates", "Santosh Bhattarai", "Marek Ziebart", "Tobias Ritschel"], "title": "Photons x Force: Differentiable Radiation Pressure Modeling", "comment": "17 pages, 19 figures", "summary": "We propose a system to optimize parametric designs subject to radiation pressure, \\ie the effect of light on the motion of objects. This is most relevant in the design of spacecraft, where radiation pressure presents the dominant non-conservative forcing mechanism, which is the case beyond approximately 800 km altitude. Despite its importance, the high computational cost of high-fidelity radiation pressure modeling has limited its use in large-scale spacecraft design, optimization, and space situational awareness applications. We enable this by offering three innovations in the simulation, in representation and in optimization: First, a practical computer graphics-inspired Monte-Carlo (MC) simulation of radiation pressure. The simulation is highly parallel, uses importance sampling and next-event estimation to reduce variance and allows simulating an entire family of designs instead of a single spacecraft as in previous work. Second, we introduce neural networks as a representation of forces from design parameters. This neural proxy model, learned from simulations, is inherently differentiable and can query forces orders of magnitude faster than a full MC simulation. Third, and finally, we demonstrate optimizing inverse radiation pressure designs, such as finding geometry, material or operation parameters that minimizes travel time, maximizes proximity given a desired end-point, minimize thruster fuel, trains mission control policies or allocated compute budget in extraterrestrial compute.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.10429", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10429", "abs": "https://arxiv.org/abs/2602.10429", "authors": ["Wenkai Fan", "Shurui Zhang", "Xiaolong Wang", "Haowei Yang", "Tsz Wai Chan", "Xingyan Chen", "Junquan Bi", "Zirui Zhou", "Jia Liu", "Kani Chen"], "title": "AIvilization v0: Toward Large-Scale Artificial Social Simulation with a Unified Agent Architecture and Adaptive Agent Profiles", "comment": null, "summary": "AIvilization v0 is a publicly deployed large-scale artificial society that couples a resource-constrained sandbox economy with a unified LLM-agent architecture, aiming to sustain long-horizon autonomy while remaining executable under rapidly changing environment. To mitigate the tension between goal stability and reactive correctness, we introduce (i) a hierarchical branch-thinking planner that decomposes life goals into parallel objective branches and uses simulation-guided validation plus tiered re-planning to ensure feasibility; (ii) an adaptive agent profile with dual-process memory that separates short-term execution traces from long-term semantic consolidation, enabling persistent yet evolving identity; and (iii) a human-in-the-loop steering interface that injects long-horizon objectives and short commands at appropriate abstraction levels, with effects propagated through memory rather than brittle prompt overrides. The environment integrates physiological survival costs, non-substitutable multi-tier production, an AMM-based price mechanism, and a gated education-occupation system. Using high-frequency transactions from the platforms mature phase, we find stable markets that reproduce key stylized facts (heavy-tailed returns and volatility clustering) and produce structured wealth stratification driven by education and access constraints. Ablations show simplified planners can match performance on narrow tasks, while the full architecture is more robust under multi-objective, long-horizon settings, supporting delayed investment and sustained exploration.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.10222", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.10222", "abs": "https://arxiv.org/abs/2602.10222", "authors": ["Harry Yizhou Tian", "Hasan Amin", "Ming Yin"], "title": "Understanding the Effects of AI-Assisted Critical Thinking on Human-AI Decision Making", "comment": null, "summary": "Despite the growing prevalence of human-AI decision making, the human-AI team's decision performance often remains suboptimal, partially due to insufficient examination of humans' own reasoning. In this paper, we explore designing AI systems that directly analyze humans' decision rationales and encourage critical reflection of their own decisions. We introduce the AI-Assisted Critical Thinking (AACT) framework, which leverages a domain-specific AI model's counterfactual analysis of human decision to help decision-makers identify potential flaws in their decision argument and support the correction of them. Through a case study on house price prediction, we find that AACT outperforms traditional AI-based decision-support in reducing over-reliance on AI, though also triggering higher cognitive load. Subgroup analysis reveals AACT can be particularly beneficial for some decision-makers such as those very familiar with AI technologies. We conclude by discussing the practical implications of our findings, use cases and design choices of AACT, and considerations for using AI to facilitate critical thinking.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.10543", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2602.10543", "abs": "https://arxiv.org/abs/2602.10543", "authors": ["Andrew Adamatzky"], "title": "Fungal systems for security and resilience", "comment": null, "summary": "Modern security, infrastructure, and safety-critical systems increasingly operate in environments characterised by disruption, uncertainty, physical damage, and degraded communications. Conventional digital technologies -- centralised sensors, software-defined control, and energy-intensive monitoring -- often struggle under such conditions. We propose fungi, and in particular living mycelial networks, as a novel class of biohybride systems for security, resilience, and protection in extreme environments. We discuss how fungi can function as distributed sensing substrates, self-healing materials, and low-observability anomaly-detection layers. We map fungal properties -- such as decentralised control, embodied memory, and autonomous repair -- to applications in infrastructure protection, environmental monitoring, tamper evidence, and long-duration resilience.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.10219", "categories": ["cs.MM", "eess.IV"], "pdf": "https://arxiv.org/pdf/2602.10219", "abs": "https://arxiv.org/abs/2602.10219", "authors": ["Jihao Zhu", "Zixuan Chen", "Jiali Liu", "Lingxiao Yang", "Yi Zhou", "Weiqi Luo", "Xiaohua Xie"], "title": "Rethinking Security of Diffusion-based Generative Steganography", "comment": null, "summary": "Generative image steganography is a technique that conceals secret messages within generated images, without relying on pre-existing cover images. Recently, a number of diffusion model-based generative image steganography (DM-GIS) methods have been introduced, which effectively combat traditional steganalysis techniques. In this paper, we identify the key factors that influence DM-GIS security and revisit the security of existing methods. Specifically, we first provide an overview of the general pipelines of current DM-GIS methods, finding that the noise space of diffusion models serves as the primary embedding domain. Further, we analyze the relationship between DM-GIS security and noise distribution of diffusion models, theoretically demonstrating that any steganographic operation that disrupts the noise distribution compromise DM-GIS security. Building on this insight, we propose a Noise Space-based Diffusion Steganalyzer (NS-DSer)-a simple yet effective steganalysis framework allowing for detecting DM-GIS generated images in the diffusion model noise space. We reevaluate the security of existing DM-GIS methods using NS-DSer across increasingly challenging detection scenarios. Experimental results validate our theoretical analysis of DM-GIS security and show the effectiveness of NS-DSer across diverse detection scenarios.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.10555", "categories": ["cs.MA", "cs.DB", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.10555", "abs": "https://arxiv.org/abs/2602.10555", "authors": ["Hsan Sandar Win", "Andrew Walters", "Cheng-Chew Lim", "Daniel Webber", "Seth Leslie", "Tan Doan"], "title": "An Ontology-driven Dynamic Knowledge Base for Uninhabited Ground Vehicles", "comment": "10 pages, 11 figures, 2025 Australasian Conference on Robotics and Automation (ACRA 2025)", "summary": "In this paper, the concept of Dynamic Contextual Mission Data (DCMD) is introduced to develop an ontology-driven dynamic knowledge base for Uninhabited Ground Vehicles (UGVs) at the tactical edge. The dynamic knowledge base with DCMD is added to the UGVs to: support enhanced situation awareness; improve autonomous decision making; and facilitate agility within complex and dynamic environments. As UGVs are heavily reliant on the a priori information added pre-mission, unexpected occurrences during a mission can cause identification ambiguities and require increased levels of user input. Updating this a priori information with contextual information can help UGVs realise their full potential. To address this, the dynamic knowledge base was designed using an ontology-driven representation, supported by near real-time information acquisition and analysis, to provide in-mission on-platform DCMD updates. This was implemented on a team of four UGVs that executed a laboratory based surveillance mission. The results showed that the ontology-driven dynamic representation of the UGV operational environment was machine actionable, producing contextual information to support a successful and timely mission, and contributed directly to the situation awareness.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.10235", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.10235", "abs": "https://arxiv.org/abs/2602.10235", "authors": ["Xinru Tang", "Anne Marie Piper"], "title": "Reimagining Sign Language Technologies: Analyzing Translation Work of Chinese Deaf Online Content Creators", "comment": null, "summary": "While sign language translation systems promise to enhance deaf people's access to information and communication, they have been met with strong skepticism from deaf communities due to risks of misrepresenting and oversimplifying the richness of signed communication in technologies. This article provides empirical evidence of the complexity of translation work involved in deaf communication through interviews with 13 deaf Chinese content creators who actively produce and share sign language content on video sharing platforms with both deaf and hearing audiences. By studying this unique group of content creators, our findings highlight the nuances of sign language translation, showing how deaf creators create content with multilingualism and multiculturalism in mind, support meaning making across languages and cultures, and navigate politics involved in their translation work. Grounded in these deaf-led translation practices, we draw on the sociolinguistic concept of (trans)languaging to re-conceptualize and reimagine the design of sign language translation systems.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.10685", "categories": ["cs.MA", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10685", "abs": "https://arxiv.org/abs/2602.10685", "authors": ["Alejandro Mendoza Barrionuevo", "Samuel Yanes Luis", "Daniel Guti\u00e9rrez Reina", "Sergio L. Toral Mar\u00edn"], "title": "Beyond Task Performance: A Metric-Based Analysis of Sequential Cooperation in Heterogeneous Multi-Agent Destructive Foraging", "comment": null, "summary": "This work addresses the problem of analyzing cooperation in heterogeneous multi-agent systems which operate under partial observability and temporal role dependency, framed within a destructive multi-agent foraging setting. Unlike most previous studies, which focus primarily on algorithmic performance with respect to task completion, this article proposes a systematic set of general-purpose cooperation metrics aimed at characterizing not only efficiency, but also coordination and dependency between teams and agents, fairness, and sensitivity. These metrics are designed to be transferable to different multi-agent sequential domains similar to foraging. The proposed suite of metrics is structured into three main categories that jointly provide a multilevel characterization of cooperation: primary metrics, inter-team metrics, and intra-team metrics. They have been validated in a realistic destructive foraging scenario inspired by dynamic aquatic surface cleaning using heterogeneous autonomous vehicles. It involves two specialized teams with sequential dependencies: one focused on the search of resources, and another on their destruction. Several representative approaches have been evaluated, covering both learning-based algorithms and classical heuristic paradigms.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.10237", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.10237", "abs": "https://arxiv.org/abs/2602.10237", "authors": ["Albin Zeqiri", "Michael Rietzler", "Enrico Rukzio"], "title": "Investigating the Effects of Eco-Friendly Service Options on Rebound Behavior in Ride-Hailing", "comment": null, "summary": "Eco-friendly service options (EFSOs) aim to reduce personal carbon emissions, yet their eco-friendly framing may permit increased consumption, weakening their intended impact. Such rebound effects remain underexamined in HCI, including how common eco-feedback approaches shape them. We investigate this in an online within-subjects experiment (N=75) in a ride-hailing context. Participants completed 10 trials for five conditions (No EFSO, EFSO - Minimal, EFSO - CO2 Equivalency, EFSO - Gamified, EFSO - Social), yielding 50 choices between walking and ride-hailing for trips ranging from 0.5mi - 2.0mi (0.80km - 3.22km). We measured how different EFSO variants affected ride-hailing uptake relative to a No EFSO baseline. EFSOs lacking explicit eco-feedback metrics increased ride-hailing uptake, and qualitative responses indicate that EFSOs can make convenience-driven choices more permissible. We conclude with implications for designing EFSOs that begin to take rebound effects into account.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.10996", "categories": ["cs.MA", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10996", "abs": "https://arxiv.org/abs/2602.10996", "authors": ["Daniela Mihai", "Lucas Weber", "Francesca Franzon"], "title": "The emergence of numerical representations in communicating artificial agents", "comment": "In the Sixteenth International Conference on the Evolution of Language", "summary": "Human languages provide efficient systems for expressing numerosities, but whether the sheer pressure to communicate is enough for numerical representations to arise in artificial agents, and whether the emergent codes resemble human numerals at all, remains an open question. We study two neural network-based agents that must communicate numerosities in a referential game using either discrete tokens or continuous sketches, thus exploring both symbolic and iconic representations. Without any pre-defined numeric concepts, the agents achieve high in-distribution communication accuracy in both communication channels and converge on high-precision symbol-meaning mappings. However, the emergent code is non-compositional: the agents fail to derive systematic messages for unseen numerosities, typically reusing the symbol of the highest trained numerosity (discrete), or collapsing extrapolated values onto a single sketch (continuous). We conclude that the communication pressure alone suffices for precise transmission of learned numerosities, but additional pressures are needed to yield compositional codes and generalisation abilities.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.10251", "categories": ["cs.HC", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.10251", "abs": "https://arxiv.org/abs/2602.10251", "authors": ["Olivia Figueira", "Pranathi Chamarthi", "Tu Le", "Athina Markopoulou"], "title": "Actions Speak Louder Than Chats: Investigating AI Chatbot Age Gating", "comment": null, "summary": "AI chatbots are widely used by children and teens today, but they pose significant risks to youth's privacy and safety due to both increasingly personal conversations and potential exposure to unsafe content. While children under 13 are protected by the Children's Online Privacy Protection Act (COPPA), chatbot providers' own privacy policies may also provide protections, since they typically prohibit children from accessing their platforms. Age gating is often employed to restrict children online, but chatbot age gating in particular has not been studied. In this paper, we investigate whether popular consumer chatbots are (i) able to estimate users' ages based solely on their conversations, and (ii) whether they take action upon identifying children. To that end, we develop an auditing framework in which we programmatically interact with chatbots and conduct 1050 experiments using our comprehensive library of age-indicative prompts, including implicit and explicit age disclosures, to analyze the chatbots' responses and actions. We find that while chatbots are capable of estimating age, they do not take any action when children are identified, contradicting their own policies. Our methodology and findings provide insights for platform design, demonstrated by our proof-of-concept chatbot age gating implementation, and regulation to protect children online.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.11114", "categories": ["cs.MA", "cs.AI", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.11114", "abs": "https://arxiv.org/abs/2602.11114", "authors": ["Jialiang Wang", "Shengxiang Xu", "Hanmo Liu", "Jiachuan Wang", "Yuyu Luo", "Shimin Di", "Min-Ling Zhang", "Lei Chen"], "title": "Learning to Compose for Cross-domain Agentic Workflow Generation", "comment": null, "summary": "Automatically generating agentic workflows -- executable operator graphs or codes that orchestrate reasoning, verification, and repair -- has become a practical way to solve complex tasks beyond what single-pass LLM generation can reliably handle. Yet what constitutes a good workflow depends heavily on the task distribution and the available operators. Under domain shift, current systems typically rely on iterative workflow refinement to discover a feasible workflow from a large workflow space, incurring high iteration costs and yielding unstable, domain-specific behavior. In response, we internalize a decompose-recompose-decide mechanism into an open-source LLM for cross-domain workflow generation. To decompose, we learn a compact set of reusable workflow capabilities across diverse domains. To recompose, we map each input task to a sparse composition over these bases to generate a task-specific workflow in a single pass. To decide, we attribute the success or failure of workflow generation to counterfactual contributions from learned capabilities, thereby capturing which capabilities actually drive success by their marginal effects. Across stringent multi-domain, cross-domain, and unseen-domain evaluations, our 1-pass generator surpasses SOTA refinement baselines that consume 20 iterations, while substantially reducing generation latency and cost.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.10295", "categories": ["cs.HC", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.10295", "abs": "https://arxiv.org/abs/2602.10295", "authors": ["Jiqun Liu", "Nischal Dinesh", "Ran Yu"], "title": "ECHO: An Open Research Platform for Evaluation of Chat, Human Behavior, and Outcomes", "comment": null, "summary": "ECHO (Evaluation of Chat, Human behavior, and Outcomes) is an open research platform designed to support reproducible, mixed-method studies of human interaction with both conversational AI systems and Web search engines. It enables researchers from varying disciplines to orchestrate end-to-end experimental workflows that integrate consent and background surveys, chat-based and search-based information-seeking sessions, writing or judgment tasks, and pre- and post-task evaluations within a unified, low-coding-load framework. ECHO logs fine-grained interaction traces and participant responses, and exports structured datasets for downstream analysis. By supporting both chat and search alongside flexible evaluation instruments, ECHO lowers technical barriers for studying learning, decision making, and user experience across different information access paradigms, empowering researchers from information retrieval, HCI, and the social sciences to conduct scalable and reproducible human-centered AI evaluations.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.10403", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.10403", "abs": "https://arxiv.org/abs/2602.10403", "authors": ["Xinru Tang", "Jingjin Li", "Shaomei Wu"], "title": "Disability-First AI Dataset Annotation: Co-designing Stuttered Speech Annotation Guidelines with People Who Stutter", "comment": null, "summary": "Despite efforts to increase the representation of disabled people in AI datasets, accessibility datasets are often annotated by crowdworkers without disability-specific expertise, leading to inconsistent or inaccurate labels. This paper examines these annotation challenges through a case study of annotating speech data from people who stutter (PWS). Given the variability of stuttering and differing views on how it manifests, annotating and transcribing stuttered speech remains difficult, even for trained professionals. Through interviews and co-design workshops with PWS and domain experts, we identify challenges in stuttered speech annotation and develop practices that integrate the lived experiences of PWS into the annotation process. Our findings highlight the value of embodied knowledge in improving dataset quality, while revealing tensions between the complexity of disability experiences and the rigidity of static labels. We conclude with implications for disability-first and multiplicity-aware approaches to data interpretation across the AI pipeline.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.10407", "categories": ["cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10407", "abs": "https://arxiv.org/abs/2602.10407", "authors": ["Lawrence Obiuwevwi", "Krzysztof J. Rechowicz", "Vikas Ashok", "Sampath Jayarathna"], "title": "Towards Affordable, Non-Invasive Real-Time Hypoglycemia Detection Using Wearable Sensor Signals", "comment": null, "summary": "Accurately detecting hypoglycemia without invasive glucose sensors remains a critical challenge in diabetes management, particularly in regions where continuous glucose monitoring (CGM) is prohibitively expensive or clinically inaccessible. This extended study introduces a comprehensive, multimodal physiological framework for non-invasive hypoglycemia detection using wearable sensor signals. Unlike prior work limited to single-signal analysis, this chapter evaluates three physiological modalities, galvanic skin response (GSR), heart rate (HR), and their combined fusion, using the OhioT1DM 2018 dataset. We develop an end-to-end pipeline that integrates advanced preprocessing, temporal windowing, handcrafted and sequence-based feature extraction, early and late fusion strategies, and a broad spectrum of machine learning and deep temporal models, including CNNs, LSTMs, GRUs, and TCNs. Our results demonstrate that physiological signals exhibit distinct autonomic patterns preceding hypoglycemia and that combining GSR with HR consistently enhances detection sensitivity and stability compared to single-signal models. Multimodal deep learning architectures achieve the most reliable performance, particularly in recall, the most clinically urgent metric. Ablation studies further highlight the complementary contributions of each modality, strengthening the case for affordable, sensor-based glycemic monitoring. The findings show that real-time hypoglycemia detection is achievable using only inexpensive, non-invasive wearable sensors, offering a pathway toward accessible glucose monitoring in underserved communities and low-resource healthcare environments.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.10442", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.10442", "abs": "https://arxiv.org/abs/2602.10442", "authors": ["Hao Zhou", "Mahanth Gowda"], "title": "Exploring the Feasibility of Full-Body Muscle Activation Sensing with Insole Pressure Sensors", "comment": null, "summary": "Muscle activation initiates contractions that drive human movement, and understanding it provides valuable insights for injury prevention and rehabilitation. Yet, sensing muscle activation is barely explored in the rapidly growing mobile health market. Traditional methods for muscle activation sensing rely on specialized electrodes, such as surface electromyography, making them impractical, especially for long-term usage. In this paper, we introduce Press2Muscle, the first system to unobtrusively infer muscle activation using insole pressure sensors. The key idea is to analyze foot pressure changes resulting from full-body muscle activation that drives movements. To handle variations in pressure signals due to differences in users' gait, weight, and movement styles, we propose a data-driven approach to dynamically adjust reliance on different foot regions and incorporate easily accessible biographical data to enhance Press2Muscle's generalization to unseen users. We conducted an extensive study with 30 users. Under a leave-one-user-out setting, Press2Muscle achieves a root mean square error of 0.025, marking a 19% improvement over a video-based counterpart. A robustness study validates Press2Muscle's ability to generalize across user demographics, footwear types, and walking surfaces. Additionally, we showcase muscle imbalance detection and muscle activation estimation under free-living settings with Press2Muscle, confirming the feasibility of muscle activation sensing using insole pressure sensors in real-world settings.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.10473", "categories": ["cs.HC", "cs.AI", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.10473", "abs": "https://arxiv.org/abs/2602.10473", "authors": ["Haoyu Hu", "Raja Marjieh", "Katherine M Collins", "Chenyi Li", "Thomas L. Griffiths", "Ilia Sucholutsky", "Nori Jacoby"], "title": "Why Human Guidance Matters in Collaborative Vibe Coding", "comment": null, "summary": "Writing code has been one of the most transformative ways for human societies to translate abstract ideas into tangible technologies. Modern AI is transforming this process by enabling experts and non-experts alike to generate code without actually writing code, but instead, through natural language instructions, or \"vibe coding\". While increasingly popular, the cumulative impact of vibe coding on productivity and collaboration, as well as the role of humans in this process, remains unclear. Here, we introduce a controlled experimental framework for studying collaborative vibe coding and use it to compare human-led, AI-led, and hybrid groups. Across 16 experiments involving 604 human participants, we show that people provide uniquely effective high-level instructions for vibe coding across iterations, whereas AI-provided instructions often result in performance collapse. We further demonstrate that hybrid systems perform best when humans retain directional control (providing the instructions), while evaluation is delegated to AI.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.10501", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.10501", "abs": "https://arxiv.org/abs/2602.10501", "authors": ["Ziyi Wang", "Congrong Zhang", "Jingying Deng", "Xiaofan Hu", "Jie Cai", "Nan Gao", "Chun Yu", "Haining Zhang"], "title": "Division of Labor and Collaboration Between Parents in Family Education", "comment": "16 pages. To appear in Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems (CHI 2026), Barcelona, Spain, April 13-17, 2026", "summary": "Homework tutoring work is a demanding and often conflict-prone practice in family life, and parents often lack targeted support for managing its cognitive and emotional burdens. Through interviews with 18 parents of children in grades 1-3, we examine how homework-related labor is divided and coordinated between parents, and where AI might meaningfully intervene. We found three key insights: (1) Homework labor encompasses distinct dimensions: physical, cognitive, and emotional, with the latter two often remaining invisible. (2) We identified father-mother-child triadic dynamics in labor division, with children's feedback as the primary factor shaping parental labor adjustments. (3) Building on prior HCI research, we propose an AI design that prioritizes relationship maintenance over task automation or broad labor mitigation. By employing labor as a lens that integrates care work, we explore the complexities of labor within family contexts, contributing to feminist and care-oriented HCI and to the development of context-sensitive coparenting practices.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.10535", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.10535", "abs": "https://arxiv.org/abs/2602.10535", "authors": ["Kai Alexander Hackney", "Lucas Guarenti Zangari", "Jhonathan Sora-Cardenas", "Emmanuel Munoz", "Sterling R. Kalogeras", "Betsy DiSalvo", "Pedro Guillermo Feijoo-Garcia"], "title": "Exploring the Interplay Between Voice, Personality, and Gender in Human-Agent Interactions", "comment": null, "summary": "To foster effective human-agent interactions, designers need to identify characteristics that could affect how agents are perceived and accepted, and to what extent they could impact rapport-building. Aiming to explore the role of user-agent synchrony, we assessed 388 participants to determine whether they could perceive personality traits from four artificial voices we selected and adapted from human samples, considering gender (male or female) and personality (introvert or extrovert) as grouping factors. Our findings suggest that participants were able to significantly differentiate female agents by personality, while male agents were not consistently distinguished. We also observed evidence of personality synchrony, where participants tended to perceive the first agent as more similar to their own personality, with this effect driven mainly by male participants, especially toward male agents. This paper contributes findings and insights to consider the interplay of user-agent personality and gender synchrony in the design of human-agent interactions.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.10548", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.10548", "abs": "https://arxiv.org/abs/2602.10548", "authors": ["Yigang Qin", "EunJeong Cheon"], "title": "Labor, Capital, and Machine: Toward a Labor Process Theory for HCI", "comment": "20 pages, 2 figures. Accepted to CHI'26", "summary": "The HCI community has called for renewed attention to labor issues and the political economy of computing. Yet much work remains in engaging with labor theory to better understand modern work and workers. This article traces the development of Labor Process Theory (LPT) -- from Karl Marx and Harry Braverman to Michael Burawoy and beyond -- and introduces it as an essential yet underutilized resource for structural analysis of work under capitalism and the design of computing systems. We examine HCI literature on labor, investigating focal themes and conceptual, empirical, and design approaches. Drawing from LPT, we offer directions for HCI research and practice: distinguish labor from work, link work practice to value production, study up the management, analyze consent and legitimacy, move beyond the point of production, design alternative institutions, and unnaturalize bourgeois designs. These directions can deepen analyses of tech-mediated workplace regimes, inform critical and normative designs, and strengthen the field's connection to broader political economic critique.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.10618", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.10618", "abs": "https://arxiv.org/abs/2602.10618", "authors": ["Robin Beierling", "Manuel Scheibl", "Jonas Dech", "Abhijit Vyas", "Anna-Lisa Vollmer"], "title": "From Interaction to Demonstration Quality in Virtual Reality: Effects of Interaction Modality and Visual Representation on Everyday Tasks", "comment": "26 pages, 6 figures, 7 tables (including appendix)", "summary": "Virtual Reality (VR) is increasingly used for training and demonstration purposes including a variety of applications ranging from robot learning to rehabilitation. However, the choice of input device and its visualization might influence workload and thus user performance leading to suboptimal demonstrations or reduced training effects. This study investigates how different VR input configurations - motion capture gloves, controllers with hand visualization, and controllers with controller visualization - affect user experience and task execution, with the goal of identifying which configuration is best suited for which type of task. Participants performed various kitchen-related activities of daily living (ADLs), including object placement, cutting, cleaning, and pouring in a simulated environment. To address two research questions, we evaluated user experience using the System Usability Scale and NASA Task Load Index (RQ1), and task-specific interaction behavior (RQ2). The latter was assessed using trajectory segmentation, analyzing movement efficiency, unnecessary actions, and execution precision. While no significant differences in overall usability and workload were found, trajectory analysis revealed configuration-specific execution behaviors with different movement strategies. Controllers enabled significantly faster task completion with less movement variability in pick-and-place style tasks such as table setting. In contrast, motion capture gloves produced more natural movements with fewer unnecessary actions, but also showed greater variance in movement patterns for manner-oriented tasks such as cutting bread. These findings highlight trade-offs between efficiency and naturalism, and have implications for optimizing VR-based training, improving the quality of user-generated demonstrations, and tailoring interaction design to specific application goals.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.10684", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.10684", "abs": "https://arxiv.org/abs/2602.10684", "authors": ["Zhuoyang Li", "Yanlai Wu", "Yao Li", "Xinning Gui", "Yuhan Luo"], "title": "Privacy Control in Conversational LLM Platforms: A Walkthrough Study", "comment": null, "summary": "Large language models (LLMs) are increasingly integrated into daily life through conversational interfaces, processing user data via natural language inputs and exhibiting advanced reasoning capabilities, which raises new concerns about user control over privacy. While much research has focused on potential privacy risks, less attention has been paid to the data control mechanisms these platforms provide. This study examines six conversational LLM platforms, analyzing how they define and implement features for users to access, edit, delete, and share data. Our analysis reveals an emerging paradigm of data control in conversational LLM platforms, where user data is generated and derived through interaction itself, natural language enables flexible yet often ambiguous control, and multi-user interactions with shared data raise questions of co-ownership and governance. Based on these findings, we offer practical insights for platform developers, policymakers, and researchers to design more effective and usable privacy controls in LLM-powered conversational interactions.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.10701", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.10701", "abs": "https://arxiv.org/abs/2602.10701", "authors": ["Cedric Faas", "Richard Uth", "Sarah Sterz", "Markus Langer", "Anna Maria Feit"], "title": "Don't blame me: How Intelligent Support Affects Moral Responsibility in Human Oversight", "comment": null, "summary": "AI-based systems can increasingly perform work tasks autonomously. In safety-critical tasks, human oversight of these systems is required to mitigate risks and to ensure responsibility in case something goes wrong. Since people often struggle to stay focused and perform good oversight, intelligent support systems are used to assist them, giving decision recommendations, alerting users, or restricting them from dangerous actions. However, in cases where recommendations are wrong, decision support might undermine the very reason why human oversight was employed -- genuine moral responsibility. The goal of our study was to investigate how a decision support system that restricted available interventions would affect overseer's perceived moral responsibility, in particular in cases where the support errs. In a simulated oversight experiment, participants (\\textit{N}=274) monitored an autonomous drone that faced ten critical situations, choosing from six possible actions to resolve each situation. An AI system constrained participants' choices to either six, four, two, or only one option (between-subject study). Results showed that participants, who were restricted to choosing from a single action, felt less morally responsible if a crash occurred. At the same time, participants' judgments about the responsibility of other stakeholders (the AI; the developer of the AI) did not change between conditions. Our findings provide important insights for user interface design and oversight architectures: they should prevent users from attributing moral agency to AI, help them understand how moral responsibility is distributed, and, when oversight aims to prevent ethically undesirable outcomes, be designed to support the epistemic and causal conditions required for moral responsibility.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.10827", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.10827", "abs": "https://arxiv.org/abs/2602.10827", "authors": ["Yuxin Zhang", "Fan Zhang"], "title": "The Effect of Design Thinking on Creative & Innovation Processes: An Empirical Study Across Different Design Experience Levels", "comment": null, "summary": "This study employs linear regression and structural equation modeling to explore how Thinking Skills, Design Thinking, Creative Self-Efficacy (CSE), and Collective Creative Efficacy (CCE) drive Design Creativity & Innovation, and analyzes the structural stability of the model across different levels of experience. Path analysis results indicate that the four Design Thinking Skills, Problem-driven Design (beta = 0.198, p < 0.01), Information-driven Design (beta = 0.241, p < 0.001), Solution-driven Design (beta = 0.227, p < 0.001), and Knowledge-driven Design (beta = 0.263, p < 0.001) all significantly and positively influence Design Thinking. Furthermore, Design Thinking has a significant positive predictive effect on Design Creativity & Innovation (beta = 0.286, p < 0.001). Mediation analysis confirms three significant mediation paths: the CSE mediation path (beta = 0.128, p < 0.001), the CCE mediation path (beta = 0.073, p < 0.01), and the \"CSE to CCE\" chain mediation path (beta = 0.025, p < 0.01). Multi-group comparison results reveal significant differences between the student and professional groups under the full equivalence model. After relaxing specific constraints, there were no significant differences between the nested models of the baseline model, partial measurement invariance, structural weight invariance, and structural covariance invariance. These findings elucidate the multi-dimensional pathways of Design Creativity & Innovation, providing a robust empirical basis for optimizing differentiated pedagogical models and professional practice guidelines.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.10871", "categories": ["cs.HC", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.10871", "abs": "https://arxiv.org/abs/2602.10871", "authors": ["Yu Zhang", "Xinyi Zhao", "Chongke Bi", "Siming Chen"], "title": "Viewpoint Recommendation for Point Cloud Labeling through Interaction Cost Modeling", "comment": "Accepted to IEEE TVCG", "summary": "Semantic segmentation of 3D point clouds is important for many applications, such as autonomous driving. To train semantic segmentation models, labeled point cloud segmentation datasets are essential. Meanwhile, point cloud labeling is time-consuming for annotators, which typically involves tuning the camera viewpoint and selecting points by lasso. To reduce the time cost of point cloud labeling, we propose a viewpoint recommendation approach to reduce annotators' labeling time costs. We adapt Fitts' law to model the time cost of lasso selection in point clouds. Using the modeled time cost, the viewpoint that minimizes the lasso selection time cost is recommended to the annotator. We build a data labeling system for semantic segmentation of 3D point clouds that integrates our viewpoint recommendation approach. The system enables users to navigate to recommended viewpoints for efficient annotation. Through an ablation study, we observed that our approach effectively reduced the data labeling time cost. We also qualitatively compare our approach with previous viewpoint selection approaches on different datasets.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.10935", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10935", "abs": "https://arxiv.org/abs/2602.10935", "authors": ["Bijean Ghafouri", "Dorsaf Sallami", "Luca Luceri", "Taylor Lynn Curtis", "Jean-Francois Godbout", "Emilio Ferrara", "Reihaneh Rabbany"], "title": "What do people want to fact-check?", "comment": null, "summary": "Research on misinformation has focused almost exclusively on supply, asking what falsehoods circulate, who produces them, and whether corrections work. A basic demand-side question remains unanswered. When ordinary people can fact-check anything they want, what do they actually ask about? We provide the first large-scale evidence on this question by analyzing close to 2{,}500 statements submitted by 457 participants to an open-ended AI fact-checking system. Each claim is classified along five semantic dimensions (domain, epistemic form, verifiability, target entity, and temporal reference), producing a behavioral map of public verification demand. Three findings stand out. First, users range widely across topics but default to a narrow epistemic repertoire, overwhelmingly submitting simple descriptive claims about present-day observables. Second, roughly one in four requests concerns statements that cannot be empirically resolved, including moral judgments, speculative predictions, and subjective evaluations, revealing a systematic mismatch between what users seek from fact-checking tools and what such tools can deliver. Third, comparison with the FEVER benchmark dataset exposes sharp structural divergences across all five dimensions, indicating that standard evaluation corpora encode a synthetic claim environment that does not resemble real-world verification needs. These results reframe fact-checking as a demand-driven problem and identify where current AI systems and benchmarks are misaligned with the uncertainty people actually experience.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.11025", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.11025", "abs": "https://arxiv.org/abs/2602.11025", "authors": ["Liuchuan Yu", "Yongqi Zhang", "Lap-Fai Yu"], "title": "Reality Copilot: Voice-First Human-AI Collaboration in Mixed Reality Using Large Multimodal Models", "comment": null, "summary": "Large Multimodal Models (LMMs) have shown strong potential for assisting users in tasks, such as programming, content creation, and information access, yet their interaction remains largely limited to traditional interfaces such as desktops and smartphones. Meanwhile, advances in mixed reality (MR) hardware have enabled applications that extend beyond entertainment and into everyday use. However, most existing MR systems rely primarily on manual input (e.g., hand gestures or controllers) and provide limited intelligent assistance due to the lack of integration with large-scale AI models. We present Reality Copilot, a voice-first human-AI assistant for mixed reality that leverages LMMs to enable natural speech-based interaction. The system supports contextual understanding of physical environments, realistic 3D content generation, and real-time information retrieval. In addition to in-headset interaction, Reality Copilot facilitates cross-platform workflows by generating context-aware textual content and exporting generated assets. This work explores the design space of LMM-powered human-AI collaboration in mixed reality.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.11026", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.11026", "abs": "https://arxiv.org/abs/2602.11026", "authors": ["Yehuda Perry", "Tawfiq Ammari"], "title": "Normalized Surveillance in the Datafied Car: How Autonomous Vehicle Users Rationalize Privacy Trade-offs", "comment": null, "summary": "Autonomous vehicles (AVs) are characterized by pervasive datafication and surveillance through sensors like in-cabin cameras, LIDAR, and GPS. Drawing on 16 semi-structured interviews with AV drivers analyzed using constructivist grounded theory, this study examines how users make sense of vehicular surveillance within everyday datafication. Findings reveal drivers demonstrate few AV-specific privacy concerns, instead normalizing monitoring through comparisons with established digital platforms. We theorize this indifference by situating AV surveillance within the `surveillance ecology' of platform environments, arguing the datafied car functions as a mobile extension of the `leaky home' -- private spaces rendered permeable through connected technologies continuously transmitting behavioral data.\n  The study contributes to scholarship on surveillance beliefs, datafication, and platform governance by demonstrating how users who have accepted comprehensive smartphone and smart home monitoring encounter AV datafication as just another node in normalized data extraction. We highlight how geographic restrictions on data access -- currently limiting driver log access to California -- create asymmetries that impede informed privacy deliberation, exemplifying `tertiary digital divides.' Finally, we examine how machine learning's reliance on data-intensive approaches creates structural pressure for surveillance that transcends individual manufacturer choices. We propose governance interventions to democratize social learning, including universal data access rights, binding transparency requirements, and data minimization standards to prevent race-to-the-bottom dynamics in automotive datafication.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.11055", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.11055", "abs": "https://arxiv.org/abs/2602.11055", "authors": ["Yate Ge", "Lin Tian", "Yi Dai", "Shuhan Pan", "Yiwen Zhang", "Qi Wang", "Weiwei Guo", "Xiaohua Sun"], "title": "GenFaceUI: Meta-Design of Generative Personalized Facial Expression Interfaces for Intelligent Agents", "comment": "To appear at ACM CHI '26", "summary": "This work investigates generative facial expression interfaces for intelligent agents from a meta-design perspective. We propose the Generative Personalized Facial Expression Interface (GPFEI) framework, which organizes rule-bounded spaces, character identity, and context--expression mapping to address challenges of control, coherence, and alignment in run-time facial expression generation. To operationalize this framework, we developed GenFaceUI, a proof-of-concept tool that enables designers to create templates, apply semantic tags, define rules, and iteratively test outcomes. We evaluated the tool through a qualitative study with twelve designers. The results show perceived gains in controllability and consistency, while revealing needs for structured visual mechanisms and lightweight explanations. These findings provide a conceptual framework, a proof-of-concept tool, and empirical insights that highlight both opportunities and challenges for advancing generative facial expression interfaces within a broader meta-design paradigm.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.11074", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.11074", "abs": "https://arxiv.org/abs/2602.11074", "authors": ["Bingyi Han", "Ying Ma", "Simon Coghlan", "Dana McKay", "George Buchanan", "Wally Smith"], "title": "AI Sensing and Intervention in Higher Education: Student Perceptions of Learning Impacts, Affective Responses, and Ethical Priorities", "comment": "Accepted to CHI 2026. This is the accepted author version", "summary": "AI technologies that sense student attention and emotions to enable more personalised teaching interventions are increasingly promoted, but raise pressing questions about student learning, well-being, and ethics. In particular, students' perspectives about AI sensing-intervention in learning are often overlooked. We conducted an online mixed-method experiment with Australian university students (N=132), presenting video scenarios varying by whether sensing was used (in-use vs. not-in-use), sensing modality (gaze-based attention detection vs. facial-based emotion detection), and intervention (by digital device vs. teacher). Participants also completed pairwise ranking tasks to prioritise six core ethical concerns. Findings revealed that students valued targeted intervention but responded negatively to AI monitoring, regardless of sensing methods. Students preferred system-generated hints over teacher-initiated assistance, citing learning agency and social embarrassment concerns. Students' ethical considerations prioritised autonomy and privacy, followed by transparency, accuracy, fairness, and learning beneficence. We advocate designing customisable, social-sensitive, non-intrusive systems that preserve student control, agency, and well-being.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.11141", "categories": ["cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.11141", "abs": "https://arxiv.org/abs/2602.11141", "authors": ["Yu Wang", "Frederik L. Dennig", "Michael Behrisch", "Alexandru Telea"], "title": "LCIP: Loss-Controlled Inverse Projection of High-Dimensional Image Data", "comment": null, "summary": "Projections (or dimensionality reduction) methods $P$ aim to map high-dimensional data to typically 2D scatterplots for visual exploration. Inverse projection methods $P^{-1}$ aim to map this 2D space to the data space to support tasks such as data augmentation, classifier analysis, and data imputation. Current $P^{-1}$ methods suffer from a fundamental limitation -- they can only generate a fixed surface-like structure in data space, which poorly covers the richness of this space. We address this by a new method that can `sweep' the data space under user control. Our method works generically for any $P$ technique and dataset, is controlled by two intuitive user-set parameters, and is simple to implement. We demonstrate it by an extensive application involving image manipulation for style transfer.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
