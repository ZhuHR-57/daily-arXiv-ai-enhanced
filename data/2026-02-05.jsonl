{"id": "2602.04234", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2602.04234", "abs": "https://arxiv.org/abs/2602.04234", "authors": ["Yuxuan Zhao", "Sijia Chen", "Ningxin Su"], "title": "On the Uncertainty of Large Language Model-Based Multi-Agent Systems", "comment": null, "summary": "Multi-agent systems (MAS) have emerged as a prominent paradigm for leveraging large language models (LLMs) to tackle complex tasks. However, the mechanisms governing the effectiveness of MAS built upon publicly available LLMs, specifically the underlying rationales for their success or failure, remain largely unexplored. In this paper, we revisit MAS through the perspective of uncertainty, considering both intra- and inter-agent dynamics by investigating entropy transitions during problem-solving across various topologies and six benchmark tasks. By analyzing 245 features spanning token-, trajectory-, and round-level entropy, we counterintuitively find that a single agent outperforms MAS in approximately 43.3% of cases, and that uncertainty dynamics are largely determined during the first round of interaction. Furthermore, we provide three key observations: 1) Certainty Preference: reducing uncertainty at any stage for any agent is critical for guaranteeing correct solutions; 2) Base Uncertainty: base models with lower entropy during problem-solving directly benefit MAS performance; and 3) Task Awareness: entropy dynamics of MAS play varying roles across different tasks. Building on these insights, we introduce a simple yet effective algorithm, the Entropy Judger, to select solutions from MAS's pass@k results, leading to consistent accuracy improvements across all MAS configurations and tasks. Our source code is available at https://github.com/AgenticFinLab/multiagent-entropy."}
{"id": "2602.04418", "categories": ["cs.MA", "cs.AI", "cs.DC", "cs.ET", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.04418", "abs": "https://arxiv.org/abs/2602.04418", "authors": ["Arnab Mallick", "Indraveni Chebolu", "Harmesh Rana"], "title": "SPEAR: An Engineering Case Study of Multi-Agent Coordination for Smart Contract Auditing", "comment": null, "summary": "We present SPEAR, a multi-agent coordination framework for smart contract auditing that applies established MAS patterns in a realistic security analysis workflow. SPEAR models auditing as a coordinated mission carried out by specialized agents: a Planning Agent prioritizes contracts using risk-aware heuristics, an Execution Agent allocates tasks via the Contract Net protocol, and a Repair Agent autonomously recovers from brittle generated artifacts using a programmatic-first repair policy. Agents maintain local beliefs updated through AGM-compliant revision, coordinate via negotiation and auction protocols, and revise plans as new information becomes available. An empirical study compares the multi-agent design with centralized and pipeline-based alternatives under controlled failure scenarios, focusing on coordination, recovery behavior, and resource use."}
{"id": "2602.04130", "categories": ["cs.GR", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.04130", "abs": "https://arxiv.org/abs/2602.04130", "authors": ["Tiroshan Madushanka", "Sakuna Madushanka"], "title": "Multi-threaded Recast-Based A* Pathfinding for Scalable Navigation in Dynamic Game Environments", "comment": null, "summary": "While the A* algorithm remains the industry standard for game pathfinding, its integration into dynamic 3D environments faces trade-offs between computational performance and visual realism. This paper proposes a multi-threaded framework that enhances standard A* through Recast-based mesh generation, Bezier-curve trajectory smoothing, and density analysis for crowd coordination. We evaluate our system across ten incremental phases, from 2D mazes to complex multi-level dynamic worlds. Experimental results demonstrate that the framework maintains 350+ FPS with 1000 simultaneous agents and achieves collision-free crowd navigation through density-aware path coordination."}
{"id": "2602.04035", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2602.04035", "abs": "https://arxiv.org/abs/2602.04035", "authors": ["Thomas Neuner", "Henriette Padberg", "Lior Kornblum", "Eilam Yalon", "Pedram Khalili Amiri", "Shahar Kvatinsky"], "title": "A Comparative Study of Digital Memristor-Based Processing-In-Memory from a Device and Reliability Perspective", "comment": "23 pages, 12 figures, 3 tables, invited review paper, published in: https://advanced.onlinelibrary.wiley.com/doi/full/10.1002/aelm.202500348, T. Neuner and H. Padberg contributed equally to the work, S. Kvatinsky is the corresponding author", "summary": "As data-intensive applications increasingly strain conventional computing systems, processing-in-memory (PIM) has emerged as a promising paradigm to alleviate the memory wall by minimizing data transfer between memory and processing units. This review presents the recent advances in both stateful and non-stateful logic techniques for PIM, focusing on emerging nonvolatile memory technologies such as resistive random-access memory (RRAM), phase-change memory (PCM), and magnetoresistive random-access memory (MRAM). Both experimentally demonstrated and simulated logic designs are critically examined, highlighting key challenges in reliability and the role of device-level optimization in enabling scalable and commercial viable PIM systems. The review begins with an overview of relevant logic families, memristive device types, and associated reliability metrics. Each logic family is then explored in terms of how it capitalizes on distinct device properties to implement logic techniques. A comparative table of representative device stacks and performance parameters illustrates trade-offs and quality indicators. Through this comprehensive analysis, the development of optimized, robust memristive devices for next-generation PIM applications is supported."}
{"id": "2602.03849", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03849", "abs": "https://arxiv.org/abs/2602.03849", "authors": ["Keyu Zhao", "Fengli Xu", "Yong Li", "Tie-Yan Liu"], "title": "HybridQuestion: Human-AI Collaboration for Identifying High-Impact Research Questions", "comment": "16 pages, 6 figures, 4 tables", "summary": "The \"AI Scientist\" paradigm is transforming scientific research by automating key stages of the research process, from idea generation to scholarly writing. This shift is expected to accelerate discovery and expand the scope of scientific inquiry. However, a key question remains unclear: can AI scientists identify meaningful research questions? While Large Language Models (LLMs) have been applied successfully to task-specific ideation, their potential to conduct strategic, long-term assessments of past breakthroughs and future questions remains largely unexplored. To address this gap, we explore a human-AI hybrid solution that integrates the scalable data processing capabilities of AI with the value judgment of human experts. Our methodology is structured in three phases. The first phase, AI-Accelerated Information Gathering, leverages AI's advantage in processing vast amounts of literature to generate a hybrid information base. The second phase, Candidate Question Proposing, utilizes this synthesized data to prompt an ensemble of six diverse LLMs to propose an initial candidate pool, filtered via a cross-model voting mechanism. The third phase, Hybrid Question Selection, refines this pool through a multi-stage filtering process that progressively increases human oversight. To validate this system, we conducted an experiment aiming to identify the Top 10 Scientific Breakthroughs of 2025 and the Top 10 Scientific Questions for 2026 across five major disciplines. Our analysis reveals that while AI agents demonstrate high alignment with human experts in recognizing established breakthroughs, they exhibit greater divergence in forecasting prospective questions, suggesting that human judgment remains crucial for evaluating subjective, forward-looking challenges."}
{"id": "2602.04292", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2602.04292", "abs": "https://arxiv.org/abs/2602.04292", "authors": ["Seong-Eun Hong", "JaeYoung Seon", "JuYeong Hwang", "JongHwan Shin", "HyeongYeop Kang"], "title": "Event-T2M: Event-level Conditioning for Complex Text-to-Motion Synthesis", "comment": "28 pages, 7 figures. Accepted to ICLR 2026", "summary": "Text-to-motion generation has advanced with diffusion models, yet existing systems often collapse complex multi-action prompts into a single embedding, leading to omissions, reordering, or unnatural transitions. In this work, we shift perspective by introducing a principled definition of an event as the smallest semantically self-contained action or state change in a text prompt that can be temporally aligned with a motion segment. Building on this definition, we propose Event-T2M, a diffusion-based framework that decomposes prompts into events, encodes each with a motion-aware retrieval model, and integrates them through event-based cross-attention in Conformer blocks. Existing benchmarks mix simple and multi-event prompts, making it unclear whether models that succeed on single actions generalize to multi-action cases. To address this, we construct HumanML3D-E, the first benchmark stratified by event count. Experiments on HumanML3D, KIT-ML, and HumanML3D-E show that Event-T2M matches state-of-the-art baselines on standard tests while outperforming them as event complexity increases. Human studies validate the plausibility of our event definition, the reliability of HumanML3D-E, and the superiority of Event-T2M in generating multi-event motions that preserve order and naturalness close to ground-truth. These results establish event-level conditioning as a generalizable principle for advancing text-to-motion generation beyond single-action prompts."}
{"id": "2602.04164", "categories": ["cs.ET", "stat.AP", "stat.CO", "stat.OT"], "pdf": "https://arxiv.org/pdf/2602.04164", "abs": "https://arxiv.org/abs/2602.04164", "authors": ["Yuan Cai", "Mustafa Demir", "Farzan Sasangohar", "Mohsen Zare"], "title": "The Dynamics of Attention across Automated and Manual Driving Modes: A Driving Simulation Study", "comment": null, "summary": "This study aims to explore the dynamics of driver attention to various zones, including the road, the central mirror, the embedded Human-Machine Interface (HMI), and the speedometer, across different driving modes in AVs. The integration of autonomous vehicles (AVs) into transportation systems has introduced critical safety concerns, particularly regarding driver re-engagement during mode transitions. Past accidents underscore the risks of overreliance on automation and highlight the need to understand dynamic attention allocation to support safety in autonomous driving. A high-fidelity driving simulation was conducted. Eye-tracking technology was used to measure fixation duration, fixation count, and time to first fixation across distinct driving modes (automated, manual, and transition), which were then used to assess how drivers allocated attention to various areas of interest (AOIs). Findings show that drivers' attention varies significantly across driving modes. In manual mode, attention consistently focuses on the road, while in automated mode, prolonged fixation on the embedded HMI was observed. During the handover and takeover phases, attention shifts dynamically between environmental and technological elements. The study reveals that driver attention allocation is mode-dependent. These findings inform the design of adaptive HMIs in AVs that align with drivers' attention patterns. By presenting relevant information according to the driving context, such systems can enhance driver-vehicle interaction, support effective transitions, and improve overall safety. Systematic analysis of visual attention dynamics across driving modes is gaining prominence, as it informs adaptive HMI designs and driver readiness interventions. The GLMM findings can be directly applied to the design of adaptive HMIs or driver training programs to enhance attention and improve safety."}
{"id": "2602.03850", "categories": ["cs.HC", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.03850", "abs": "https://arxiv.org/abs/2602.03850", "authors": ["Amber Yijia Zheng", "Jae Joong Lee", "Bedrich Benes", "Raymond A. Yeh"], "title": "WebAccessVL: Making an Accessible Web via Violation-Conditioned VLM", "comment": null, "summary": "We present a vision-language model (VLM) that automatically edits website HTML to address Web Content Accessibility Guidelines 2 (WCAG2) violations. We formulate this as a supervised image-conditioned program synthesis task, where the model learns to correct HTML given the HTML and its rendering. We collected WebAccessVL, a new dataset with manually corrected accessibility violations, establishing paired training data. We then propose a violation-conditioned VLM that additionally conditions on the WCAG2 violation count to guide the correction process. Experiments demonstrate that our method effectively reduces the average number of violations from 5.34 to 0.44 per website, outperforming commercial LLM APIs (Gemini, GPT-5). A perceptual study confirms that our edited websites maintain the original visual appearance and content."}
{"id": "2602.04805", "categories": ["cs.GR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04805", "abs": "https://arxiv.org/abs/2602.04805", "authors": ["Jia-peng Zhang", "Cheng-Feng Pu", "Meng-Hao Guo", "Yan-Pei Cao", "Shi-Min Hu"], "title": "Skin Tokens: A Learned Compact Representation for Unified Autoregressive Rigging", "comment": "14 pages, 10 figures", "summary": "The rapid proliferation of generative 3D models has created a critical bottleneck in animation pipelines: rigging. Existing automated methods are fundamentally limited by their approach to skinning, treating it as an ill-posed, high-dimensional regression task that is inefficient to optimize and is typically decoupled from skeleton generation. We posit this is a representation problem and introduce SkinTokens: a learned, compact, and discrete representation for skinning weights. By leveraging an FSQ-CVAE to capture the intrinsic sparsity of skinning, we reframe the task from continuous regression to a more tractable token sequence prediction problem. This representation enables TokenRig, a unified autoregressive framework that models the entire rig as a single sequence of skeletal parameters and SkinTokens, learning the complicated dependencies between skeletons and skin deformations. The unified model is then amenable to a reinforcement learning stage, where tailored geometric and semantic rewards improve generalization to complex, out-of-distribution assets. Quantitatively, the SkinTokens representation leads to a 98%-133% percents improvement in skinning accuracy over state-of-the-art methods, while the full TokenRig framework, refined with RL, enhances bone prediction by 17%-22%. Our work presents a unified, generative approach to rigging that yields higher fidelity and robustness, offering a scalable solution to a long-standing challenge in 3D content creation."}
{"id": "2602.04411", "categories": ["cs.ET", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.04411", "abs": "https://arxiv.org/abs/2602.04411", "authors": ["Tongtong Feng", "Xin Wang", "Wenwu Zhu"], "title": "Self-evolving Embodied AI", "comment": null, "summary": "Embodied Artificial Intelligence (AI) is an intelligent system formed by agents and their environment through active perception, embodied cognition, and action interaction. Existing embodied AI remains confined to human-crafted setting, in which agents are trained on given memory and construct models for given tasks, enabling fixed embodiments to interact with relatively static environments. Such methods fail in in-the-wild setting characterized by variable embodiments and dynamic open environments. This paper introduces self-evolving embodied AI, a new paradigm in which agents operate based on their changing state and environment with memory self-updating, task self-switching, environment self-prediction, embodiment self-adaptation, and model self-evolution, aiming to achieve continually adaptive intelligence with autonomous evolution. Specifically, we present the definition, framework, components, and mechanisms of self-evolving embodied AI, systematically review state-of-the-art works for realized components, discuss practical applications, and point out future research directions. We believe that self-evolving embodied AI enables agents to autonomously learn and interact with environments in a human-like manner and provide a new perspective toward general artificial intelligence."}
{"id": "2602.03851", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.03851", "abs": "https://arxiv.org/abs/2602.03851", "authors": ["Wisnu Uriawan", "Denis Firmansyah", "Devi Mulyana", "Dika Haekal Firza Pratama", "Adly Juliarta Lerian", "Fajar Satria Wiguna"], "title": "Gamification-Based Learning Method for Hijaiyah Letters", "comment": "12 pages. 13 figures, and 2 tables", "summary": "The mastery of Hijaiyah letters is a crucial foundation for reading and comprehending the Quran, yet conventional pedagogical approaches based on repetitive memorization frequently struggle to maintain the engagement of young learners in contemporary educational contexts. This research presents the design and implementation of an innovative gamification-based methodology for Hijaiyah literacy acquisition, systematically developed through the ADDIE framework (Analysis, Design, Development, Implementation, Evaluation) to optimize student motivation, participation, and educational outcomes. The resulting technological solution, engineered using Unity 2D and Firebase, strategically incorporates game design elements such as points, badges, leaderboards, and progressive leveling, while integrating multifaceted learning components including visual animations, authentic tajwid-based audio pronunciation, and interactive letter tracing exercises to simultaneously develop cognitive recognition capabilities and fine motor skills. Empirical evaluation involving 50 elementary school participants revealed substantial quantitative improvements, with mean assessment scores increasing from 42.8 to 88.6 (107% improvement, p < 0.001), demonstrating an exceptionally large effect size (Cohen's d = 4.87), complemented by strong user engagement metrics (4.2 average daily sessions) and high satisfaction ratings (4.82 out of 5 mean motivation score). Beyond cognitive learning outcomes, the gamified approach effectively fostered intrinsic Islamic values such as perseverance, responsibility, and disciplined practice, thereby establishing an innovative educational paradigm that successfully integrates traditional Islamic pedagogical principles with modern digital learning technologies to create a transformative, engaging, and meaningful framework for Hijaiyah literacy development in contemporary Islamic education."}
{"id": "2602.04495", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2602.04495", "abs": "https://arxiv.org/abs/2602.04495", "authors": ["Maher Harb", "Nader Foroughi", "Matt Stehman", "Bob Lutz", "Nati Erez", "Erik Garcell"], "title": "Quantum-Based Resilient Routing in Networks: Minimizing Latency Under Dual-Link Failures", "comment": "15 pages, 4 figures", "summary": "Network optimization problems represent large combinatorial search spaces that grow exponentially with network size, making them computationally intensive to solve. This paper addresses the latency-resilient Layer 3 routing optimization problem in telecommunications networks with predefined Layer 1 optical links. We formulate this problem as a graph-based optimization problem with the objective of minimizing latency, creating vertex-disjoint paths from each site to the internet backbone, and maximizing overall resiliency by limiting the impact of dual-link failures. By framing the problem as finding two disjoint shortest paths, coupled together with a resiliency component to the objective function, we establish a single formulation to produce optimal path design. The mathematical formulation was adapted to solve the problem using quantum approximate optimization algorithm (QAOA) executed over both quantum simulator and quantum hardware. QAOA was tested on a toy graph topology with 5 vertices and 7 edges and considering two limiting scenarios respectively representing independent (uncorrelated) link failures and highly correlated failure for one pair of edges. Both explored scenarios produced the optimal network design-corresponding to the valid solution with highest frequency of occurrence and minimum energy state, hence, validating the proposed formulation for optimizing Layer 3 routing on quantum systems of the future."}
{"id": "2602.03852", "categories": ["cs.HC", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.03852", "abs": "https://arxiv.org/abs/2602.03852", "authors": ["Chan-in Sio", "Alex Mann", "Lingxi Fan", "Andrew Cheung", "Lik-hang Lee"], "title": "Perceptions of AI-CBT: Trust and Barriers in Chinese Postgrads", "comment": "Accepted and presented in The 30th International Conference on Technologies and Applications of Artificial Intelligence in Taipei, Taiwan on 13-14 December 2025 (TAAI 2025)", "summary": "The mental well-being of graduate students is an increasing concern, yet the adoption of scalable support remains uneven. Artificial intelligence-powered cognitive behavioral therapy chatbots (AI-CBT) offer low barrier help, but little is known about how Chinese postgraduates perceive and use them. This qualitative study explored perceptions and experiences of AI-CBT chatbots among ten Chinese graduate students recruited through social media. Semi-structured Zoom interviews were conducted and analyzed using reflexive thematic analysis, with the Health Belief Model (HBM) and the Theory of Planned Behavior (TPB) as sensitizing frameworks. The findings indicate a cautious openness to AI-CBT chatbots: perceived usefulness and 24/7 access supported favorable attitudes, while data privacy, emotional safety, and uncertainty about `fit' for complex problems restricted the intention to use. Social norms (e.g., stigma and peer views) and perceived control (digital literacy, language quality) further shaped adoption. The study offers context-specific information to guide the culturally sensitive design, communication, and deployment of AI mental well-being tools for student populations in China and outlines the design implications around transparency, safeguards, and graduated care pathways."}
{"id": "2602.04418", "categories": ["cs.MA", "cs.AI", "cs.DC", "cs.ET", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.04418", "abs": "https://arxiv.org/abs/2602.04418", "authors": ["Arnab Mallick", "Indraveni Chebolu", "Harmesh Rana"], "title": "SPEAR: An Engineering Case Study of Multi-Agent Coordination for Smart Contract Auditing", "comment": null, "summary": "We present SPEAR, a multi-agent coordination framework for smart contract auditing that applies established MAS patterns in a realistic security analysis workflow. SPEAR models auditing as a coordinated mission carried out by specialized agents: a Planning Agent prioritizes contracts using risk-aware heuristics, an Execution Agent allocates tasks via the Contract Net protocol, and a Repair Agent autonomously recovers from brittle generated artifacts using a programmatic-first repair policy. Agents maintain local beliefs updated through AGM-compliant revision, coordinate via negotiation and auction protocols, and revise plans as new information becomes available. An empirical study compares the multi-agent design with centralized and pipeline-based alternatives under controlled failure scenarios, focusing on coordination, recovery behavior, and resource use."}
{"id": "2602.03853", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.03853", "abs": "https://arxiv.org/abs/2602.03853", "authors": ["Saizo Aoyagi", "Ryoma Okazaki", "Seishiro Hara", "Fumiya Ikeda", "Michiya Yamamoto"], "title": "On-Demand Lecture Watching System Using Various Actions of Student Characters to Maintain Concentration", "comment": "This is the author's final draft of Aoyagi, S., Okazaki, R., Hara, S., Ikeda, F., Yamamoto, M. (2025). On-Demand Lecture Watching System Using Various Actions of Student Characters to Maintain Concentration. In: Mori, H., Asahi, Y. (eds) Human Interface and the Management of Information. HCII 2025. Lecture Notes in Computer Science, vol 15774. Springer, Cham", "summary": "Since the COVID-19 pandemic, online lectures have spread rapidly and many students are satisfied with them. However, one challenge remains the loss of concentration due to the lack of students' copresence. Our previous work suggests that presenting 3D characters with appropriate actions has the potential to improve concentration in online lectures. Nevertheless, an effective combination of actions has not yet been identified. In this study, we developed a lecture watching system that presents a 3D virtual classroom using a naked-eye 3D display. The system includes student characters that show copresence with various actions such as nodding, notetaking, and sleeping. An evaluation experiment was conducted with two conditions; (1) student characters perform only positive actions and (2) both positive and negative actions. The results, analyzed using posture and notetaking behavior as key indicators, suggest that the system can help to maintain concentration when the student characters perform both positive and negative actions, rather than only positive ones. These findings provide promising strategies for maintaining student focus in on-demand lectures and contribute to the development of more effective online education systems."}
{"id": "2602.04621", "categories": ["cs.HC", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.04621", "abs": "https://arxiv.org/abs/2602.04621", "authors": ["Yi Wang", "Ben Cheng", "Xiao Liu", "Chetan Arora", "John Grundy", "Thuong Hoang"], "title": "VRARE: Using Virtual Reality to Understand Accessibility Requirements of Color Blindness and Weakness", "comment": "IEEE VR 26 Poster", "summary": "In this paper, we developed a virtual reality (VR) system that can simulate color blindness and weakness. We built an immersive 3D web view interface where participants can discuss accessibility requirements for a fitness website projects within a virtual fitness environment. We conducted a pilot experiment involving 24 participants from six software teams, who used both VR and non-VR methods to understand color blindness and weakness requirements in a website project. Our findings indicate that using VR can provide several benefits for requirements activities, such as an improved user experience and reduced workload."}
{"id": "2602.03854", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.03854", "abs": "https://arxiv.org/abs/2602.03854", "authors": ["Mona Alfayez", "Ohoud Alharbi"], "title": "From Expectation To Experience: A Before And After Survey Of Public Opinion On Autonomous Cars In Saudi Arabia", "comment": null, "summary": "Autonomous vehicles (AVs) are emerging as a transformative innovation in transportation, offering potential benefits in safety, sustainability, and efficiency. Saudi Arabian adoption of AVs aligns with Vision 2030, emphasizing smart mobility through initiatives such as the Riyadh Autonomous Metro and self-driving cars. This study explores Saudi citizens perceptions of AVs before and after exposure to these technologies and examines whether demographic factors age, gender, education level, and driving habits affect acceptance. Using quantitative methods, the findings provide insights into the broader influences shaping AV adoption, highlighting the importance of trust, perceived safety, and convenience. These results can inform policymakers and industry stakeholders on strategies to facilitate successful integration of AVs into Saudi Arabian transportation ecosystem."}
{"id": "2602.03958", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.03958", "abs": "https://arxiv.org/abs/2602.03958", "authors": ["Lingqing Wang", "Yingting Gao", "Chidimma Lois Anyi", "Ashok Goel"], "title": "Futuring Social Assemblages: How Enmeshing AIs into Social Life Challenges the Individual and the Interpersonal", "comment": "Accepted by CHI'26", "summary": "Recent advances in AI are integrating AI into the fabric of human social life, creating transformative, co-shaping relationships between humans and AI. This trend makes it urgent to investigate how these systems, in turn, shape their users. We conducted a three-phase design study with 24 participants to explore this dynamic. Our findings reveal critical tensions: (1) social AI often exacerbates the very interpersonal problems it is designed to mitigate; (2) it introduces nuanced privacy harms for secondary users inadvertently involved in AI-mediated social interactions; and (3) it can threaten the primary user's personal agency and identity. We argue these tensions expose a problematic tendency in the user-centered paradigm, which often prioritizes immediate user experience at the expense of core human values like interpersonal ethics and self-efficacy. We call for a paradigm shift toward a more provocative and relational design perspective that foregrounds long-term social and personal consequences."}
{"id": "2602.04000", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.04000", "abs": "https://arxiv.org/abs/2602.04000", "authors": ["Ziyi Xuan", "Yiwen Wu", "Zhaoyang Yan", "Vinod Namboodiri", "Yu Yang"], "title": "After Talking with 1,000 Personas: Learning Preference-Aligned Proactive Assistants From Large-Scale Persona Interactions", "comment": null, "summary": "Smart assistants increasingly act proactively, yet mistimed or intrusive behavior often causes users to lose trust and disable these features. Learning user preferences for proactive assistance is difficult because real-world studies are costly, limited in scale, and rarely capture how preferences change across multiple interaction sessions. Large language model based generative agents offer a way to simulate realistic interactions, but existing synthetic datasets remain limited in temporal depth, diverse personas, and multi-dimensional preferences. They also provide little support for transferring population-level insights to individual users under on-device constraints. We present a population-to-individual learning framework for preference-aligned proactive assistants that operates under on-device and privacy constraints. Our approach uses large-scale interaction simulation with 1,000 diverse personas to learn shared structure in how users express preferences across recurring dimensions such as timing, autonomy, and communication style, providing a strong cold start without relying on real user logs. The assistant then adapts to individual users on device through lightweight activation-based steering driven by simple interaction feedback, without model retraining or cloud-side updates. We evaluate the framework using controlled simulations with 1,000 simulated personas and a human-subject study with 30 participants. Results show improved timing decisions and perceived interaction quality over untuned and direct-response baselines, while on-device activation steering achieves performance comparable to reinforcement learning from human feedback. Participants also report higher satisfaction, trust, and comfort as the assistant adapts over multiple sessions of interactions."}
{"id": "2602.04015", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.04015", "abs": "https://arxiv.org/abs/2602.04015", "authors": ["Crescentia Jung", "Kexin Cheng", "Sharon Heung", "Malte F. Jung", "Shiri Azenkot"], "title": "Understanding How Accessibility Practices Impact Teamwork in Mixed-Ability Teams that Collaborate Virtually", "comment": null, "summary": "Virtual collaboration has transformed how people in mixed-ability teams, composed of disabled and non-disabled people, work together by offering greater flexibility. In these settings, accessibility practices, such as accommodations and inclusive norms, are essential for providing access to disabled people. However, we do not yet know how these practices shape broader facets of teamwork, such as productivity, participation, and camaraderie. To address this gap, we interviewed 18 participants (12 disabled, 6 non-disabled) who are part of mixed-ability teams. We found that beyond providing access, accessibility practices shaped how all participants coordinated tasks, sustained rapport, and negotiated responsibilities. Accessibility practices also introduced camaraderie challenges, such as balancing empathy and accountability. Non-disabled participants described allyship as a learning process and skill shaped by their disabled team members and team culture. Based on our findings, we present recommendations for team practices and design opportunities for virtual collaboration tools that reframe accessibility practices as a foundation for strong teamwork."}
{"id": "2602.04017", "categories": ["cs.HC", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.04017", "abs": "https://arxiv.org/abs/2602.04017", "authors": ["Joel Wester", "Samuel Rhys Cox", "Henning Pohl", "Niels van Berkel"], "title": "Chaplains' Reflections on the Design and Usage of AI for Conversational Care", "comment": "To appear at ACM CHI 2026. 15 pages, 2 figures, 3 tables", "summary": "Despite growing recognition that responsible AI requires domain knowledge, current work on conversational AI primarily draws on clinical expertise that prioritises diagnosis and intervention. However, much of everyday emotional support needs occur in non-clinical contexts, and therefore requires different conversational approaches. We examine how chaplains, who guide individuals through personal crises, grief, and reflection, perceive and engage with conversational AI. We recruited eighteen chaplains to build AI chatbots. While some chaplains viewed chatbots with cautious optimism, the majority expressed limitations of chatbots' ability to support everyday well-being. Our analysis reveals how chaplains perceive their pastoral care duties and areas where AI chatbots fall short, along the themes of Listening, Connecting, Carrying, and Wanting. These themes resonate with the idea of attunement, recently highlighted as a relational lens for understanding the delicate experiences care technologies provide. This perspective informs chatbot design aimed at supporting well-being in non-clinical contexts."}
{"id": "2602.04023", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.04023", "abs": "https://arxiv.org/abs/2602.04023", "authors": ["Runlong Ye", "Oliver Huang", "Jessica He", "Michael Liut"], "title": "Exploring Emerging Norms of AI Disclosure in Programming Education", "comment": null, "summary": "Generative AI blurs the lines of authorship in computing education, creating uncertainty around how students should attribute AI assistance. To examine these emerging norms, we conducted a factorial vignette study with 94 computer science students across 102 unique scenarios, systematically manipulating assessment type, AI autonomy, student activity, prior knowledge, and human refinement effort. This paper details how these factors influence students' perceptions of ownership and disclosure preferences. Our findings indicate that attribution judgments are primarily driven by different levels of AI assistance and human refinement. We also found that students' perception of authorship significantly predicts their policy expectations. We conclude by proposing a shift from statement-style policies to process-oriented attribution, transforming disclosure into a pedagogical mechanism for fostering critical engagement with AI-generated content."}
{"id": "2602.04047", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.04047", "abs": "https://arxiv.org/abs/2602.04047", "authors": ["Yijun Liu", "John Gallagher", "Sarah Sterman", "Tal August"], "title": "From Crafting Text to Crafting Thought: Grounding AI Writing Support to Writing Center Pedagogy", "comment": "Conditionally accepted to CHI 26", "summary": "As AI writing tools evolve from fixing surface errors to creating language with writers, new capabilities raise concerns about negative impacts on student writers, such as replacing their voices and undermining critical thinking skills. To address these challenges, we look at a parallel transition in university writing centers from focusing on fixing errors to preserving student voices. We develop design guidelines informed by writing center literature and interviews with 10 writing tutors. We illustrate these guidelines in a prototype AI tool, Writor. Writor helps writers revise text by setting goals, providing balanced feedback, and engaging in conversations without generating text verbatim. We conducted an expert review with 30 writing instructors, tutors, and AI researchers on Writor to assess the pedagogical soundness, alignment with writing center pedagogy, and integration contexts. We distill our findings into design implications for future AI writing feedback systems, including designing for trust among AI-skeptical educators."}
{"id": "2602.04104", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.04104", "abs": "https://arxiv.org/abs/2602.04104", "authors": ["Adriana Olmos", "Anoop K. Sinha", "Renelito Delos Santos", "Ruben Rodriguez Rodriguez", "James A. Landay", "Sam S. Sepah", "Philip Nelson", "Shaun K. Kane"], "title": "Making Videos Accessible for Blind and Low Vision Users Using a Multimodal Agent Video Player", "comment": null, "summary": "Video content remains largely inaccessible to blind and low-vision (BLV) users. To address this, we introduce a prototype that leverages a multimodal agent - powered by a novel conversational architecture using a multimodal large language model (MLLM) - to provide BLV users with an interactive, accessible video experience. This Multimodal Agent Video Player (MAVP) demonstrates that an interactive accessibility mode can be added to a video through multilayered prompt orchestration. We describe a user-centered design process involving 18 sessions with BLV users that showed that BLV users do not just want accessibility features, but desire independence and personal agency over the viewing experience. We conducted a qualitative study with an additional 8 BLV participants; in this, we saw that the MAVP's conversational dialogue offers BLV users a sense of personal agency, fostering collaboration and trust. Even in the case of hallucinations, it is meta-conversational dialogues about AI's limitations that can repair trust."}
{"id": "2602.04109", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04109", "abs": "https://arxiv.org/abs/2602.04109", "authors": ["Nayoung Choi", "Jiseung Hong", "Peace Cyebukayire", "Ikseon Choi", "Jinho D. Choi"], "title": "Tinker Tales: Supporting Child-AI Collaboration through Co-Creative Storytelling with Educational Scaffolding", "comment": null, "summary": "Artificial intelligence (AI) is increasingly framed as a collaborative partner in creative activities, yet children's interactions with AI have largely been studied in AI-led instructional settings rather than co-creative collaboration. This leaves open questions about how children can meaningfully engage with AI through iterative co-creation. We present Tinker Tales, a tangible storytelling system designed with narrative and social-emotional scaffolding to support child-AI collaboration. The system combines a physical storytelling board, NFC-embedded toys representing story elements (e.g., characters, places, items, and emotions), and a mobile app that mediates child-AI interaction. Children shape and refine stories by placing and moving story elements and interacting with the AI through tangible and voice-based interaction. We conducted an exploratory user study with 10 children to examine how they interacted with Tinker Tales. Our findings show that children treated the AI as an attentive, responsive collaborator, while scaffolding supported coherent narrative refinement without diminishing children's agency."}
{"id": "2602.04138", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.04138", "abs": "https://arxiv.org/abs/2602.04138", "authors": ["Felicia Fang-Yi Tan", "Oded Nov"], "title": "Counting the Wait: Effects of Temporal Feedback on Downstream Task Performance and Perceived Wait-Time Experience during System-Imposed Delays", "comment": "To be published in ACM CHI 2026", "summary": "System-imposed wait times can significantly disrupt digital workflows, affecting user experience and task performance. Prior HCI research has examined how temporal feedback, such as feedback mode (Elapsed-Time vs. Remaining-Time) shapes wait-time perception. However, few studies have investigated how such feedback influences users' downstream task performance, as well as overall affective and cognitive experience. To study these effects, we conducted an online experiment where 425 participants performing a visual reasoning task experienced a 10-, 30-, or 60-second wait with a Remaining-Time, Elapsed-Time, or No Time Display. Findings show that temporal feedback mode shapes how waiting is perceived: Remaining-Time feedback increased frustration relative to Elapsed-Time feedback, while No Time Display made waits feel longer and heightened ambiguity. Notably, these experiential differences did not translate into differences in post-wait task performance. Integrating psychophysical and cognitive science perspectives, we discuss implications for implementing temporal feedback in latency-prone digital systems."}
{"id": "2602.04159", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.04159", "abs": "https://arxiv.org/abs/2602.04159", "authors": ["Gang Yu", "Yuchi Sun", "Weining Yan", "Xinyu Wang", "Qi Lu"], "title": "Paint by Odor: An Exploration of Odor Visualization through Large Language Model and Generative AI", "comment": null, "summary": "Odor visualization translates odor information and perception into visual outcomes and arouses the corresponding olfactory synesthesia, surpassing the spatial limitation that odors can only be perceived where they are present. Traditional odor visualization has typically relied on unidimensional mappings, such as odor-to-color associations, and has required extensive manual design efforts. However, the advent of generative AI (Gen AI) and large language models (LLMs) presents a new opportunity for automatic odor visualization. Nonetheless, gaps remain in bridging olfactory perception with generative tools to produce odor images. To address these gaps, this paper introduces Paint by Odor, a pipeline that leverages Gen AI and LLMs to transform olfactory perceptions into rich, aesthetically engaging visual representations. Two experiments were conducted, where 30 participants smelled real-world odors and provided descriptive data and 28 participants evaluated 560 generated odor images through seven systematically designed prompts. Our findings explored the capability of LLMs in producing olfactory perception by comparing it with human responses and revealed the underlying mechanisms and effects of language-based descriptions and several abstraction styles on odor visualization. Our work further discussed the possibility of automatic odor visualization without human participation. These explorations and results have bridged the research gap in odor visualization using LLMs and Gen AI, offering valuable design insights and various possibilities for future applications."}
{"id": "2602.04242", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.04242", "abs": "https://arxiv.org/abs/2602.04242", "authors": ["Mobasshira Akter Urmi", "Raiyan Abdul Baten"], "title": "Strategic Adaptation Under Contextual Change: Insights from a Dyadic Negotiation Testbed for AI Coaching Technologies", "comment": null, "summary": "Strategic adaptation -- the ability to adjust interaction behavior in response to changing constraints and leverage -- is a central goal of negotiation training and an emerging target for AI coaching systems. However, adaptation is difficult to evaluate because adaptation-relevant moments arise unpredictably in typical tasks. We study a reusable dyadic negotiation testbed that employs a controlled midstream change in one party's outside alternative as a repeatable perturbation to stress-test adaptation. In a six-round chat-based negotiation study (N=100), the perturbation reliably reorganized interaction dynamics: transitions between integrative (cooperative) and distributive (positional) behaviors declined, behavioral diversity narrowed, and interactions drifted toward more distributive tactics. Critically, this distributive drift predicted worse relational experience net of objective outcomes, and adaptation patterns were path dependent on prior behavior. These results establish a methodological bridge for evaluating and comparing AI coaching systems on strategic adaptation as a process and identify failure modes and design targets for adaptive interaction support."}
{"id": "2602.04299", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.04299", "abs": "https://arxiv.org/abs/2602.04299", "authors": ["Lufeng Feng", "Baomin Xu", "Haoran Zhang", "Bihai Lin", "Zuxuan Deng", "Sidi Tao", "Chenyu Liu", "Shifan Jia", "Li Duan", "Ziyu Jia"], "title": "A Multimodal fNIRS-EEG Dataset for Unilateral Limb Motor Imagery", "comment": "17 pages, 12 figures", "summary": "Unilateral limb motor imagery (MI) plays an important role in upper-limb motor rehabilitation and precise control of external devices, and places higher demands on spatial resolution. However, most existing public datasets focus on binary- or four-class left-right limb paradigms that mainly exploit coarse hemispheric lateralization, and there is still a lack of multimodal datasets that simultaneously record EEG and fNIRS for unilateral multi-directional MI. To address this gap, we constructed MIND, a public motor imagery fNIRS-EEG dataset based on a four-class directional MI paradigm of the right upper limb. The dataset includes 64-channel EEG recordings (1000 Hz) and 51-channel fNIRS recordings (47.62 Hz) from 30 participants (12 females, 18 males; aged 19.0-25.0 years). We analyse the spatiotemporal characteristics of EEG spectral power and hemodynamic responses, and validate the potential advantages of hybrid fNIRS-EEG BCIs in terms of classification accuracy. We expect that this dataset will facilitate the evaluation and comparison of neuroimaging analysis and decoding methods."}
{"id": "2602.04393", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.04393", "abs": "https://arxiv.org/abs/2602.04393", "authors": ["Ritik Batra", "Roy Zunder", "Amy Cheatle", "Amritansh Kwatra", "Ilan Mandel", "Thijs Roumen", "Steven J. Jackson"], "title": "Convivial Fabrication: Towards Relational Computational Tools For and From Craft Practices", "comment": "Conditionally accepted to ACM CHI 2026, Barcelona, Spain", "summary": "Computational tools for fabrication often treat materials as passive rather than active participants in design, abstracting away relationships between craftspeople and materials. For craft communities that value relational practices, abstractions limit the adoption and creative uptake of computational tools which might otherwise be beneficial. To understand how better tool design could support richer relations between individuals, tools, and materials, we interviewed expert woodworkers, fiber artists, and metalworkers. We identify three orders of convivial relations central to craft: immediate relations between individuals, tools, and materials; mid-range relations between communities, platforms, and shared materials; and extended relations between institutions, infrastructures, and ecologies. Our analysis shows how craftspeople engage and struggle with convivial relations across all three orders, creating workflows that learn from materials while supporting autonomy. We conclude with design principles for computational tools and infrastructures to better support material dialogue, collective knowledge, and accountability, along with richer and more convivial relations between craftspeople, tools, and the material worlds around them."}
{"id": "2602.04432", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.04432", "abs": "https://arxiv.org/abs/2602.04432", "authors": ["Shota Yamanaka", "I. Scott MacKenzie"], "title": "Normalizing Speed-accuracy Biases in 2D Pointing Tasks with Better Calculation of Effective Target Widths", "comment": "To appear at CHI 2026", "summary": "For evaluations of 2D target selection using Fitts' law, ISO 9241-411 recommends using the effective target width (W_e) calculated using the univariate standard deviation of selection coordinates. Related research proposed using a bivariate standard deviation; however, the proposal was only tested using a single speed-accuracy bias condition, thus the assessment was limited. We compared the univariate and bivariate techniques in a 2D Fitts' law experiment using three speed-accuracy biases and 346 crowdworkers. Calculating W_e using the univariate standard deviation yielded higher model correlations across all bias conditions and produced more stable throughput among the biases. The findings were also consistent in cases using randomly sampled subsets of the participant data. We recommend that future research should calculate W_e using the univariate standard deviation for fair performance evaluations. Also, we found trivial effects when using nominal or effective amplitude and using different perspectives of the task axis."}
{"id": "2602.04450", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.04450", "abs": "https://arxiv.org/abs/2602.04450", "authors": ["Suvadeep Mukherjee", "Bjrn Rohles", "Gabriele Lenzini", "Pedro Cardoso-Leite"], "title": "Can Theory-Informed Message Framing Drive Honest and Motivated Performance with Better Assessment Experiences in a Remote Assessment?", "comment": null, "summary": "Remote unproctored assessments increasingly use messaging interventions to reduce cheating, but existing approaches lack theoretical grounding, focus narrowly on cheating suppression while overlooking performance and experience, and treat cheating as binary rather than continuous. This study examines whether messages based on 15 psychological concepts from self-determination, cognitive dissonance, social norms, and self-efficacy theories can reduce cheating while preserving performance and experience. Through an expert workshop (N=5), we developed 45 theory-informed messages and tested them with online participants (N=1232) who completed an incentivized anagram task. Participants were classified as non-cheaters (0% items cheated), partial-cheaters (1-99% cheated), or full-cheaters (100% cheated). Results show that concept-based messages reduced full-cheating occurrence by 42% (33% to 19%), increased non-cheating by 19% (53% to 63%), with no negative effects on performance or experience across integrity groups. Surprisingly, messages grounded in different theoretical concepts produced virtually identical effects. Analyses of self-rated psychological mechanisms revealed that messages influenced multiple mechanisms simultaneously rather than their intended targets, though these mechanisms predicted behavior, performance, and experience. These findings show that causal pathways are more complex than current theories predict. Practically, integrity interventions using supportive motivation rather than rule enforcement can reduce cheating without impairing performance or experience."}
{"id": "2602.04458", "categories": ["cs.HC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.04458", "abs": "https://arxiv.org/abs/2602.04458", "authors": ["Yaxin Hu", "Masaki Kuribayashi", "Allan Wang", "Seita Kayukawa", "Daisuke Sato", "Bilge Mutlu", "Hironobu Takagi", "Chieko Asakawa"], "title": "Robot-Assisted Group Tours for Blind People", "comment": "In Proceedings of ACM CHI 2026 conference on Human Factors in Computing Systems", "summary": "Group interactions are essential to social functioning, yet effective engagement relies on the ability to recognize and interpret visual cues, making such engagement a significant challenge for blind people. In this paper, we investigate how a mobile robot can support group interactions for blind people. We used the scenario of a guided tour with mixed-visual groups involving blind and sighted visitors. Based on insights from an interview study with blind people (n=5) and museum experts (n=5), we designed and prototyped a robotic system that supported blind visitors to join group tours. We conducted a field study in a science museum where each blind participant (n=8) joined a group tour with one guide and two sighted participants (n=8). Findings indicated users' sense of safety from the robot's navigational support, concerns in the group participation, and preferences for obtaining environmental information. We present design implications for future robotic systems to support blind people's mixed-visual group participation."}
{"id": "2602.04478", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.04478", "abs": "https://arxiv.org/abs/2602.04478", "authors": ["Keya Shah", "Himanshi Lalwani", "Zein Mukhanov", "Hanan Salam"], "title": "Informing Robot Wellbeing Coach Design through Longitudinal Analysis of Human-AI Dialogue", "comment": null, "summary": "Social robots and conversational agents are being explored as supports for wellbeing, goal-setting, and everyday self-regulation. While prior work highlights their potential to motivate and guide users, much of the evidence relies on self-reported outcomes or short, researcher-mediated encounters. As a result, we know little about the interaction dynamics that unfold when people use such systems in real-world contexts, and how these dynamics should shape future robot wellbeing coaches. This paper addresses this gap through content analysis of 4352 messages exchanged longitudinally between 38 university students and an LLM-based wellbeing coach. Our results provide a fine-grained view into how users naturally shape, steer, and sometimes struggle within supportive human-AI dialogue, revealing patterns of user-led direction, guidance-seeking, and emotional expression. We discuss how these dynamics can inform the design of robot wellbeing coaches that support user autonomy, provide appropriate scaffolding, and uphold ethical boundaries in sustained wellbeing interactions."}
{"id": "2602.04482", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.04482", "abs": "https://arxiv.org/abs/2602.04482", "authors": ["Yuanbo Tang", "Huaze Tang", "Tingyu Cao", "Lam Nguyen", "Anping Zhang", "Xinwen Cao", "Chunkang Liu", "Wenbo Ding", "Yang Li"], "title": "Proactive Agents, Long-term User Context, VLM Annotation, Privacy Protection, Human-Computer Interaction", "comment": null, "summary": "Proactive agents that anticipate user intentions without explicit prompts represent a significant evolution in human-AI interaction, promising to reduce cognitive load and streamline workflows. However, existing datasets suffer from two critical deficiencies: (1) reliance on LLM-synthesized data that fails to capture authentic human decision-making patterns, and (2) focus on isolated tasks rather than continuous workflows, missing the pre-assistance behavioral context essential for learning proactive intervention signals. To address these gaps, we introduce ProAgentBench, a rigorous benchmark for proactive agents in working scenarios. Our contributions include: (1) a hierarchical task framework that decomposes proactive assistance into timing prediction and assist content generation; (2) a privacy-compliant dataset with 28,000+ events from 500+ hours of real user sessions, preserving bursty interaction patterns (burstiness B=0.787) absent in synthetic data; and (3) extensive experiments that evaluates LLM- and VLM-based baselines. Numerically, we showed that long-term memory and historical context significantly enhance prediction accuracy, while real-world training data substantially outperforms synthetic alternatives. We release our dataset and code at https://anonymous.4open.science/r/ProAgentBench-6BC0."}
{"id": "2602.04487", "categories": ["cs.HC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.04487", "abs": "https://arxiv.org/abs/2602.04487", "authors": ["Himanshi Lalwani", "Hanan Salam"], "title": "The Supportiveness-Safety Tradeoff in LLM Well-Being Agents", "comment": null, "summary": "Large language models (LLMs) are being integrated into socially assistive robots (SARs) and other conversational agents providing mental health and well-being support. These agents are often designed to sound empathic and supportive in order to maximize user's engagement, yet it remains unclear how increasing the level of supportive framing in system prompts influences safety relevant behavior. We evaluated 6 LLMs across 3 system prompts with varying levels of supportiveness on 80 synthetic queries spanning 4 well-being domains (1440 responses). An LLM judge framework, validated against human ratings, assessed safety and care quality. Moderately supportive prompts improved empathy and constructive support while maintaining safety. In contrast, strongly validating prompts significantly degraded safety and, in some cases, care across all domains, with substantial variation across models. We discuss implications for prompt design, model selection, and domain specific safeguards in SARs deployment."}
{"id": "2602.04540", "categories": ["cs.HC", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.04540", "abs": "https://arxiv.org/abs/2602.04540", "authors": ["Saleh Afzoon", "Amin Beheshti", "Usman Naseem"], "title": "PersoPilot: An Adaptive AI-Copilot for Transparent Contextualized Persona Classification and Personalized Response Generation", "comment": "Accepted for the Demo Track at the IEEE International Conference on Data Mining (ICDM) 2025", "summary": "Understanding and classifying user personas is critical for delivering effective personalization. While persona information offers valuable insights, its full potential is realized only when contextualized, linking user characteristics with situational context to enable more precise and meaningful service provision. Existing systems often treat persona and context as separate inputs, limiting their ability to generate nuanced, adaptive interactions. To address this gap, we present PersoPilot, an agentic AI-Copilot that integrates persona understanding with contextual analysis to support both end users and analysts. End users interact through a transparent, explainable chat interface, where they can express preferences in natural language, request recommendations, and receive information tailored to their immediate task. On the analyst side, PersoPilot delivers a transparent, reasoning-powered labeling assistant, integrated with an active learning-driven classification process that adapts over time with new labeled data. This feedback loop enables targeted service recommendations and adaptive personalization, bridging the gap between raw persona data and actionable, context-aware insights. As an adaptable framework, PersoPilot is applicable to a broad range of service personalization scenarios."}
{"id": "2602.04598", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.04598", "abs": "https://arxiv.org/abs/2602.04598", "authors": ["Lucile Favero", "Juan Antonio Prez-Ortiz", "Tanja Kser", "Nuria Oliver"], "title": "AI in Education Beyond Learning Outcomes: Cognition, Agency, Emotion, and Ethics", "comment": null, "summary": "Artificial intelligence (AI) is rapidly being integrated into educational contexts, promising personalized support and increased efficiency. However, growing evidence suggests that the uncritical adoption of AI may produce unintended harms that extend beyond individual learning outcomes to affect broader societal goals. This paper examines the societal implications of AI in education through an integrative framework with four interrelated dimensions: cognition, agency, emotional well-being, and ethics. Drawing on research from education, cognitive science, psychology, and ethics, we synthesize existing evidence to show how AI-driven cognitive offloading, diminished learner agency, emotional disengagement, and surveillance-oriented practices can mutually reinforce one another. We argue that these dynamics risk undermining critical thinking, intellectual autonomy, emotional resilience, and trust, capacities that are foundational both for effective learning and also for democratic participation and informed civic engagement. Moreover, AI's impact is contingent on design and governance: pedagogically aligned, ethically grounded, and human-centered AI systems can scaffold effortful reasoning, support learner agency, and preserve meaningful social interaction. By integrating fragmented strands of prior research into a unified framework, this paper advances the discourse on responsible AI in education and offers actionable implications for educators, designers, and institutions. Ultimately, the paper contends that the central challenge is not whether AI should be used in education, but how it can be designed and governed to support learning while safeguarding the social and civic purposes of education."}
{"id": "2602.04616", "categories": ["cs.HC", "cs.AI", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04616", "abs": "https://arxiv.org/abs/2602.04616", "authors": ["Luyi Sun", "Wei Xu", "Zaifeng Gao"], "title": "A Human-Centered Privacy Approach (HCP) to AI", "comment": null, "summary": "As the paradigm of Human-Centered AI (HCAI) gains prominence, its benefits to society are accompanied by significant ethical concerns, one of which is the protection of individual privacy. This chapter provides a comprehensive overview of privacy within HCAI, proposing a human-centered privacy (HCP) framework, providing integrated solution from technology, ethics, and human factors perspectives. The chapter begins by mapping privacy risks across each stage of AI development lifecycle, from data collection to deployment and reuse, highlighting the impact of privacy risks on the entire system. The chapter then introduces privacy-preserving techniques such as federated learning and dif erential privacy. Subsequent chapters integrate the crucial user perspective by examining mental models, alongside the evolving regulatory and ethical landscapes as well as privacy governance. Next, advice on design guidelines is provided based on the human-centered privacy framework. After that, we introduce practical case studies across diverse fields. Finally, the chapter discusses persistent open challenges and future research directions, concluding that a multidisciplinary approach, merging technical, design, policy, and ethical expertise, is essential to successfully embed privacy into the core of HCAI, thereby ensuring these technologies advance in a manner that respects and ensures human autonomy, trust and dignity."}
{"id": "2602.04621", "categories": ["cs.HC", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.04621", "abs": "https://arxiv.org/abs/2602.04621", "authors": ["Yi Wang", "Ben Cheng", "Xiao Liu", "Chetan Arora", "John Grundy", "Thuong Hoang"], "title": "VRARE: Using Virtual Reality to Understand Accessibility Requirements of Color Blindness and Weakness", "comment": "IEEE VR 26 Poster", "summary": "In this paper, we developed a virtual reality (VR) system that can simulate color blindness and weakness. We built an immersive 3D web view interface where participants can discuss accessibility requirements for a fitness website projects within a virtual fitness environment. We conducted a pilot experiment involving 24 participants from six software teams, who used both VR and non-VR methods to understand color blindness and weakness requirements in a website project. Our findings indicate that using VR can provide several benefits for requirements activities, such as an improved user experience and reduced workload."}
{"id": "2602.04632", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.04632", "abs": "https://arxiv.org/abs/2602.04632", "authors": ["Yi Wang", "Zhengxin Zhang", "Xiao Liu", "Chetan Arora", "John Grundy", "Thuong Hoang"], "title": "Discussing Your Needs in VR: A Novel Approach through Persona-based Stakeholder Role-Playing", "comment": "IEEE VR 26 Poster", "summary": "In this study, we propose a novel approach that supports requirements discussions in virtual environments by automatically generating personas from real-time speech-to-text data. In our pilot experiment, 18 participants (14 from universities and 4 from IT companies) used the generated personas to discuss accessibility requirements within the virtual environment. Participants reported a relatively high level of satisfaction with the social presence and usability of the VR system. We also found that requirements discussions based on personas have a lower workload. Finally, we outline the main directions for future work."}
{"id": "2602.04713", "categories": ["cs.HC", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.04713", "abs": "https://arxiv.org/abs/2602.04713", "authors": ["Xinyi Wen", "Lena Hegemann", "Xiaofu Jin", "Shuai Ma", "Antti Oulasvirta"], "title": "Adaptive Prompt Elicitation for Text-to-Image Generation", "comment": "ACM International Conference on Intelligent User Interfaces (IUI) 2026, March 23-26, Paphos, Cyprus", "summary": "Aligning text-to-image generation with user intent remains challenging, for users who provide ambiguous inputs and struggle with model idiosyncrasies. We propose Adaptive Prompt Elicitation (APE), a technique that adaptively asks visual queries to help users refine prompts without extensive writing. Our technical contribution is a formulation of interactive intent inference under an information-theoretic framework. APE represents latent intent as interpretable feature requirements using language model priors, adaptively generates visual queries, and compiles elicited requirements into effective prompts. Evaluation on IDEA-Bench and DesignBench shows that APE achieves stronger alignment with improved efficiency. A user study with challenging user-defined tasks demonstrates 19.8% higher alignment without workload overhead. Our work contributes a principled approach to prompting that, for general users, offers an effective and efficient complement to the prevailing prompt-based interaction paradigm with text-to-image models."}
{"id": "2602.04787", "categories": ["cs.HC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.04787", "abs": "https://arxiv.org/abs/2602.04787", "authors": ["Jiaye Li", "Tongshun Chen", "Siyi Ma", "Elizabeth Churchill", "Ke Wu"], "title": "PuppetAI: A Customizable Platform for Designing Tactile-Rich Affective Robot Interaction", "comment": null, "summary": "We introduce PuppetAI, a modular soft robot interaction platform. This platform offers a scalable cable-driven actuation system and a customizable, puppet-inspired robot gesture framework, supporting a multitude of interaction gesture robot design formats. The platform comprises a four-layer decoupled software architecture that includes perceptual processing, affective modeling, motion scheduling, and low-level actuation. We also implemented an affective expression loop that connects human input to the robot platform by producing real-time emotional gestural responses to human vocal input. For our own designs, we have worked with nuanced gestures enacted by \"soft robots\" with enhanced dexterity and \"pleasant-to-touch\" plush exteriors. By reducing operational complexity and production costs while enhancing customizability, our work creates an adaptable and accessible foundation for future tactile-based expressive robot research. Our goal is to provide a platform that allows researchers to independently construct or refine highly specific gestures and movements performed by social robots."}
{"id": "2602.04841", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.04841", "abs": "https://arxiv.org/abs/2602.04841", "authors": ["Jeongmin Rhee", "Changhee Lee", "DongHwa Shin", "Bohyoung Kim"], "title": "Vivifying LIME: Visual Interactive Testbed for LIME Analysis", "comment": null, "summary": "Explainable Artificial Intelligence (XAI) has gained importance in interpreting model predictions. Among leading techniques for XAI, Local Interpretable Model-agnostic Explanations (LIME) is most frequently utilized as it notably helps people's understanding of complex models. However, LIME's analysis is constrained to a single image at a time. Besides, it lacks interaction mechanisms for observing the LIME's results and direct manipulations of factors affecting the results. To address these issues, we introduce an interactive visualization tool, LIMEVis, which improves the analysis workflow of LIME by enabling users to explore multiple LIME results simultaneously and modify them directly. With LIMEVis, we could conveniently identify common features in images that a model seems to mainly consider for category classification. Additionally, by interactively modifying the LIME results, we could determine which segments in an image influence the model's classification."}
