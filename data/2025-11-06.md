<div id=toc></div>

# Table of Contents

- [cs.HC](#cs.HC) [Total: 19]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.ET](#cs.ET) [Total: 3]


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [1] [An extended reality-based framework for user risk training in urban built environment](https://arxiv.org/abs/2511.02837)
*Sotirios Konstantakos,Sotirios Asparagkathos,Moatasim Mahmoud,Stamatia Rizou,Enrico Quagliarini,Gabriele Bernardini*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In the context of increasing urban risks, particularly from climate
change-induced flooding, this paper presents an extended Reality (XR)-based
framework to improve user risk training within urban built environments. The
framework is designed to improve risk awareness and preparedness among various
stakeholders, including citizens, local authorities, and emergency responders.
Using immersive XR technologies, the training experience simulates real-world
emergency scenarios, contributing to active participation and a deeper
understanding of potential hazards and especially for floods. The framework
highlights the importance of stakeholder participation in its development,
ensuring that training modules are customized to address the specific needs of
different user groups. The iterative approach of the framework supports ongoing
refinement through user feedback and performance data, thus improving the
overall effectiveness of risk training initiatives. This work outlines the
methodological phases involved in the framework's implementation, including i)
user flow mapping, ii) scenario selection, and iii) performance evaluation,
with a focus on the pilot application in Senigallia, Italy. The findings
underscore the potential of XR technologies to transform urban risk training,
promoting a culture of preparedness and resilience against urban hazards.

</details>


### [2] [How ChatGPT and Gemini View the Elements of Communication Competence of Large Language Models: A Pilot Study](https://arxiv.org/abs/2511.02838)
*Goran Bubas*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: A concise overview is provided of selected theoretical models of
communication competence in the fields of linguistics, interpersonal
communication, second language use, and human-robot interaction. The following
practical research consisted of two case studies with the goals of
investigating how advanced AI tools like ChatGPT and Gemini interpret elements
of two communication competence theories in the context of Large Language Model
(LLM) interactions with users. The focus was on these theoretical approaches:
(1) an integrated linguistic-interpersonal model and (2) an interpersonal
"human-humanoid" interaction model. The conclusion is that both approaches are
suitable for a better understanding of LLM-user interaction.

</details>


### [3] [Evaluating Generative AI as an Educational Tool for Radiology Resident Report Drafting](https://arxiv.org/abs/2511.02839)
*Antonio Verdone,Aidan Cardall,Fardeen Siddiqui,Motaz Nashawaty,Danielle Rigau,Youngjoon Kwon,Mira Yousef,Shalin Patel,Alex Kieturakis,Eric Kim,Laura Heacock,Beatriu Reig,Yiqiu Shen*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Objective: Radiology residents require timely, personalized feedback to
develop accurate image analysis and reporting skills. Increasing clinical
workload often limits attendings' ability to provide guidance. This study
evaluates a HIPAA-compliant GPT-4o system that delivers automated feedback on
breast imaging reports drafted by residents in real clinical settings.
  Methods: We analyzed 5,000 resident-attending report pairs from routine
practice at a multi-site U.S. health system. GPT-4o was prompted with clinical
instructions to identify common errors and provide feedback. A reader study
using 100 report pairs was conducted. Four attending radiologists and four
residents independently reviewed each pair, determined whether predefined error
types were present, and rated GPT-4o's feedback as helpful or not. Agreement
between GPT and readers was assessed using percent match. Inter-reader
reliability was measured with Krippendorff's alpha. Educational value was
measured as the proportion of cases rated helpful.
  Results: Three common error types were identified: (1) omission or addition
of key findings, (2) incorrect use or omission of technical descriptors, and
(3) final assessment inconsistent with findings. GPT-4o showed strong agreement
with attending consensus: 90.5%, 78.3%, and 90.4% across error types.
Inter-reader reliability showed moderate variability ({\alpha} = 0.767, 0.595,
0.567), and replacing a human reader with GPT-4o did not significantly affect
agreement ({\Delta} = -0.004 to 0.002). GPT's feedback was rated helpful in
most cases: 89.8%, 83.0%, and 92.0%.
  Discussion: ChatGPT-4o can reliably identify key educational errors. It may
serve as a scalable tool to support radiology education.

</details>


### [4] [Interview Survey on Attractivenesses of Place Re-creation Toward Developing a Virtual Twin Design Theory](https://arxiv.org/abs/2511.02840)
*Saizo Aoyagi*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: It is often seen that real-world locations are re-created using models,
metaverse technology, or computer graphics. Although the surface-level purposes
of these re-creations vary, the author hypothesizes that there exists an
underlying common attractiveness that remains unclear. This research aims to
clarify the attractiveness and its structures of place re-creations through an
interview study with qualitative analysis. The interviews used examples of
physical re-creations, such as the model in Komazawa University's Zen Culture
History Museum and some dioramas of Tokyo, as well as computer-generated
re-creations of Shibuya using platforms like Minecraft and Project Plateau's 3D
city model. Using insights gained from this investigation, this study seeks to
establish a theoretical framework for designing virtual twins.

</details>


### [5] [Node-Based Editing for Multimodal Generation of Text, Audio, Image, and Vide](https://arxiv.org/abs/2511.03227)
*Alexander Htet Kyaw,Lenin Ravindranath Sivalingam*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a node-based storytelling system for multimodal content
generation. The system represents stories as graphs of nodes that can be
expanded, edited, and iteratively refined through direct user edits and
natural-language prompts. Each node can integrate text, images, audio, and
video, allowing creators to compose multimodal narratives. A task selection
agent routes between specialized generative tasks that handle story generation,
node structure reasoning, node diagram formatting, and context generation. The
interface supports targeted editing of individual nodes, automatic branching
for parallel storylines, and node-based iterative refinement. Our results
demonstrate that node-based editing supports control over narrative structure
and iterative generation of text, images, audio, and video. We report
quantitative outcomes on automatic story outline generation and qualitative
observations of editing workflows. Finally, we discuss current limitations such
as scalability to longer narratives and consistency across multiple nodes, and
outline future work toward human-in-the-loop and user-centered creative AI
tools.

</details>


### [6] [Digital Transformation Chatbot (DTchatbot): Integrating Large Language Model-based Chatbot in Acquiring Digital Transformation Needs](https://arxiv.org/abs/2511.02842)
*Jiawei Zheng,Gokcen Yilmaz,Ji Han,Saeema Ahmed-Kristensen*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Many organisations pursue digital transformation to enhance operational
efficiency, reduce manual efforts, and optimise processes by automation and
digital tools. To achieve this, a comprehensive understanding of their unique
needs is required. However, traditional methods, such as expert interviews,
while effective, face several challenges, including scheduling conflicts,
resource constraints, inconsistency, etc. To tackle these issues, we
investigate the use of a Large Language Model (LLM)-powered chatbot to acquire
organisations' digital transformation needs. Specifically, the chatbot
integrates workflow-based instruction with LLM's planning and reasoning
capabilities, enabling it to function as a virtual expert and conduct
interviews. We detail the chatbot's features and its implementation. Our
preliminary evaluation indicates that the chatbot performs as designed,
effectively following predefined workflows and supporting user interactions
with areas for improvement. We conclude by discussing the implications of
employing chatbots to elicit user information, emphasizing their potential and
limitations.

</details>


### [7] [A Survey of Driver Distraction and Inattention in Popular Commercial Software-Defined Vehicles](https://arxiv.org/abs/2511.02891)
*Lingyu Zhao,Yuankai He*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: As the automotive industry embraces software-defined vehicles (SDVs), the
role of user interface (UI) design in ensuring driver safety has become
increasingly significant. In crashes related to distracted driving, over 90%
did not involve cellphone use but were related to UI controls. However, many of
the existing UI SDV implementations do not consider Drive Distraction and
Inattention (DDI), which is reflected in many popular commercial vehicles. This
paper investigates the impact of UI designs on driver distraction and
inattention within the context of SDVs. Through a survey of popular commercial
vehicles, we identify UI features that potentially increase cognitive load and
evaluate design strategies to mitigate these risks. This survey highlights the
need for UI designs that balance advanced software functionalities with
driver-cognitive ergonomics. Findings aim to provide valuable guidance to
researchers and OEMs to contribute to the field of automotive UI, contributing
to the broader discussion on enhancing vehicular safety in the software-centric
automotive era.

</details>


### [8] [Inter-Agent Trust Models: A Comparative Study of Brief, Claim, Proof, Stake, Reputation and Constraint in Agentic Web Protocol Design-A2A, AP2, ERC-8004, and Beyond](https://arxiv.org/abs/2511.03434)
*Botao 'Amber' Hu,Helena Rong*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: As the "agentic web" takes shape-billions of AI agents (often LLM-powered)
autonomously transacting and collaborating-trust shifts from human oversight to
protocol design. In 2025, several inter-agent protocols crystallized this
shift, including Google's Agent-to-Agent (A2A), Agent Payments Protocol (AP2),
and Ethereum's ERC-8004 "Trustless Agents," yet their underlying trust
assumptions remain under-examined. This paper presents a comparative study of
trust models in inter-agent protocol design: Brief (self- or third-party
verifiable claims), Claim (self-proclaimed capabilities and identity, e.g.
AgentCard), Proof (cryptographic verification, including zero-knowledge proofs
and trusted execution environment attestations), Stake (bonded collateral with
slashing and insurance), Reputation (crowd feedback and graph-based trust
signals), and Constraint (sandboxing and capability bounding). For each, we
analyze assumptions, attack surfaces, and design trade-offs, with particular
emphasis on LLM-specific fragilities-prompt injection,
sycophancy/nudge-susceptibility, hallucination, deception, and
misalignment-that render purely reputational or claim-only approaches brittle.
Our findings indicate no single mechanism suffices. We argue for
trustless-by-default architectures anchored in Proof and Stake to gate
high-impact actions, augmented by Brief for identity and discovery and
Reputation overlays for flexibility and social signals. We comparatively
evaluate A2A, AP2, ERC-8004 and related historical variations in academic
research under metrics spanning security, privacy, latency/cost, and social
robustness (Sybil/collusion/whitewashing resistance). We conclude with hybrid
trust model recommendations that mitigate reputation gaming and misinformed LLM
behavior, and we distill actionable design guidelines for safer, interoperable,
and scalable agent economies.

</details>


### [9] [Systematizing LLM Persona Design: A Four-Quadrant Technical Taxonomy for AI Companion Applications](https://arxiv.org/abs/2511.02979)
*Esther Sun,Zichu Wu*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The design and application of LLM-based personas in AI companionship is a
rapidly expanding but fragmented field, spanning from virtual emotional compan-
ions and game NPCs to embodied functional robots. This diversity in objectives,
modality, and technical stacks creates an urgent need for a unified framework.
To address this gap, this paper systematizes the field by proposing a
Four-Quadrant Technical Taxonomy for AI companion applications. The framework
is structured along two critical axes: Virtual vs. Embodied and Emotional
Companionship vs. Functional Augmentation. Quadrant I (Virtual Companionship)
explores virtual idols, romantic companions, and story characters, introducing
a four-layer technical framework to analyze their challenges in maintaining
long-term emotional consistency. Quadrant II (Functional Virtual Assistants)
analyzes AI applica- tions in work, gaming, and mental health, highlighting the
shift from "feeling" to "thinking and acting" and pinpointing key technologies
like enterprise RAG and on-device inference. Quadrants III & IV (Embodied
Intelligence) shift from the virtual to the physical world, analyzing home
robots and vertical-domain assistants, revealing core challenges in symbol
grounding, data privacy, and ethical liability. This taxonomy provides not only
a systematic map for researchers and developers to navigate the complex persona
design space but also a basis for policymakers to identify and address the
unique risks inherent in different application scenarios.

</details>


### [10] [Tracing Generative AI in Digital Art: A Longitudinal Study of Chinese Painters' Attitudes, Practices, and Identity Negotiation](https://arxiv.org/abs/2511.03117)
*Yibo Meng,Ruiqi Chen,Xin Chen,Zhiming Liu,Yan Guan*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This study presents a five-year longitudinal mixed-methods study of 17
Chinese digital painters, examining how their attitudes and practices evolved
in response to generative AI. Our findings reveal a trajectory from resistance
and defensiveness, to pragmatic adoption, and ultimately to reflective
reconstruction, shaped by strong peer pressures and shifting emotional
experiences. Persistent concerns around copyright and creative labor highlight
the ongoing negotiation of identity and values. This work contributes by
offering rare longitudinal empirical data, advancing a theoretical lens of
"identity and value negotiation," and providing design implications for future
human-AI collaborative systems.

</details>


### [11] [Ceci N'est Pas un Drone: Investigating the Impact of Design Representation on Design Decision Making When Using GenAI](https://arxiv.org/abs/2511.03131)
*Zeda Xu,Nikolas Martelaro,Christopher McComb*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: With generative AI-powered design tools, designers and engineers can
efficiently generate large numbers of design ideas. However, efficient
exploration of these ideas requires designers to select a smaller group of
potential solutions for further development. Therefore, the ability to judge
and evaluate designs is critical for the successful use of generative design
tools. Different design representation modalities can potentially affect
designers' judgments. This work investigates how different design modalities,
including visual rendering, numerical performance data, and a combination of
both, affect designers' design selections from AI-generated design concepts for
Uncrewed Aerial Vehicles. We found that different design modalities do affect
designers' choices. Unexpectedly, we found that providing only numerical design
performance data can lead to the best ability to select optimal designs. We
also found that participants prefer visually conventional designs with
axis-symmetry. The findings of this work provide insights into the interaction
between human users and generative design systems.

</details>


### [12] [From Measurement to Expertise: Empathetic Expert Adapters for Context-Based Empathy in Conversational AI Agents](https://arxiv.org/abs/2511.03143)
*Erfan Shayegani,Jina Suh,Andy Wilson,Nagu Rangan,Javier Hernandez*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Empathy is a critical factor in fostering positive user experiences in
conversational AI. While models can display empathy, it is often generic rather
than tailored to specific tasks and contexts. In this work, we introduce a
novel framework for developing and evaluating context-specific empathetic large
language models (LLMs). We first analyze a real-world conversational dataset
consisting of 672 multi-turn conversations across 8 tasks, revealing
significant differences in terms of expected and experienced empathy before and
after the conversations, respectively. To help minimize this gap, we develop a
synthetic multi-turn conversational generation pipeline and steer responses
toward our defined empathy patterns based on the context that more closely
matches users' expectations. We then train empathetic expert adapters for
context-specific empathy that specialize in varying empathy levels based on the
recognized task. Our empirical results demonstrate a significant gap reduction
of 72.66% between perceived and desired empathy with scores increasing by an
average factor of 2.43 as measured by our metrics and reward models.
Additionally, our trained empathetic expert adapters demonstrate superior
effectiveness in preserving empathy patterns throughout conversation turns,
outperforming system prompts, which tend to dramatically diminish in impact as
conversations lengthen.

</details>


### [13] [AI as We Describe It: How Large Language Models and Their Applications in Health are Represented Across Channels of Public Discourse](https://arxiv.org/abs/2511.03174)
*Jiawei Zhou,Lei Zhang,Mei Li,Benjamin D Horne,Munmun De Choudhury*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Representation shapes public attitudes and behaviors. With the arrival and
rapid adoption of LLMs, the way these systems are introduced will negotiate
societal expectations for their role in high-stakes domains like health. Yet it
remains unclear whether current narratives present a balanced view. We analyzed
five prominent discourse channels (news, research press, YouTube, TikTok, and
Reddit) over a two-year period on lexical style, informational content, and
symbolic representation. Discussions were generally positive and episodic, with
positivity increasing over time. Risk communication was unthorough and often
reduced to information quality incidents, while explanations of LLMs'
generative nature were rare. Compared with professional outlets, TikTok and
Reddit highlighted wellbeing applications and showed greater variations in tone
and anthropomorphism but little attention to risks. We discuss implications for
public discourse as a diagnostic tool in identifying literacy and governance
gaps, and for communication and design strategies to support more informed LLM
engagement.

</details>


### [14] [Large Language Models as Information Sources: Distinctive Characteristics and Types of Low-Quality Information](https://arxiv.org/abs/2511.03198)
*Jiawei Zhou,Amy Z. Chen,Darshi Shah,Laura M. Schwab-Reese,Munmun De Choudhury*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent advances in large language models (LLMs) have brought public and
scholarly attention to their potential in generating low-quality information.
While widely acknowledged as a risk, low-quality information remains a vaguely
defined concept, and little is known about how it manifests in LLM outputs or
how these outputs differ from those of traditional information sources. In this
study, we focus on two key questions: What types of low-quality information are
produced by LLMs, and what makes them distinct than human-generated
counterparts? We conducted focus groups with public health professionals and
individuals with lived experience in three critical health contexts (vaccines,
opioid use disorder, and intimate partner violence) where high-quality
information is essential and misinformation, bias, and insensitivity are
prevalent concerns. We identified a typology of LLM-generated low-quality
information and a set of distinctive LLM characteristics compared to
traditional information sources. Our findings show that low-quality information
extends beyond factual inaccuracies into types such as misprioritization and
exaggeration, and that LLM affordances fundamentally differs from previous
technologies. This work offers typologies on LLM distinctive characteristics
and low-quality information types as a starting point for future efforts to
understand LLM-generated low-quality information and mitigate related
informational harms. We call for conceptual and methodological discussions of
information quality to move beyond truthfulness, in order to address the
affordances of emerging technologies and the evolving dynamics of information
behaviors.

</details>


### [15] [I Prompt, it Generates, we Negotiate. Exploring Text-Image Intertextuality in Human-AI Co-Creation of Visual Narratives with VLMs](https://arxiv.org/abs/2511.03375)
*Mengyao Guo,Kexin Nie,Ze Gao,Black Sun,Xueyang Wang,Jinda Han,Xingting Wu*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Creating meaningful visual narratives through human-AI collaboration requires
understanding how text-image intertextuality emerges when textual intentions
meet AI-generated visuals. We conducted a three-phase qualitative study with 15
participants using GPT-4o to investigate how novices navigate sequential visual
narratives. Our findings show that users develop strategies to harness AI's
semantic surplus by recognizing meaningful visual content beyond literal
descriptions, iteratively refining prompts, and constructing narrative
significance through complementary text-image relationships. We identified four
distinct collaboration patterns and, through fsQCA's analysis, discovered three
pathways to successful intertextual collaboration: Educational Collaborator,
Technical Expert, and Visual Thinker. However, participants faced challenges,
including cultural representation gaps, visual consistency issues, and
difficulties translating narrative concepts into visual prompts. These findings
contribute to HCI research by providing an empirical account of
\textit{text-image intertextuality} in human-AI co-creation and proposing
design implications for role-based AI assistants that better support iterative,
human-led creative processes in visual storytelling.

</details>


### [16] [SVG Decomposition for Enhancing Large Multimodal Models Visualization Comprehension: A Study with Floor Plans](https://arxiv.org/abs/2511.03478)
*Jeongah Lee,Ali Sarvghad*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large multimodal models (LMMs) are increasingly capable of interpreting
visualizations, yet they continue to struggle with spatial reasoning. One
proposed strategy is decomposition, which breaks down complex visualizations
into structured components. In this work, we examine the efficacy of scalable
vector graphics (SVGs) as a decomposition strategy for improving LMMs'
performance on floor plans comprehension. Floor plans serve as a valuable
testbed because they combine geometry, topology, and semantics, and their
reliable comprehension has real-world applications, such as accessibility for
blind and low-vision individuals. We conducted an exploratory study with three
LMMs (GPT-4o, Claude 3.7 Sonnet, and Llama 3.2 11B Vision Instruct) across 75
floor plans. Results show that combining SVG with raster input (SVG+PNG)
improves performance on spatial understanding tasks but often hinders spatial
reasoning, particularly in pathfinding. These findings highlight both the
promise and limitations of decomposition as a strategy for advancing spatial
visualization comprehension.

</details>


### [17] [PnPSelect: Plug-and-play IoT Device Selection Using Ultra-wideband Signals](https://arxiv.org/abs/2511.03534)
*Zhaoxin Chang,Fusang Zhang,Jie Xiong,Ziyu Li,Badii Jouaber,Daqing Zhang*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In recent years, the number of Internet of Things (IoT) devices in smart
homes has rapidly increased. A key challenge affecting user experience is how
to enable users to efficiently and intuitively select the devices they wish to
control. This paper proposes PnPSelect, a plug-and-play IoT device selection
solution utilizing Ultra-wideband (UWB) technology on commercial devices.
Unlike previous works, PnPSelect does not require the installation of dedicated
hardware on each IoT device, thereby reducing deployment costs and
complexities, and achieving true plug-and-play functionality. To enable
intuitive device selection, we introduce a pointing direction estimation method
that utilizes UWB readings from a single anchor to infer the user pointing
direction. Additionally, we propose a lightweight device localization method
that allows users to register new IoT devices by simply pointing at them from
two distinct positions, eliminating the need for manual measurements. We
implement PnPSelect on commercial smartphones and smartwatches and conduct
extensive evaluations in both controlled laboratory settings and real-world
environments. Our results demonstrate high accuracy, robustness, and
adaptability, making PnPSelect a practical and scalable solution for
next-generation smart home interactions.

</details>


### [18] [Knowledge Graph for Intelligent Generation of Artistic Image Creation: Constructing a New Annotation Hierarchy](https://arxiv.org/abs/2511.03585)
*Jia Kaixin,Zhu Kewen,Deng Huanghuang,Qiu Yiwu,Ding Shiying,Ding Chenyang,Li Zejian*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Our study aims to establish a unified, systematic, and referable knowledge
framework for the annotation of art image datasets, addressing issues of
ambiguous definitions and inconsistent results caused by the lack of common
standards during the annotation process. To achieve this goal, a hierarchical
and systematic art image knowledge graph was constructed. It was developed
based on the composition principles of art images, incorporating the Structured
Theory of Visual Knowledge proposed by Academician Yunhe Pan in On Visual
Knowledge-which states that visual knowledge must achieve precise expression of
spatial forms and dynamic relationships through "prototype-category" and
"hierarchical structure". Through in-depth review of Chinese and Western art
theories and pioneering integration of the Chinese cultural perspective, this
graph took shape. The core visual language of art images was deconstructed by
this knowledge graph. Meanwhile, the unique spatial theory and symbolic system
of Chinese painting were compared with and supplemented by Western art
theories. This graph converts qualitative artistic concepts into a clear
structured framework. It not only conforms to the cognitive law that "visual
knowledge takes precedence over verbal knowledge" in humans but also provides
an interpretable and inferential visual knowledge foundation for AI art
generation and cross-cultural art analysis. It ensures the high quality and
consistency of annotated data, thus offering key support for art intelligence
research in the AI 2.0 era.

</details>


### [19] [OriFeel: Origami-Inspired Actuation for Force-Based Tactile Feedback on Ambient Surfaces](https://arxiv.org/abs/2511.03673)
*Shubham Rohal,Shijia Pan*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: People are constantly in touch with surfaces in their lives, such as a sofa,
armrest, and table, making them natural tactile interfaces. Despite the recent
advancements in shape-changing surfaces, current available solutions are often
challenging to retrofit into ambient surfaces due to their bulky form factor or
high power requirements. We present \name, a foldable structure-enabled tactile
feedback mechanism that leverages the structural properties of Miura-Ori fold
to enable on-surface force actuation. The foldable structure allows the
surfaces to provide perpendicular force via lateral actuation, resulting in a
slim form factor that can be actuated via cable-based design using a servo
motor. We evaluate the system with a real-world prototype and a user study. The
user study shows that users can effectively distinguish multiple intensity
levels.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [20] [Scheduling the Off-Diagonal Weingarten Loss of Neural SDFs for CAD Models](https://arxiv.org/abs/2511.03147)
*Haotian Yin,Przemyslaw Musialski*

Main category: cs.GR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Neural signed distance functions (SDFs) have become a powerful representation
for geometric reconstruction from point clouds, yet they often require both
gradient- and curvature-based regularization to suppress spurious warp and
preserve structural fidelity. FlatCAD introduced the Off-Diagonal Weingarten
(ODW) loss as an efficient second-order prior for CAD surfaces, approximating
full-Hessian regularization at roughly half the computational cost. However,
FlatCAD applies a fixed ODW weight throughout training, which is suboptimal:
strong regularization stabilizes early optimization but suppresses detail
recovery in later stages. We present scheduling strategies for the ODW loss
that assign a high initial weight to stabilize optimization and progressively
decay it to permit fine-scale refinement. We investigate constant, linear,
quintic, and step interpolation schedules, as well as an increasing warm-up
variant. Experiments on the ABC CAD dataset demonstrate that time-varying
schedules consistently outperform fixed weights. Our method achieves up to a
35% improvement in Chamfer Distance over the FlatCAD baseline, establishing
scheduling as a simple yet effective extension of curvature regularization for
robust CAD reconstruction.

</details>


### [21] [Visualization Biases MLLM's Decision Making in Network Data Tasks](https://arxiv.org/abs/2511.03617)
*Timo Brand,Henry FÃ¶rster,Stephen G. Kobourov,Jacob Miller*

Main category: cs.GR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We evaluate how visualizations can influence the judgment of MLLMs about the
presence or absence of bridges in a network. We show that the inclusion of
visualization improves confidence over a structured text-based input that could
theoretically be helpful for answering the question. On the other hand, we
observe that standard visualization techniques create a strong bias towards
accepting or refuting the presence of a bridge -- independently of whether or
not a bridge actually exists in the network. While our results indicate that
the inclusion of visualization techniques can effectively influence the MLLM's
judgment without compromising its self-reported confidence, they also imply
that practitioners must be careful of allowing users to include visualizations
in generative AI applications so as to avoid undesired hallucinations.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [22] [ALAS: Transactional and Dynamic Multi-Agent LLM Planning](https://arxiv.org/abs/2511.03094)
*Longling Geng,Edward Y. Chang*

Main category: cs.MA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large language models enable flexible multi-agent planning but remain fragile
in practice: verification is often circular, state changes are not tracked for
repair, and small faults trigger costly global recomputation. We present ALAS,
a stateful, disruption-aware framework that separates planning from
non-circular validation, records a versioned execution log for grounded checks
and restore points, and performs localized repair that preserves work in
progress. The validator operates independently of the planning LLM with fresh,
bounded context, avoiding self-check loops and mid-context attrition. The
repair protocol edits only the minimal affected region under explicit policies
(retry, catch, timeout, backoff, idempotency keys, compensation, loop guards)
defined in a canonical workflow IR that maps to Amazon States Language and Argo
Workflows. On job-shop scheduling suites (DMU, TA) across five classical
benchmarks, ALAS matches or exceeds strong single-LLM and multi-agent
baselines, achieving 83.7% success, reducing token usage by 60%, and running
1.82times faster under comparable settings. A minimal reliability study shows
that the validator detects injected structural faults with low overhead, and
that localized repair contains runtime perturbations with a bounded edit radius
and less makespan degradation than global recompute. Results indicate that the
combination of validator isolation, versioned execution logs, and localized
repair provides measurable efficiency, feasibility, and scalability for
multi-agent LLM planning. Code and seeds will be released.

</details>


### [23] [Learning Communication Skills in Multi-task Multi-agent Deep Reinforcement Learning](https://arxiv.org/abs/2511.03348)
*Changxi Zhu,Mehdi Dastani,Shihan Wang*

Main category: cs.MA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In multi-agent deep reinforcement learning (MADRL), agents can communicate
with one another to perform a task in a coordinated manner. When multiple tasks
are involved, agents can also leverage knowledge from one task to improve
learning in other tasks. In this paper, we propose Multi-task Communication
Skills (MCS), a MADRL with communication method that learns and performs
multiple tasks simultaneously, with agents interacting through learnable
communication protocols. MCS employs a Transformer encoder to encode
task-specific observations into a shared message space, capturing shared
communication skills among agents. To enhance coordination among agents, we
introduce a prediction network that correlates messages with the actions of
sender agents in each task. We adapt three multi-agent benchmark environments
to multi-task settings, where the number of agents as well as the observation
and action spaces vary across tasks. Experimental results demonstrate that MCS
achieves better performance than multi-task MADRL baselines without
communication, as well as single-task MADRL baselines with and without
communication.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [24] [NF-SecRIS: RIS-Assisted Near-Field Physical Layer Security via Secure Location Modulation](https://arxiv.org/abs/2511.02949)
*Zhendong Wang,Chenyang Meng,Jun Yang,Jiayuan Wang,Yin Li,Linshan Jiang,Jin Zhang*

Main category: cs.ET

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The 6G wireless networks impose extremely high requirements on physical layer
secure communication. However, the existing solutions usually can only achieve
one-dimensional physical layer security (PLS) in the angle dimension, and
cannot achieve PLS in the range dimension. In this paper, we propose the
NF-SecRIS system, the first range-angle-dependent (2D) PLS near-field
communication system based on ultra-large-scale reconfigurable intelligent
surface (RIS). We propose the secure location modulation scheme to synthesize
the near-field spatial-temporal coding pattern of RIS with extremely low
complexity. It ensures that only legitimate user can receive the raw
constellations, while potential eavesdroppers at other ranges or angles can
only receive the obfuscated constellations. NF-SecRIS operates without
requiring synchronization with either transmitter or receiver. We implement a
prototype of NF-SecRIS and conduct comprehensive experiments with multiple
modulation schemes. The results show that the bit error rate (BER) of
legitimate user is below 10^{-4}, while eavesdroppers at other ranges or angles
suffer from BER exceeding 40%. It validates the implementation of 2D PLS in
near-field communications.

</details>


### [25] [QAGT-MLP: An Attention-Based Graph Transformer for Small and Large-Scale Quantum Error Mitigation](https://arxiv.org/abs/2511.03119)
*Seyed Mohamad Ali Tousi,G. N. DeSouza*

Main category: cs.ET

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Noisy quantum devices demand error-mitigation techniques to be accurate yet
simple and efficient in terms of number of shots and processing time. Many
established approaches (e.g., extrapolation and quasi-probability cancellation)
impose substantial execution or calibration overheads, while existing
learning-based methods have difficulty scaling to large and deep circuits. In
this research, we introduce QAGT-MLP: an attention-based graph transformer
tailored for small- and large-scale quantum error mitigation (QEM). QAGT-MLP
encodes each quantum circuit as a graph whose nodes represent gate instances
and whose edges capture qubit connectivity and causal adjacency. A dual-path
attention module extracts features around measured qubits at two scales or
contexts: 1) graph-wide global structural context; and 2) fine-grained local
lightcone context. These learned representations are concatenated with
circuit-level descriptor features and the circuit noisy expected values, then
they are passed to a lightweight MLP to predict the noise-mitigated values. On
large-scale 100-qubit Trotterized 1D Transverse-Field Ising Models -- TFIM
circuits -- the proposed QAGT-MLP outperformed state-of-the-art learning
baselines in terms of mean error and error variability, demonstrating strong
validity and applicability in real-world QEM scenarios under matched shot
budgets. By using attention to fuse global structures with local lightcone
neighborhoods, QAGT-MLP achieves high mitigation quality without the increasing
noise scaling or resource demand required by classical QEM pipelines, while
still offering a scalable and practical path to QEM in modern and future
quantum workloads.

</details>


### [26] [LLM-enhanced Air Quality Monitoring Interface via Model Context Protocol](https://arxiv.org/abs/2511.03706)
*Yu-Erh Pan,Ayesha Siddika Nipu*

Main category: cs.ET

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Air quality monitoring is central to environmental sustainability and public
health, yet traditional systems remain difficult for non-expert users to
interpret due to complex visualizations, limited interactivity, and high
deployment costs. Recent advances in Large Language Models (LLMs) offer new
opportunities to make sensor data more accessible, but their tendency to
produce hallucinations limits reliability in safety-critical domains. To
address these challenges, we present an LLM-enhanced Air Monitoring Interface
(AMI) that integrates real-time sensor data with a conversational interface via
the Model Context Protocol (MCP). Our system grounds LLM outputs in live
environmental data, enabling accurate, context-aware responses while reducing
hallucination risk. The architecture combines a Django-based backend, a
responsive user dashboard, and a secure MCP server that exposes system
functions as discoverable tools, allowing the LLM to act as an active operator
rather than a passive responder. Expert evaluation demonstrated high factual
accuracy (4.78), completeness (4.82), and minimal hallucinations (4.84), on a
scale of 5, supported by inter-rater reliability analysis. These results
highlight the potential of combining LLMs with standardized tool protocols to
create reliable, secure, and user-friendly interfaces for real-time
environmental monitoring.

</details>
