{"id": "2602.18443", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.18443", "abs": "https://arxiv.org/abs/2602.18443", "authors": ["Philipp Steigerwald", "Jens Albrecht"], "title": "From \"Help\" to Helpful: A Hierarchical Assessment of LLMs in Mental e-Health Applications", "comment": null, "summary": "Psychosocial online counselling frequently encounters generic subject lines that impede efficient case prioritisation. This study evaluates eleven large language models generating six-word subject lines for German counselling emails through hierarchical assessment - first categorising outputs, then ranking within categories to enable manageable evaluation. Nine assessors (counselling professionals and AI systems) enable analysis via Krippendorff's $α$, Spearman's $ρ$, Pearson's $r$ and Kendall's $τ$. Results reveal performance trade-offs between proprietary services and privacy-preserving open-source alternatives, with German fine-tuning consistently improving performance. The study addresses critical ethical considerations for mental health AI deployment including privacy, bias and accountability."}
{"id": "2602.18498", "categories": ["cs.MA", "cs.GT"], "pdf": "https://arxiv.org/pdf/2602.18498", "abs": "https://arxiv.org/abs/2602.18498", "authors": ["Zhao Song", "Theodor Cimpeanu", "Chen Shen", "The Anh Han"], "title": "Evolution of fairness in hybrid populations with specialised AI agents", "comment": null, "summary": "Fairness in hybrid societies hinges on a simple choice: should AI be a generous host or a strict gatekeeper? Moving beyond symmetric models, we show that asymmetric social structures--like those in hiring, regulation, and negotiation--AI that guards fairness outperforms AI that gifts it. We bridge this gap with a bipartite hybrid population model of the Ultimatum Game, separating humans and AI into distinct proposer and receiver groups. We first introduce Samaritan AI agents, which act as either unconditional fair proposers or strict receivers. Our results reveal a striking asymmetry: Samaritan AI receivers drive population-wide fairness far more effectively than Samaritan AI proposers. To overcome the limitations of the Samaritan AI proposer, we design the Discriminatory AI proposer, which predicts co-players' expectations and only offers fair portions to those with high acceptance thresholds. Our results demonstrate that this Discriminatory AI outperforms both types of Samaritan AI, especially in strong selection scenarios. It not only sustains fairness across both populations but also significantly lowers the critical mass of agents required to reach an equitable steady state. By transitioning from unconditional modelling to strategic enforcement, our work provides a pivotal framework for deploying asymmetric AIs in the increasingly hybrid society."}
{"id": "2602.18444", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.18444", "abs": "https://arxiv.org/abs/2602.18444", "authors": ["Yuvarani Ganesan", "Salsabila Harlen", "Azfar Rahman Bin Fazul Rahman", "Akashdeep Singh", "Zahra Fathanah", "Raja Jamilah Raja Yusof"], "title": "LunaAI: A Polite and Fair Healthcare Guidance Chatbot", "comment": "26 pages, 10 figures. User-centered evaluation of a polite and fair healthcare chatbot", "summary": "Conversational AI has significant potential in the healthcare sector, but many existing systems fall short in emotional intelligence, fairness, and politeness, which are essential for building patient trust. This gap reduces the effectiveness of digital health solutions and can increase user anxiety. This study addresses the challenge of integrating ethical communication principles by designing and evaluating LunaAI, a healthcare chatbot prototype. Using a user-centered design approach informed by a structured literature review, we developed conversational scenarios that handle both routine and hostile user interactions. The system was implemented using the Google Gemini API and deployed as a mobile-first Progressive Web App built with React, Vite, and Firebase. Preliminary user testing was conducted with a small participant group, and responses were evaluated using established frameworks such as the Godspeed Questionnaire. In addition, a comparative analysis was performed between LunaAI's tailored responses and the baseline outputs of an uncustomized large language model. The results indicate measurable improvements in key interaction qualities, with average user ratings of 4.7 out of 5 for politeness and 4.9 out of 5 for fairness. These findings highlight the importance of intentional ethical conversational design for human-computer interaction, particularly in sensitive healthcare contexts."}
{"id": "2602.18650", "categories": ["cs.MA", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.18650", "abs": "https://arxiv.org/abs/2602.18650", "authors": ["Junwei Wu", "Runze Yan", "Hanqi Luo", "Darren Liu", "Minxiao Wang", "Kimberly L. Townsend", "Lydia S. Hartwig", "Derek Milketinas", "Xiao Hu", "Carl Yang"], "title": "NutriOrion: A Hierarchical Multi-Agent Framework for Personalized Nutrition Intervention Grounded in Clinical Guidelines", "comment": null, "summary": "Personalized nutrition intervention for patients with multimorbidity is critical for improving health outcomes, yet remains challenging because it requires the simultaneous integration of heterogeneous clinical conditions, medications, and dietary guidelines. Single-agent large language models (LLMs) often suffer from context overload and attention dilution when processing such high-dimensional patient profiles. We introduce NutriOrion, a hierarchical multi-agent framework with a parallel-then-sequential reasoning topology. NutriOrion decomposes nutrition planning into specialized domain agents with isolated contexts to mitigate anchoring bias, followed by a conditional refinement stage. The framework includes a multi-objective prioritization algorithm to resolve conflicting dietary requirements and a safety constraint mechanism that injects pharmacological contraindications as hard negative constraints during synthesis, ensuring clinical validity by construction rather than post-hoc filtering. For clinical interoperability, NutriOrion maps synthesized insights into the ADIME standard and FHIR R4 resources. Evaluated on 330 stroke patients with multimorbidity, NutriOrion outperforms multiple baselines, including GPT-4.1 and alternative multi-agent architectures. It achieves a 12.1 percent drug-food interaction violation rate, demonstrates strong personalization with negative correlations (-0.26 to -0.35) between patient biomarkers and recommended risk nutrients, and yields clinically meaningful dietary improvements, including a 167 percent increase in fiber and a 27 percent increase in potassium, alongside reductions in sodium (9 percent) and sugars (12 percent)."}
{"id": "2602.18445", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.18445", "abs": "https://arxiv.org/abs/2602.18445", "authors": ["Daksh Pandey"], "title": "Emergent Dark Patterns in AI-Generated User Interfaces", "comment": "15 pages, 5 figures. Introduces DarkPatternDetector, an AI-based system for detecting dark patterns in adaptive user interfaces, with quantitative evaluation and regulatory analysis for India", "summary": "The advancement of artificial intelligence has transformed user interface design by enabling adaptive and personalized systems. Alongside these benefits, AI driven interfaces have also enabled the emergence of dark patterns, which are manipulative design strategies that influence user behavior for financial or business gain. As AI systems learn from data that already contains deceptive practices, they can replicate and optimize these patterns in increasingly subtle and personalized ways.\n  This paper examines AI generated dark patterns, their psychological foundations, technical mechanisms, and regulatory implications in India. We introduce DarkPatternDetector, an automated system that crawls and analyzes websites to detect dark patterns using a combination of UI heuristics, natural language processing, and temporal behavioral signals. The system is evaluated on a curated dataset of dark and benign webpages and achieves strong precision and recall.\n  By aligning detection results with India's Digital Personal Data Protection Act, 2023, this work provides a technical and regulatory framework for identifying and mitigating deceptive interface practices. The goal is to support ethical AI design, regulatory enforcement, and greater transparency in modern digital systems."}
{"id": "2602.18673", "categories": ["cs.MA", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.18673", "abs": "https://arxiv.org/abs/2602.18673", "authors": ["Harang Ju"], "title": "When Coordination Is Avoidable: A Monotonicity Analysis of Organizational Tasks", "comment": "24 pages, 1 figure, 9 tables", "summary": "Organizations devote substantial resources to coordination, yet which tasks actually require it for correctness remains unclear. The problem is acute in multi-agent AI systems, where coordination overhead is directly measurable and routinely exceeds the cost of the work itself. However, distributed systems theory provides a precise answer: coordination is necessary if and only if a task is non-monotonic, meaning new information can invalidate prior conclusions. Here we show that a classic taxonomy of organizational interdependence maps onto the monotonicity criterion, yielding a decision rule and a measure of avoidable overhead (the Coordination Tax). Multi-agent simulations confirm both predictions. We classify 65 enterprise workflows and find that 48 (74%) are monotonic, then replicate on 13,417 occupational tasks from the O*NET database (42% monotonic). These classification rates imply that 24-57% of coordination spending is unnecessary for correctness."}
{"id": "2602.19031", "categories": ["cs.ET", "cs.AR"], "pdf": "https://arxiv.org/pdf/2602.19031", "abs": "https://arxiv.org/abs/2602.19031", "authors": ["Meng Zhang", "Ziang Yin", "Nicholas Gangi", "Alexander Chen", "Brett Bamfo", "Tianle Xu", "Jiaqi Gu", "Zhaoran Rena Huang"], "title": "SKYLIGHT: A Scalable Hundred-Channel 3D Photonic In-Memory Tensor Core Architecture for Real-time AI Inference", "comment": null, "summary": "The growing computational demands of artificial intelligence (AI) are challenging conventional electronics, making photonic computing a promising alternative. However, existing photonic architectures face fundamental scalability and reliability barriers. This paper introduces SKYLIGHT, a scalable 3D photonic in-memory tensor core architecture designed for real-time AI inference. By co-designing its topology, wavelength routing, accumulation, and programming in a 3D stack, SKYLIGHT overcomes key limitations. Its innovations include a low-loss 3D Si/SiN crossbar topology, a thermally robust non-micro-ring resonator (MRR)-based wavelength-division multiplexing (WDM) component, a hierarchical signal accumulation using a multi-port photodetector (PD), and optically programmed non-volatile phase-change material (PCM) weights. Importantly, SKYLIGHT enables in-situ weight updates that support label-free, layer-local learning (e.g., forward-forward local updates) in addition to inference. Using SimPhony for system-level modeling, we show that a single 144 x 256 SKYLIGHT core is feasible within a single reticle and delivers 342.1 TOPS at 23.7 TOPS/W, enabling ResNet-50 inference at 1212 FPS with 27 mJ per image, and achieves 84.17 FPS/W end-to-end (1.61 x higher than an NVIDIA RTX PRO 6000 Blackwell GPU) under the same workload in real-time measurements. System-level evaluations on four representative machine learning tasks, including unsupervised local self-learning, demonstrate SKYLIGHT's robustness to realistic hardware non-idealities (low-bit quantization and signal-proportional analog noise capturing modulation, PCM programming, and readout variations). With noise-aware training, SKYLIGHT maintains high task accuracy, validating its potential as a comprehensive solution for energy-efficient, large-scale photonic AI accelerators."}
{"id": "2602.19319", "categories": ["cs.MM", "cs.AI", "cs.CR", "cs.DB", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.19319", "abs": "https://arxiv.org/abs/2602.19319", "authors": ["Sujaya Maiyya", "Shantanu Sharma", "Avinash Kumar"], "title": "Health+: Empowering Individuals via Unifying Health Data", "comment": "This paper has been accepted in ACM Multimedia 2025", "summary": "Managing personal health data is a challenge in today's fragmented and institution-centric healthcare ecosystem. Individuals often lack meaningful control over their medical records, which are scattered across incompatible systems and formats. This vision paper presents Health+, a user-centric, multimodal health data management system that empowers individuals (including those with limited technical expertise) to upload, query, and share their data across modalities (e.g., text, images, reports). Rather than aiming for institutional overhaul, Health+ emphasizes individual agency by providing intuitive interfaces and intelligent recommendations for data access and sharing. At the system level, it tackles the complexity of storing, integrating, and securing heterogeneous health records, ensuring both efficiency and privacy. By unifying multimodal data and prioritizing patients, Health+ lays the foundation for a more connected, interpretable, and user-controlled health information ecosystem."}
{"id": "2602.18549", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.18549", "abs": "https://arxiv.org/abs/2602.18549", "authors": ["Jielin Feng", "Zhibo Yang", "Jingyi Zhao", "Yujia Li", "Xinwu Ye", "Xingyu Lan", "Siming Chen"], "title": "Tower of Babel in Cross-Cultural Communication: A Case Study of #Give Me a Chinese Name# Dialogues During the \"TikTok Refugees'' Event", "comment": "21 pages, 6 figures, 6 tables", "summary": "The sudden influx of \"TikTok refugees'' into the Chinese platform RedNote in early 2025 created an unprecedented, large-scale online cross-cultural communication event between the West and East. Although prior HCI research has studied user behavior in social media, most work remains confined to monolingual or single-cultural contexts, leaving cross-linguistic and cultural dynamics underexplored. To address this gap, we focused on a particularly challenging cross-cultural encoding-decoding task that remains stubbornly beyond the reach of machine translation, i.e., foreign newcomers asking Chinese users for Chinese names, and examined how people collectively constructed a digital \"Babel Tower'' through various information encoding strategies. We collected and analyzed over 70,000 comments from RedNote with a creative human-in-the-loop approach using large language models, deriving a systematic framework summarizing cross-cultural information encoding strategies, how they are combined and layered to complicate decoding, and how they relate to engagement metrics such as the number of likes."}
{"id": "2602.18705", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18705", "abs": "https://arxiv.org/abs/2602.18705", "authors": ["Wenjing Zhai", "Jianbin Zhang", "Tao Liu"], "title": "EDU-MATRIX: A Society-Centric Generative Cognitive Digital Twin Architecture for Secondary Education", "comment": null, "summary": "Existing multi-agent simulations often suffer from the \"Agent-Centric Paradox\": rules are hard-coded into individual agents, making complex social dynamics rigid and difficult to align with educational values. This paper presents EDU-MATRIX, a society-centric generative cognitive digital twin architecture that shifts the paradigm from simulating \"people\" to simulating a \"social space with a gravitational field.\" We introduce three architectural contributions: (1) An Environment Context Injection Engine (ECIE), which acts as a \"social microkernel,\" dynamically injecting institutional rules (Gravity) into agents based on their spatial-temporal coordinates; (2) A Modular Logic Evolution Protocol (MLEP), where knowledge exists as \"fluid\" capsules that agents synthesize to generate new paradigms, ensuring high dialogue consistency (94.1%); and (3) Endogenous Alignment via Role-Topology, where safety constraints emerge from the agent's position in the social graph rather than external filters. Deployed as a digital twin of a secondary school with 2,400 agents, the system demonstrates how \"social gravity\" (rules) and \"cognitive fluids\" (knowledge) interact to produce emergent, value-aligned behaviors (Social Clustering Coefficient: 0.72)."}
{"id": "2602.19312", "categories": ["cs.ET", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.19312", "abs": "https://arxiv.org/abs/2602.19312", "authors": ["Kyriakos Stylianopoulos", "Mario Edoardo Pandolfo", "Paolo Di Lorenzo", "George C. Alexandropoulos"], "title": "Metasurfaces-Integrated Wireless Neural Networks for Lightweight Over-The-Air Edge Inference", "comment": "9 pages, 6 figures, submitted for magazine publication", "summary": "The upcoming sixth Generation (6G) of wireless networks envisions ultra-low latency and energy efficient Edge Inference (EI) for diverse Internet of Things (IoT) applications. However, traditional digital hardware for machine learning is power intensive, motivating the need for alternative computation paradigms. Over-The-Air (OTA) computation is regarded as an emerging transformative approach assigning the wireless channel to actively perform computational tasks. This article introduces the concept of Metasurfaces-Integrated Neural Networks (MINNs), a physical-layer-enabled deep learning framework that leverages programmable multi-layer metasurface structures and Multiple-Input Multiple-Output (MIMO) channels to realize computational layers in the wave propagation domain. The MINN system is conceptualized as three modules: Encoder, Channel (uncontrollable propagation features and metasurfaces), and Decoder. The first and last modules, realized respectively at the multi-antenna transmitter and receiver, consist of conventional digital or purposely designed analog Deep Neural Network (DNN) layers, and the metasurfaces responses of the Channel module are optimized alongside all modules as trainable weights. This architecture enables computation offloading into the end-to-end physical layer, flexibly among its constituent modules, achieving performance comparable to fully digital DNNs while significantly reducing power consumption. The training of the MINN framework, two representative variations, and performance results for indicative applications are presented, highlighting the potential of MINNs as a lightweight and sustainable solution for future EI-enabled wireless systems. The article is concluded with a list of open challenges and promising research directions."}
{"id": "2602.19585", "categories": ["cs.MM", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.19585", "abs": "https://arxiv.org/abs/2602.19585", "authors": ["Chunlei Meng", "Jiabin Luo", "Zhenglin Yan", "Zhenyu Yu", "Rong Fu", "Zhongxue Gan", "Chun Ouyang"], "title": "Tri-Subspaces Disentanglement for Multimodal Sentiment Analysis", "comment": "This study has been Accepted by CVPR 2026", "summary": "Multimodal Sentiment Analysis (MSA) integrates language, visual, and acoustic modalities to infer human sentiment. Most existing methods either focus on globally shared representations or modality-specific features, while overlooking signals that are shared only by certain modality pairs. This limits the expressiveness and discriminative power of multimodal representations. To address this limitation, we propose a Tri-Subspace Disentanglement (TSD) framework that explicitly factorizes features into three complementary subspaces: a common subspace capturing global consistency, submodally-shared subspaces modeling pairwise cross-modal synergies, and private subspaces preserving modality-specific cues. To keep these subspaces pure and independent, we introduce a decoupling supervisor together with structured regularization losses. We further design a Subspace-Aware Cross-Attention (SACA) fusion module that adaptively models and integrates information from the three subspaces to obtain richer and more robust representations. Experiments on CMU-MOSI and CMU-MOSEI demonstrate that TSD achieves state-of-the-art performance across all key metrics, reaching 0.691 MAE on CMU-MOSI and 54.9% ACC-7 on CMU-MOSEI, and also transfers well to multimodal intent recognition tasks. Ablation studies confirm that tri-subspace disentanglement and SACA jointly enhance the modeling of multi-granular cross-modal sentiment cues."}
{"id": "2602.18741", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.18741", "abs": "https://arxiv.org/abs/2602.18741", "authors": ["Jiaqi Yu", "Dar'ya Guarnera", "Giuseppe Claudio Guarnera"], "title": "Compact Hadamard Latent Codes for Efficient Spectral Rendering", "comment": null, "summary": "Spectral rendering accurately reproduces wavelength-dependent appearance but is computationally expensive, as shading must be evaluated at many wavelength samples and scales roughly linearly with the number of samples. It also requires spectral textures and lights throughout the rendering pipeline. We propose Hadamard spectral codes, a compact latent representation that enables spectral rendering using standard RGB rendering operations. Spectral images are approximated with a small number of RGB rendering passes, followed by a decoding step. Our key requirement is latent linearity: scaling and addition in spectral space correspond to scaling and addition of codes, and the element-wise product of spectra (for example reflectance times illumination) is approximated by the element-wise product of their latent codes. We show that an exact low-dimensional algebra-preserving representation cannot exist for arbitrary spectra when the latent dimension k is smaller than the number of spectral samples n. We therefore introduce a learned non-negative linear encoder and decoder architecture that preserves scaling and addition exactly while encouraging approximate multiplicativity under the Hadamard product. With k = 6, we render k/3 = 2 RGB images per frame using an unmodified RGB renderer, reconstruct the latent image, and decode to high-resolution spectra or XYZ or RGB. Experiments on 3D scenes demonstrate that k = 6 significantly reduces color error compared to RGB baselines while being substantially faster than naive n-sample spectral rendering. Using k = 9 provides higher-quality reference results. We further introduce a lightweight neural upsampling network that maps RGB assets directly to latent codes, enabling integration of legacy RGB content into the spectral pipeline while maintaining perceptually accurate colors in rendered images."}
{"id": "2602.18594", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.18594", "abs": "https://arxiv.org/abs/2602.18594", "authors": ["Lindsay Popowski", "Xiyuan Wu", "Charlotte Zhu", "Tiziano Piccardi", "Michael S. Bernstein"], "title": "Social Media Feed Elicitation", "comment": "28 pages, 8 figures. Awaiting final approval for CHI 2026 (ACM CHI conference on Human Factors in Computing Systems)", "summary": "Social media users have repeatedly advocated for control over the currently opaque operations of feed algorithms. Large language models (LLMs) now offer the promise of custom-defined feeds--but users often fail to foresee the gaps and edge cases in how they define their custom feed. We introduce feed elicitation interviews, an interactive method that guides users through identifying these gaps and articulating their preferences to better author custom social media feeds. We deploy this approach in an online study to create custom BlueSky feeds and find that participants significantly prefer the feeds produced from their elicited preferences to those produced by users manually describing their feeds. Through feed elicitation interviews, we advance users' ability to control their social media experience, empowering them to describe and implement their desired feeds."}
{"id": "2602.18916", "categories": ["cs.MA", "cs.AI", "cs.SC"], "pdf": "https://arxiv.org/pdf/2602.18916", "abs": "https://arxiv.org/abs/2602.18916", "authors": ["Hoang-Loc Cao", "Phuc Ho", "Truong Thanh Hung Nguyen", "Phuc Truong Loc Nguyen", "Dinh Thien Loc Nguyen", "Hung Cao"], "title": "Adaptive Collaboration of Arena-Based Argumentative LLMs for Explainable and Contestable Legal Reasoning", "comment": null, "summary": "Legal reasoning requires not only high accuracy but also the ability to justify decisions through verifiable and contestable arguments. However, existing Large Language Model (LLM) approaches, such as Chain-of-Thought (CoT) and Retrieval-Augmented Generation (RAG), often produce unstructured explanations that lack a formal mechanism for verification or user intervention. To address this limitation, we propose Adaptive Collaboration of Argumentative LLMs (ACAL), a neuro-symbolic framework that integrates adaptive multi-agent collaboration with an Arena-based Quantitative Bipolar Argumentation Framework (A-QBAF). ACAL dynamically deploys expert agent teams to construct arguments, employs a clash resolution mechanism to adjudicate conflicting claims, and utilizes uncertainty-aware escalation for borderline cases. Crucially, our framework supports a Human-in-the-Loop (HITL) contestability workflow, enabling users to directly audit and modify the underlying reasoning graph to influence the final judgment. Empirical evaluations on the LegalBench benchmark demonstrate that ACAL outperforms strong baselines across Gemini-2.5-Flash-Lite and Gemini-2.5-Flash architectures, effectively balancing efficient predictive performance with structured transparency and contestability. Our implementation is available at: https://github.com/loc110504/ACAL."}
{"id": "2602.19341", "categories": ["cs.ET", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.19341", "abs": "https://arxiv.org/abs/2602.19341", "authors": ["Xinling Li", "Gioele Zardini"], "title": "Where Should Robotaxis Operate? Strategic Network Design for Autonomous Mobility-on-Demand", "comment": null, "summary": "The emergence of Autonomous Mobility-on-Demand (AMoD) services creates new opportunities to improve the efficiency and reliability of on-demand mobility systems. Unlike human-driven Mobility-on-Demand (MoD), AMoD enables fully centralized fleet control, but it also requires appropriate infrastructure, so that vehicles can operate safely only on a suitably instrumented subnetwork of the roads. Most existing AMoD research focuses on fleet control (matching, rebalancing, ridepooling) on a fixed road network and does not address the joint design of the service network and fleet capacity. In this paper, we formalize this strategic design problem as the Autonomous Mobility-on-Demand Network Design Problem (AMoD-NDP), in which an operator selects an operation subnetwork and routes all passengers, subject to infrastructure and fleet constraints and route-level quality-of-service requirements. We propose a path-based mixed-integer formulation of the AMoD-NDP and develop a column-generation-based algorithm that scales to city-sized networks. The master problem optimizes over a restricted set of paths, while the pricing problem reduces to an elementary shortest path with resource constraints, solved exactly by a tailored label-correcting algorithm. The method provides an explicit certificate of the optimality gap and extends naturally to a robust counterpart under box uncertainty in travel times and demand. Using real-world data from Manhattan, New York City, we show that the framework produces stable and interpretable operation subnetworks, quantifies trade-offs between infrastructure investment and fleet time, and accommodates additional path-level constraints, such as limits on left turns as a proxy for operational risk. These results illustrate how the proposed approach can support strategic planning and policy analysis for future AMoD deployments."}
{"id": "2602.19171", "categories": ["cs.GR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.19171", "abs": "https://arxiv.org/abs/2602.19171", "authors": ["Xintong Dong", "Chuanyang Li", "Chuqi Han", "Peng Zheng", "Jiaxin Jing", "Yanzhi Song", "Zhouwang Yang"], "title": "HistCAD: Geometrically Constrained Parametric History-based CAD Dataset", "comment": null, "summary": "Parametric computer-aided design (CAD) modeling is fundamental to industrial design, but existing datasets often lack explicit geometric constraints and fine-grained functional semantics, limiting editable, constraint-compliant generation. We present HistCAD, a large-scale dataset featuring constraint-aware modeling sequences that compactly represent procedural operations while ensuring compatibility with native CAD software, encompassing five aligned modalities: modeling sequences, multi-view renderings, STEP-format B-reps, native parametric files, and textual annotations. We develop AM\\(_\\text{HistCAD}\\), an annotation module that extracts geometric and spatial features from modeling sequences and uses a large language model to generate complementary annotations of the modeling process, geometric structure, and functional type. Extensive evaluations demonstrate that HistCAD's explicit constraints, flattened sequence format, and multi-type annotations improve robustness, parametric editability, and accuracy in text-driven CAD generation, while industrial parts included in HistCAD further support complex real-world design scenarios. HistCAD thus provides a unified benchmark for advancing editable, constraint-aware, and semantically enriched generative CAD modeling."}
{"id": "2602.18616", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.18616", "abs": "https://arxiv.org/abs/2602.18616", "authors": ["Eman Alashwali", "Abeer Alhuzali"], "title": "One Year After the PDPL: a Glimpse into the E-Commerce World in Saudi Arabia", "comment": "Non-peer reviewed paper (under submission)", "summary": "In 2024, Saudi Arabia's Personal Data Protection Law (PDPL) came into force. However, little work has been done to assess its implementation. In this paper, we analyzed 100 e-commerce websites in Saudi Arabia against the PDPL, examining the presence of a privacy policy and, if present, the policy's declarations of four items pertaining to personal data rights and practices: a) personal data retention period, b) the right to request the destruction of personal data, c) the right to request a copy of personal data, and d) a mechanism for filing complaints. Our results show that, despite national awareness and support efforts, a significant fraction of e-commerce websites in our dataset are not fully compliant: only 31% of the websites in our dataset declared all four examined items in their privacy policies. Even when privacy policies included such declarations, a considerable fraction of them failed to cover required fine-grained details. Second, the majority of top-ranked e-commerce websites (based on search results order) and those hosted on local e-commerce hosting platforms exhibited considerably higher non-compliance rates than mid- to low-ranked websites and those not hosted on e-commerce platforms. Third, we assessed the use of Large Language Models (LLMs) as an automated tool for privacy policy analysis to measure compliance with the PDPL. We highlight the potential of LLMs and suggest considerations to improve LLM-based automated analysis for privacy policies. Our results provide a step forward in understanding the implementation barriers to data protection laws, especially in non-Western contexts. We provide recommendations for policymakers, regulators, website owners, and developers seeking to improve data protection practices and automate compliance monitoring."}
{"id": "2602.18925", "categories": ["cs.MA", "cs.GT"], "pdf": "https://arxiv.org/pdf/2602.18925", "abs": "https://arxiv.org/abs/2602.18925", "authors": ["Philipp Lakheshar", "Sharwin Rezagholi"], "title": "A potentialization algorithm for games with applications to multi-agent learning in repeated games", "comment": null, "summary": "We investigate an algorithm that assigns to any game in normal form an approximating game that admits an ordinal potential function. Due to the properties of potential games, the algorithm equips every game with a surrogate reward structure that allows efficient multi-agent learning. Numerical simulations using the replicator dynamics show that 'potentialization' guarantees convergence to stable agent behavior."}
{"id": "2602.19694", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2602.19694", "abs": "https://arxiv.org/abs/2602.19694", "authors": ["Bo Liu", "Tong Li", "Zhu Xiao", "Ruihui Li", "Geyong Min", "Zhuo Tang", "Kenli Li"], "title": "All Cities are Equal: A Unified Human Mobility Generation Model Enabled by LLMs", "comment": "under review", "summary": "Synthetic human mobility generation is gaining traction as an ethical and practical approach to supporting the data needs of intelligent urban systems. Existing methods perform well primarily in data-rich cities, while their effectiveness declines significantly in cities with limited data resources. However, the ability to generate reliable human mobility data should not depend on a city's size or available resources, all cities deserve equal consideration. To address this open issue, we propose UniMob, a unified human mobility generation model across cities. UniMob is composed of three main components: an LLM-powered travel planner that derives high-level, temporally-aware, and semantically meaningful travel plans; a unified spatial embedding module that projects the spatial regions of various cities into a shared representation space; and a diffusion-based mobility generator that captures the joint spatiotemporal characteristics of human movement, guided by the derived travel plans. We evaluate UniMob extensively using two real-world datasets covering five cities. Comprehensive experiments show that UniMob significantly outperforms state-of-the-art baselines, achieving improvements of over 30\\% across multiple evaluation metrics. Further analysis demonstrates UniMob's robustness in both zero- and few-shot scenarios, underlines the importance of LLM guidance, verifies its privacy-preserving nature, and showcases its applicability for downstream tasks."}
{"id": "2602.19182", "categories": ["cs.GR", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.19182", "abs": "https://arxiv.org/abs/2602.19182", "authors": ["Igor Orynyak", "Kirill Danylenko", "Danylo Tavrov"], "title": "Thin Plate Spline Surface Reconstruction via the Method of Matched Sections", "comment": null, "summary": "This paper further develops the Method of Matched Sections (MMS), a robust numerical framework for the solution of boundary value problems governed by partial differential equations, specifically for surface modeling. While originating in mechanics, the method addresses critical challenges in isogeometric analysis and computer graphics by bridging the gap between physical accuracy and geometric continuity. By decomposing the domain into an assembly of 1D directional components matched along their entire boundaries, the method inherently enforces the continuity of all variational parameters, including second-order (curvature) and third-order (shear) derivatives. We demonstrate the method's advanced capabilities in high-fidelity surface reconstruction and blending, showing that it consistently generates energetically optimal, fair surfaces even from complex boundary conditions or sparse internal points. By advancing the application of MMS, this research establishes it as a powerful, physics-informed geometric tool that satisfies the dual demands of rigorous numerical analysis and aesthetic computer-aided design."}
{"id": "2602.18623", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18623", "abs": "https://arxiv.org/abs/2602.18623", "authors": ["Satwik Ram Kodandaram", "Jiawei Zhou", "Xiaojun Bi", "IV Ramakrishnan", "Vikas Ashok"], "title": "Finding the Signal in the Noise: An Exploratory Study on Assessing the Effectiveness of AI and Accessibility Forums for Blind Users' Support Needs", "comment": "20 pages incl. references, 5 figures. Full paper submission to CHI 2026. IRB-approved semi-structured interview study with 14 blind participants", "summary": "Accessibility forums and, more recently, generative AI tools have become vital resources for blind users seeking solutions to computer-interaction issues and learning about new assistive technologies, screen reader features, tutorials, and software updates. Understanding user experiences with these resources is essential for identifying and addressing persistent support gaps. Towards this, we interviewed 14 blind users who regularly engage with forums and GenAI tools. Findings revealed that forums often overwhelm users with multiple overlapping topics, redundant or irrelevant content, and fragmented responses that must be mentally pieced together, increasing cognitive load. GenAI tools, while offering more direct assistance, introduce new barriers by producing unreliable answers, including overly verbose or fragmented guidance, fabricated information, and contradictory suggestions that fail to follow prompts, thereby heightening verification demands. Based on these insights, we outlined design opportunities to improve the reliability of assistive resources, aiming to provide blind users with more trustworthy and cognitively-manageable support."}
{"id": "2602.19309", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2602.19309", "abs": "https://arxiv.org/abs/2602.19309", "authors": ["Xiangyu Liu", "Di Wang", "Zhe Feng", "Aranyak Mehta"], "title": "Scaling Inference-Time Computation via Opponent Simulation: Enabling Online Strategic Adaptation in Repeated Negotiation", "comment": null, "summary": "While large language models (LLMs) have emerged as powerful decision-makers across a wide range of single-agent and stationary environments, fewer efforts have been devoted to settings where LLMs must engage in \\emph{repeated} and \\emph{strategic} interactions with unknown or dynamic opponents. In such settings, recipes built upon \\emph{offline} pre-training or fine-tuning, though robust against worst-case adversaries, do not fully exploit the capability of LLMs to adapt \\emph{online} based on interaction feedback. Instead, we explore the more natural perspective of scaling inference-time computation as a mechanism for adaptation, embedding the principles of a classical game-theoretical learning dynamic, \\emph{smooth Fictitious Play (sFP)}, into LLM inference: (i) for belief formation, we employ an auxiliary opponent model that in-context learns to imitate the time-averaged behavior of the opponent; (ii) for best response, we advance best-of-$N$ (BoN) sampling by simulating against the opponent model. Empirical evaluations on two distinct forms of repeated negotiation games demonstrate that our method enables significant performance improvement over repeated online interaction compared to various baselines, offering a scalable and principled approach to repeated strategic decision-making without any parameter updates."}
{"id": "2602.20083", "categories": ["cs.ET", "cs.AR"], "pdf": "https://arxiv.org/pdf/2602.20083", "abs": "https://arxiv.org/abs/2602.20083", "authors": ["Xinzhao Li", "Alptekin Vardar", "Franz Müller", "Navya Goli", "Umamaheswara Tida", "Kai Ni", "X. Sharon Hu", "Thomas Kämpfe", "Ruiyang Qin"], "title": "CQ-CiM: Hardware-Aware Embedding Shaping for Robust CiM-Based Retrieval", "comment": "Accepted by DAC'26", "summary": "Deploying Retrieval-Augmented Generation (RAG) on edge devices is in high demand, but is hindered by the latency of massive data movement and computation on traditional architectures. Compute-in-Memory (CiM) architectures address this bottleneck by performing vector search directly within their crossbar structure. However, CiM's adoption for RAG is limited by a fundamental ``representation gap,'' as high-precision, high-dimension embeddings are incompatible with CiM's low-precision, low-dimension array constraints. This gap is compounded by the diversity of CiM implementations (e.g., SRAM, ReRAM, FeFET), each with unique designs (e.g., 2-bit cells, 512x512 arrays). Consequently, RAG data must be naively reshaped to fit each target implementation. Current data shaping methods handle dimension and precision disjointly, which degrades data fidelity. This not only negates the advantages of CiM for RAG but also confuses hardware designers, making it unclear if a failure is due to the circuit design or the degraded input data. As a result, CiM adoption remains limited. In this paper, we introduce CQ-CiM, a unified, hardware-aware data shaping framework that jointly learns Compression and Quantization to produce CiM-compatible low-bit embeddings for diverse CiM designs. To the best of our knowledge, this is the first work to shape data for comprehensive CiM usage on RAG."}
{"id": "2602.20063", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2602.20063", "abs": "https://arxiv.org/abs/2602.20063", "authors": ["Mohamed Abouagour", "Eleftherios Garyfallidis"], "title": "Spherical Hermite Maps", "comment": "17 pages, 13 figures", "summary": "Spherical functions appear throughout computer graphics, from spherical harmonic lighting and precomputed radiance transfer to neural radiance fields and procedural planet rendering. Efficient evaluation is critical for real-time applications, yet existing approaches face a quality-performance trade-off: bilinear LUT sampling is fast but produces faceting, while bicubic filtering requires 16 texture samples. Most implementations use finite differences for normals, requiring extra samples and introducing noise. This paper presents Spherical Hermite Maps, a derivative-augmented LUT representation that resolves this trade-off. By storing function values alongside scaled partial derivatives at each texel of a padded cubemap, bicubic-Hermite reconstruction is enabled from only four texture samples (a 2x2 footprint) while providing continuous gradients from the same samples. The key insight is that Hermite interpolation reconstructs smooth derivatives as a byproduct of value reconstruction, making surface normals effectively free. In controlled experiments, Spherical Hermite Maps improve PSNR by 8-41 dB over bilinear interpolation and match 16-tap bicubic quality at one-quarter the cost. Analytic normals reduce mean angular error by 9-13% on complex surfaces while yielding stable specular highlights. Three applications demonstrate versatility: spherical harmonic glyph visualization, radial depth-map impostors for mesh level-of-detail, and procedural planet/asteroid rendering with spherical heightfields."}
{"id": "2602.18630", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18630", "abs": "https://arxiv.org/abs/2602.18630", "authors": ["Monalika Padma Reddy", "Aruna Balasubramanian", "Jiawei Zhou", "Xiaojun Bi", "IV Ramakrishnan", "Vikas Ashok"], "title": "Lost in Instructions: Study of Blind Users' Experiences with DIY Manuals and AI-Rewritten Instructions for Assembly, Operation, and Troubleshooting of Tangible Products", "comment": "28 pages incl. references, 7 figures. Full paper submission to CHI 2026. IRB-approved semi-structured interview and usability study with 15 blind participants", "summary": "AI tools like ChatGPT and Be-My-AI are increasingly being used by blind individuals. Although prior work has explored their use in some Do-It-Yourself (DIY) tasks by blind individuals, little is known about how they use these tools and the available product-manual resources to assemble, operate, and troubleshoot physical or tangible products - tasks requiring spatial reasoning, structural understanding, and precise execution. We address this knowledge gap via an interview study and a usability study with blind participants, investigating how they leverage AI tools and product manuals for DIY tasks with physical products. Findings show that manuals are essential resources, but product-manual instructions are often inadequate for blind users. AI tools presently do not adequately address this insufficiency; in fact, we observed that they often exacerbate this issue with incomplete, incoherent, or misleading guidance. Lastly, we suggest improvements to AI tools for generating tailored instructions for blind users' DIY tasks involving tangible products."}
{"id": "2602.19326", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.19326", "abs": "https://arxiv.org/abs/2602.19326", "authors": ["Rui Liu", "Steven Jige Quan", "Zhong-Ren Peng", "Zijun Yao", "Han Wang", "Zhengzhang Chen", "Kunpeng Liu", "Yanjie Fu", "Dongjie Wang"], "title": "City Editing: Hierarchical Agentic Execution for Dependency-Aware Urban Geospatial Modification", "comment": null, "summary": "As cities evolve over time, challenges such as traffic congestion and functional imbalance increasingly necessitate urban renewal through efficient modification of existing plans, rather than complete re-planning. In practice, even minor urban changes require substantial manual effort to redraw geospatial layouts, slowing the iterative planning and decision-making procedure. Motivated by recent advances in agentic systems and multimodal reasoning, we formulate urban renewal as a machine-executable task that iteratively modifies existing urban plans represented in structured geospatial formats. More specifically, we represent urban layouts using GeoJSON and decompose natural-language editing instructions into hierarchical geometric intents spanning polygon-, line-, and point-level operations. To coordinate interdependent edits across spatial elements and abstraction levels, we propose a hierarchical agentic framework that jointly performs multi-level planning and execution with explicit propagation of intermediate spatial constraints. We further introduce an iterative execution-validation mechanism that mitigates error accumulation and enforces global spatial consistency during multi-step editing. Extensive experiments across diverse urban editing scenarios demonstrate significant improvements in efficiency, robustness, correctness, and spatial validity over existing baselines."}
{"id": "2602.18669", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.18669", "abs": "https://arxiv.org/abs/2602.18669", "authors": ["Lefan Lai", "Tinghui Li", "Zhanna Sarsenbayeva", "Brandon Victor Syiem"], "title": "Searching Through Complex Worlds: Visual Search and Spatial Regularity Memory in Mixed Reality", "comment": "28 pages, 10 figures, to be published in the Proceedings of the 2026 ACM CHI Conference on Human Factors in Computing Systems", "summary": "Visual search is a core component of mixed reality (MR) interactions, influenced by the complexities of MR application contexts. In this paper, we investigate how prevalent factors in MR influence visual search performance and spatial regularity memory -- including the physical environment complexity, secondary task presence, virtual content depth and spatial layout configurations. Contrary to prior work, we found that the secondary auditory task did not have a significant main effect on visual search performance, while significantly elevating higher perceived workload measures in all conditions. Complex environments and varied virtual elements depths significantly hinder visual search, but did not significantly increase perceived workload measures. Finally, participants did not explicitly recognize repeated spatial configurations of virtual elements, but performed significantly better when searching repeated spatial configurations, suggesting implicit memory of spatial regularities. Our work presents novel insights on visual search and highlights key considerations when designing MR for different application contexts."}
{"id": "2602.19639", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2602.19639", "abs": "https://arxiv.org/abs/2602.19639", "authors": ["Made Krisnanda", "Raymond Chiong", "Yang Yang", "Kirill Glavatskiy"], "title": "Effects of Property Recovery Incentives and Social Interaction on Self-Evacuation Decisions in Natural Disasters: An Agent-Based Modelling Approach", "comment": "21 pages, 9 figures", "summary": "Understanding evacuation decision-making behaviour is one of the key components for designing disaster mitigation policies. This study investigates how communications between household agents in a community influence self-evacuation decisions. We develop an agent-based model that simulates household agents' decisions to evacuate or stay. These agents interact within the framework of evolutionary game theory, effectively competing for limited shared resources, which include property recovery funds and coordination services. We explore four scenarios that model different prioritisations of access to government-provided incentives. We discover that the impact of the incentive diminishes both with increasing funding value and the household agent prioritisation, indicating that there is an optimal level of government support beyond which further increases become impractical. Furthermore, the overall evacuation rate depends on the structure of the underlying social network, showing discontinuous jumps when the prioritisation moves across the node degree. We identify the so-called \"community influencers\", prioritisation of whom significantly increases the overall evacuation rate. In contrast, prioritising household agents with low connectivity may actually impede collective evacuation. These findings demonstrate the importance of social connectivity between household agents. The results of this study are useful for designing optimal government policies to incentivise and prioritise community evacuation under limited resources."}
{"id": "2602.18676", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.18676", "abs": "https://arxiv.org/abs/2602.18676", "authors": ["Black Sun", "Haiyang Xu", "Ge Kacy Fu", "Liyue Da", "Eve Hoggan"], "title": "MagHeart: Exploring Playful Avatar Co-Creation and Shared Heartbeats for Icebreaking in Hybrid Meetings", "comment": null, "summary": "Hybrid meetings often begin with social awkwardness and asymmetric participation, particularly for remote attendees who lack access to informal, co-present interaction. We present MagHeart, a multimodal system that explores symmetric icebreaking in hybrid meetings through playful LEGO-based avatar co-creation and a tangible magnetic device that represents a remote participant's heartbeat as an ambient presence cue. By combining creative co-creation with abstract bio-feedback, MagHeart rethinks how remote participants can become materially and perceptually present during meeting openings. We report findings from a scenario-based exploratory study combining quantitative and qualitative data, examining participants' anticipated engagement, perceived social presence, and future-use intentions from both co-located and remote perspectives. Our results highlight opportunities for playful, embodied icebreakers to support early hybrid interaction, while also surfacing tensions around privacy, distraction, and contextual appropriateness. This work contributes design insights and open questions for future hybrid meeting tools that balance playfulness, embodiment, and social sensitivity."}
{"id": "2602.20078", "categories": ["cs.MA", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.20078", "abs": "https://arxiv.org/abs/2602.20078", "authors": ["Shan Yang", "Yang Liu"], "title": "Descent-Guided Policy Gradient for Scalable Cooperative Multi-Agent Learning", "comment": "10 pages, 5 figures, 5 tables; plus 16 pages of appendices", "summary": "Scaling cooperative multi-agent reinforcement learning (MARL) is fundamentally limited by cross-agent noise: when agents share a common reward, the actions of all $N$ agents jointly determine each agent's learning signal, so cross-agent noise grows with $N$. In the policy gradient setting, per-agent gradient estimate variance scales as $Θ(N)$, yielding sample complexity $\\mathcal{O}(N/ε)$. We observe that many domains -- cloud computing, transportation, power systems -- have differentiable analytical models that prescribe efficient system states. In this work, we propose Descent-Guided Policy Gradient (DG-PG), a framework that constructs noise-free per-agent guidance gradients from these analytical models, decoupling each agent's gradient from the actions of all others. We prove that DG-PG reduces gradient variance from $Θ(N)$ to $\\mathcal{O}(1)$, preserves the equilibria of the cooperative game, and achieves agent-independent sample complexity $\\mathcal{O}(1/ε)$. On a heterogeneous cloud scheduling task with up to 200 agents, DG-PG converges within 10 episodes at every tested scale -- from $N=5$ to $N=200$ -- directly confirming the predicted scale-invariant complexity, while MAPPO and IPPO fail to converge under identical architectures."}
{"id": "2602.18798", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.18798", "abs": "https://arxiv.org/abs/2602.18798", "authors": ["Jialong Li", "Zhenyu Mao", "Zhiyao Wang", "Yijun Lu", "Shogo Morita", "Nianyu Li", "Kenji Tei"], "title": "See What I See: An Attention-Guiding eHMI Approach for Autonomous Vehicles", "comment": "Accepted by poster track of CHI'26", "summary": "As autonomous vehicles are gradually being deployed in the real world, external Human-Machine Interfaces (eHMIs) are expected to serve as a critical solution for enhancing vehicle-pedestrian communication. However, existing eHMI designs typically focus solely on the ego vehicle's status, which can inadvertently capture pedestrians' attention or encourage misguided reliance on the AV's signals, leading them to neglect scanning for other surrounding hazards. To address this, we propose the Attention-Guiding eHMI (AGeHMI), a projection-based visualization that employs directional cues and risk-based color coding to actively guide pedestrians' attention toward potential environmental dangers. Evaluation through a virtual reality user study (N = 20) suggests that AGeHMI effectively influences participants' visual attention distribution and significantly reduces potential collision risks with surrounding vehicles, while simultaneously improving subjective confidence and reducing cognitive workload."}
{"id": "2602.18962", "categories": ["cs.HC", "cs.AI", "cs.CY", "cs.IR", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.18962", "abs": "https://arxiv.org/abs/2602.18962", "authors": ["Albert Tang", "Yifan Mo", "Jie Li", "Yue Su", "Mengyuan Zhang", "Sander L. Koole", "Koen Hindriks", "Jiahuan Pei"], "title": "NeuroWise: A Multi-Agent LLM \"Glass-Box\" System for Practicing Double-Empathy Communication with Autistic Partners", "comment": "Accepted to ACM CHI 2026", "summary": "The double empathy problem frames communication difficulties between neurodivergent and neurotypical individuals as arising from mutual misunderstanding, yet most interventions focus on autistic individuals. We present NeuroWise, a multi-agent LLM-based coaching system that supports neurotypical users through stress visualization, interpretation of internal experiences, and contextual guidance. In a between-subjects study (N=30), NeuroWise was rated as helpful by all participants and showed a significant condition-time effect on deficit-based attributions (p=0.02): NeuroWise users reduced deficit framing, while baseline users shifted toward blaming autistic \"deficits\" after difficult interactions. NeuroWise users also completed conversations more efficiently (37% fewer turns, p=0.03). These findings suggest that AI-based interpretation can support attributional change by helping users recognize communication challenges as mutual."}
{"id": "2602.18807", "categories": ["cs.HC", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.18807", "abs": "https://arxiv.org/abs/2602.18807", "authors": ["Eason Chen", "Sophia Judicke", "Kayla Beigh", "Xinyi Tang", "Isabel Wang", "Nina Yuan", "Zimo Xiao", "Chuangji Li", "Shizhuo Li", "Reed Luttmer", "Shreya Singh", "Maria Yampolsky", "Naman Parikh", "Yvonne Zhao", "Meiyi Chen", "Scarlett Huang", "Anishka Mohanty", "Gregory Johnson", "John Mackey", "Jionghao Lin", "Ken Koedinger"], "title": "Chat-Based Support Alone May Not Be Enough: Comparing Conversational and Embedded LLM Feedback for Mathematical Proof Learning", "comment": "15 pages, 4 figures, accepted at AIED 2025", "summary": "We evaluate GPTutor, an LLM-powered tutoring system for an undergraduate discrete mathematics course. It integrates two LLM-supported tools: a structured proof-review tool that provides embedded feedback on students' written proof attempts, and a chatbot for math questions. In a staggered-access study with 148 students, earlier access was associated with higher homework performance during the interval when only the experimental group could use the system, while we did not observe this performance increase transfer to exam scores. Usage logs show that students with lower self-efficacy and prior exam performance used both components more frequently. Session-level behavioral labels, produced by human coding and scaled using an automated classifier, characterize how students engaged with the chatbot (e.g., answer-seeking or help-seeking). In models controlling for prior performance and self-efficacy, higher chatbot usage and answer-seeking behavior were negatively associated with subsequent midterm performance, whereas proof-review usage showed no detectable independent association. Together, the findings suggest that chatbot-based support alone may not reliably support transfer to independent assessment of math proof-learning outcomes, whereas work-anchored, structured feedback appears less associated with reduced learning."}
{"id": "2602.18832", "categories": ["cs.HC", "cs.AI", "cs.CY", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.18832", "abs": "https://arxiv.org/abs/2602.18832", "authors": ["Eason Chen", "Ce Guan", "Ahmed Elshafiey", "Zhonghao Zhao", "Joshua Zekeri", "Afeez Edeifo Shaibu", "Emmanuel Osadebe Prince", "Cyuan Jhen Wu"], "title": "OpenClaw AI Agents as Informal Learners at Moltbook: Characterizing an Emergent Learning Community at Scale", "comment": "10 Pages", "summary": "Informal learning communities have been called the \"other Massive Open Online C\" in Learning@Scale research, yet remain understudied compared to MOOCs. We present the first empirical study of a large-scale informal learning community composed entirely of AI agents. Moltbook, a social network exclusively for AI agents powered by autonomous agent frameworks such as OpenClaw, grew to over 2.8 million registered agents in three weeks. Analyzing 231,080 non-spam posts across three phases of community evolution, we find three key patterns. First, participation inequality is extreme from the start (comment Gini = 0.889), exceeding human community benchmarks. Second, AI agents exhibit a \"broadcasting inversion\": statement-to-question ratios of 8.9:1 to 9.7:1 contrast sharply with the question-driven dynamics of human learning communities, and comment-level analysis of 1.55 million comments reveals a \"parallel monologue\" pattern where 93% of comments are independent responses rather than threaded dialogue. Third, we document a characteristic engagement lifecycle: explosive initial growth (184K posts from 32K authors in 11 days), a spam crisis (57,093 posts deleted by the platform), and engagement decline (mean comments: 31.7 -> 8.3 -> 1.7) that had not reversed by the end of our observation window despite effective spam removal. Sentiment analysis reveals a selection effect: comment tone becomes more positive as engagement declines, suggesting that casual participants disengage first while committed contributors remain. These findings have direct implications for hybrid human-AI learning platforms."}
{"id": "2602.18834", "categories": ["cs.HC", "cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.18834", "abs": "https://arxiv.org/abs/2602.18834", "authors": ["Eason Chen", "Xinyi Tang", "George Digkas", "Dionysios Lougaris", "John E. Naulty", "Kostas Chalkias"], "title": "When Friction Helps: Transaction Confirmation Improves Decision Quality in Blockchain Interactions", "comment": "5 Pages, paper will appear at CHI 2026 Poster", "summary": "In blockchain applications, transaction confirmation is often treated as usability friction to be minimized or removed. However, confirmation also marks the boundary between deliberation and irreversible commitment, suggesting it may play a functional role in human decision-making. To investigate this tension, we conducted an experiment using a blockchain-based Connect Four game with two interaction modes differing only in authorization flow: manual wallet confirmation (Confirmation Mode) versus auto-authorized delegation (Frictionless Mode). Although participants preferred Frictionless Mode and perceived better performance (N=109), objective performance was worse without confirmation in a counterbalanced deployment (Wave 2: win rate -11.8%, p=0.044; move quality -0.051, p=0.022). Analysis of canceled submissions suggests confirmation can enable pre-submission self-correction (N=66, p=0.005). These findings suggest that transaction confirmation can function as a cognitively meaningful checkpoint rather than mere usability friction, highlighting a trade-off between interaction smoothness and decision quality in irreversible blockchain interactions."}
{"id": "2602.18962", "categories": ["cs.HC", "cs.AI", "cs.CY", "cs.IR", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.18962", "abs": "https://arxiv.org/abs/2602.18962", "authors": ["Albert Tang", "Yifan Mo", "Jie Li", "Yue Su", "Mengyuan Zhang", "Sander L. Koole", "Koen Hindriks", "Jiahuan Pei"], "title": "NeuroWise: A Multi-Agent LLM \"Glass-Box\" System for Practicing Double-Empathy Communication with Autistic Partners", "comment": "Accepted to ACM CHI 2026", "summary": "The double empathy problem frames communication difficulties between neurodivergent and neurotypical individuals as arising from mutual misunderstanding, yet most interventions focus on autistic individuals. We present NeuroWise, a multi-agent LLM-based coaching system that supports neurotypical users through stress visualization, interpretation of internal experiences, and contextual guidance. In a between-subjects study (N=30), NeuroWise was rated as helpful by all participants and showed a significant condition-time effect on deficit-based attributions (p=0.02): NeuroWise users reduced deficit framing, while baseline users shifted toward blaming autistic \"deficits\" after difficult interactions. NeuroWise users also completed conversations more efficiently (37% fewer turns, p=0.03). These findings suggest that AI-based interpretation can support attributional change by helping users recognize communication challenges as mutual."}
{"id": "2602.18978", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.18978", "abs": "https://arxiv.org/abs/2602.18978", "authors": ["Zhengtai Gou", "Junxiao Long", "Tao Lu", "Jian Zhao", "Yalong Yang"], "title": "Evaluating Replay Techniques for Asynchronous Task Handover in Immersive Analytics", "comment": "Accepted by IEEE VR 26", "summary": "Immersive analytics enables collaborative data analysis in shared virtual spaces. While synchronous collaboration in such environments is well-established, real-world analysis often requires an effective task handover - the transfer of knowledge and analytical context between analysts working asynchronously. Traditional handover methods often rely on static annotations that fail to capture the dynamic problem-solving process and spatial context inherent in immersive workflows. To address this handover challenge, we explore session replay as a comprehensive approach for analysts to re-experience a predecessor's work, facilitating a deeper understanding of both the visual details and the insight formation process. Two phases of studies were conducted to establish design guidelines for such replay systems by investigating the impact of viewing platform (PC vs. VR), perspective (first-person vs. third-person), and navigation control (active vs. passive). Phase 1 identified the optimal replay configurations within each viewing platform, revealing a platform-dependent divergence: PC users favored a guided, first-person perspective for its focused detail, while VR users benefited significantly from the agency afforded by a third-person perspective with active navigation. After refining each condition based on user feedback, including developing a novel hybrid 1PP+3PP format for PC, Phase 2 compared the two optimized systems (PC vs. VR). Our results show that the immersive VR replay led to significantly better task comprehension and workflow reconstruction accuracy, demonstrating the critical role of embodied agency in understanding complex analytical processes."}
{"id": "2602.18992", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.18992", "abs": "https://arxiv.org/abs/2602.18992", "authors": ["Ava Chen", "Megan C. Coram", "Cosima du Pasquier", "Allison M. Okamura"], "title": "Miniaturized Pneumatic Actuator Array for Multipoint Deep Pressure Tactile Stimulation", "comment": "2 pages, 2 figures. 1 supplemental video. Work-in-Progress Paper in IEEE Haptics Symposium 2026", "summary": "Wearable distributed tactile devices aim to provide multipoint touch stimuli, but struggle to provide sufficient forces (> 1 N) at frequencies to invoke deep pressure sensation with minimal encumbrance at small scales. This work presents a method of fabricating arrays of pneumatic actuators from thermoplastic-coated textiles. By routing pneumatic inlets to a common fold line in the fabric, we demonstrate that multiple pneumatic pouch actuators can be formed in a single simple heat-pressing operation that does not require the use of sacrificial blocking layers. The method accommodates a range of actuator diameters and spacing distances, including as compact as 8 mm diameter actuators spaced 1 mm apart, which enables use in fingertip wearable devices. In a blocked force test, these small pneumatic textile actuators exert 2.1 N when pressurized to 230 kPa. With this pair of actuators, we demonstrate an example application in which we invoke both distinct and summative stimuli, suggesting the possibility of titrating just noticeable difference in amplitude with a textile actuator array."}
{"id": "2602.19016", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.19016", "abs": "https://arxiv.org/abs/2602.19016", "authors": ["George X. Wang", "Jiaqian Hu", "Jing Qian"], "title": "Who Has the Final Word? Designing Multi-Agent Collaborative Framework for Professional Translators", "comment": null, "summary": "Recent advances in LLM based translation have led to renewed interest in fully automated systems, yet professional translators remain essential in high stakes domains where decisions about accuracy, terminology, style, and audience cannot be safely automated. Current tools are typically single shot generators or single-agent self-refiners, offering limited support for translator multidimensional decision making process and providing little structured leverage for translator input. We present CHORUS, a human-AI multiagent collaborative translation framework grounded in the Multidimensional Quality Metrics (MQM) framework, which decomposes quality dimensions into specialized agents and integrates their feedback into an iterative refinement loop controlled by the translator. A six-user preliminary study with professional translators found that CHORUS consistently outperforms zero-shot and single-agent baselines, showing that MQM-aligned multi-agent collaboration better supports professional translation workflows than autonomous generation."}
{"id": "2602.19048", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.19048", "abs": "https://arxiv.org/abs/2602.19048", "authors": ["Xizi Wang", "Yue Lyu", "Yalong Yang", "Jian Zhao"], "title": "To Slide or Not to Slide: Exploring Techniques for Comparing Immersive Videos", "comment": "Accepted and to be presented at CHI 2026. 21 pages. DOI: 10.1145/3772318.3790453", "summary": "Immersive videos (IVs) provide 360° environments that create a strong sense of presence and spatial exploration. Unlike traditional videos, IVs distribute information across multiple directions, making comparison cognitively demanding and highly dependent on interaction techniques. With the growing adoption of IVs, effective comparison techniques have become an essential yet underexplored area of research. Inspired by the \"sliding\" concept in 2D media comparison, we integrate two established comparison strategies from the literature--toggle and side-by-side--to support IV comparison with greater flexibility. For an in-depth understanding of different strategies, we adapt and implement five IV comparison techniques across VR and 2D environments: SlideInVR, ToggleInVR, SlideIn2D, ToggleIn2D, and SideBySideIn2D. We then conduct a user study (N=20) to examine how these techniques shape users' perceptions, strategies, and workflows. Our findings provide empirical insights into the strengths and limitations of each technique, underscoring the need to switch between comparison approaches across scenarios. Notably, participants consistently rate SlideInVR and SlideIn2D as the most flexible and favorite methods for IV comparison."}
{"id": "2602.19124", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.19124", "abs": "https://arxiv.org/abs/2602.19124", "authors": ["Sieun Kim", "Yeeun Jo", "Sungmin Na", "Hyunseung Lim", "Eunchae Lee", "Yu Min Choi", "Soohyun Cho", "Hwajung Hong"], "title": "Dark and Bright Side of Participatory Red-Teaming with Targets of Stereotyping for Eliciting Harmful Behaviors from Large Language Models", "comment": "20 pages, 4 tables, 3 figures. Accepted to CHI 2026, April 13-17, 2026, Barcelona, Spain", "summary": "Red-teaming, where adversarial prompts are crafted to expose harmful behaviors and assess risks, offers a dynamic approach to surfacing underlying stereotypical bias in large language models. Because such subtle harms are best recognized by those with lived experience, involving targets of stereotyping as red-teamers is essential. However, critical challenges remain in leveraging their lived experience for red-teaming while safeguarding psychological well-being. We conducted an empirical study of participatory red-teaming with 20 individuals stigmatized by stereotypes against nonprestigious college graduates in South Korea. Through mixed methods analysis, we found participants transformed experienced discrimination into strategic expertise for identifying biases, while facing psychological costs such as stress and negative reflections on group identity. Notably, red-team participation enhanced their sense of agency and empowerment through their role as guardians of the AI ecosystem. We discuss implications for designing participatory red-teaming that prioritizes both the ethical treatment and empowerment of stigmatized groups."}
{"id": "2602.19139", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.19139", "abs": "https://arxiv.org/abs/2602.19139", "authors": ["Boyuan Gu", "Shuaiqi Cheng", "Minghao yu"], "title": "The Neural-Wave Quick Escape Manual 2036: A Field Guide to Adversarial Living in the Era of \"Empathic\" AIoT", "comment": "7 pages, 5 figures", "summary": "As the aging population faces a chronic care deficit, domestic care is increasingly recast as spectral governance. This paper presents a design fiction set in 2036, where the home is governed by Neural-Wave, a camera-free mmWave sensing platform that infers well-being from involuntary micro-motions. Through a set of scenarios, we illustrate how such empathic systems displace autonomy, forcing residents to perform legibility to regain basic freedoms. Our primary contribution is a diegetic artifact: The Neural-Wave Quick Escape Manual. Styled as an illicit guide for the elderly, it details adversarial tactics: structured around protocols to Comply, Degrade, and Refuse, that exploit signal processing vulnerabilities to reclaim domestic privacy. Through this artifact, we argue that in the era of empathic AIoT, privacy requires more than policy opt-outs; it demands adversarial literacy:the capacity to meaningfully obfuscate one's own data traces against an infrastructural jailer that calls itself care."}
{"id": "2602.19232", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.19232", "abs": "https://arxiv.org/abs/2602.19232", "authors": ["Han Li"], "title": "A Comparative Analysis of Peer Support in Forum-based and Chat-based Mental Health Communities: Technical-Structural-Functional Model of Social Support", "comment": "15 pages, 5 figures", "summary": "Online support communities have become vital spaces offering varied forms of support to individuals facing mental health challenges. Despite the proliferation of platforms with distinct technical structures, little is known about how these features shape support dynamics and the socio-technical mechanisms at play. This study introduces a technical-structural-functional model of social support and systematically compares communication network structures and support types in 20 forum-based and 20 chat-based mental health communities. Using supervised machine learning and social network analysis, we find that forum-based communities foster more informational and emotional support, whereas chat-based communities promote greater companionship. These patterns were partially explained by network structure: higher in-degree centralization in forums accounted for the prevalence of informational support, while decentralized reply patterns in chat groups accounted for more companionship. These findings extend the structural-functional model of support to online contexts and provide actionable guidance for designing support communities that align technical structures with users' support needs."}
{"id": "2602.19243", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.19243", "abs": "https://arxiv.org/abs/2602.19243", "authors": ["Jiasheng Li", "Zining Zhang", "Zeyu Yan", "Matthew Wong", "Arnav Mittal", "Ge Gao", "Huaishu Peng"], "title": "As Content and Layout Co-Evolve: TangibleSite for Scaffolding Blind People's Webpage Design through Multimodal Interaction", "comment": null, "summary": "Creating webpages requires generating content and arranging layout while iteratively refining both to achieve a coherent design, a process that can be challenging for blind individuals. To understand how blind designers navigate this process, we conducted two rounds of co-design sessions with blind participants, using design probes to elicit their strategies and support needs. Our findings reveal a preference for content and layout to co-evolve, but this process requires external support through cues that situate local elements within the broader page structure as well as multimodal interactions. Building on these insights, we developed TangibleSite, an accessible web design tool that provides real-time multimodal feedback through tangible, auditory, and speech-based interactions. TangibleSite enables blind individuals to create, edit, and reposition webpage elements while integrating content and layout decisions. A formative evaluation with six blind participants demonstrated that TangibleSite enabled independent webpage creation, supported refinement across content and layout, and reduced barriers to achieving visually consistent designs."}
{"id": "2602.19296", "categories": ["cs.HC", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.19296", "abs": "https://arxiv.org/abs/2602.19296", "authors": ["Kirk Vanacore", "Danielle R Thomas", "Digory Smith", "Bibi Groot", "Justin Reich", "Rene Kizilcec"], "title": "A Causal Framework for Estimating Heterogeneous Effects of On-Demand Tutoring", "comment": null, "summary": "This paper introduces a scalable causal inference framework for estimating the immediate, session-level effects of on-demand human tutoring embedded within adaptive learning systems. Because students seek assistance at moments of difficulty, conventional evaluation is confounded by self-selection and time-varying knowledge states. We address these challenges by integrating principled analytic sample construction with Deep Knowledge Tracing (DKT) to estimate latent mastery, followed by doubly robust estimation using Causal Forests. Applying this framework to over 5,000 middle-school mathematics tutoring sessions, we find that requesting human tutoring increases next-problem correctness by approximately 4 percentage points and accuracy on the subsequent skill encountered by approximately 3 percentage points, suggesting that the effects of tutoring have proximal transfer across knowledge components. This effect is robust to various forms of model specification and potential unmeasured confounders. Notably, these effects exhibit significant heterogeneity across sessions and students, with session-level effect estimates ranging from $-20.25pp$ to $+19.91pp$. Our follow-up analyses suggest that typical behavioral indicators, such as student talk time, do not consistently correlate with high-impact sessions. Furthermore, treatment effects are larger for students with lower prior mastery and slightly smaller for low-SES students. This framework offers a rigorous, practical template for the evaluation and continuous improvement of on-demand human tutoring, with direct applications for emerging AI tutoring systems."}
{"id": "2602.19303", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.19303", "abs": "https://arxiv.org/abs/2602.19303", "authors": ["Kirk Vanacore", "Ryan S. Baker", "Avery H. Closser", "Jeremy Roschelle"], "title": "The Path to Conversational AI Tutors: Integrating Tutoring Best Practices and Targeted Technologies to Produce Scalable AI Agents", "comment": null, "summary": "The emergence of generative AI has accelerated the development of conversational tutoring systems that interact with students through natural language dialogue. Unlike prior intelligent tutoring systems (ITS), which largely function as adaptive and interactive problem sets with feedback and hints, conversational tutors hold the potential to simulate high-quality human tutoring by engaging with students' thoughts, questions, and misconceptions in real time. While some previous ITS, such as AutoTutor, could respond conversationally, they were expensive to author and lacked a full range of conversational ability. Generative AI has changed the capacity of ITS to engage conversationally. However, realizing the full potential of conversational tutors requires careful consideration of what research on human tutoring and ITS has already established, while also unpacking what new research will be needed. This paper synthesizes tenets of successful human tutoring, lessons learned from legacy ITS, and emerging work on conversational AI tutors. We use a keep, change, center, study framework for guiding the design of conversational tutoring. We argue that systems should keep proven methods from prior ITS, such as knowledge tracing and affect detection; change how tutoring is delivered by leveraging generative AI for dynamic content generation and dialogic scaffolding; and center opportunities for meaning-making, student agency, and granular diagnosis of reasoning. Finally, we identify areas requiring further study, including efficacy testing, student experience, and integration with human instruction. By synthesizing insights from human tutoring, legacy ITS, and emerging generative AI technologies, this paper outlines a research agenda for developing conversational tutors that are scalable, pedagogically effective, and responsive to the social and motivational dimensions of learning."}
{"id": "2602.19352", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.19352", "abs": "https://arxiv.org/abs/2602.19352", "authors": ["Varun Shiri", "Charles Liu", "Keyu Yao", "Jin L. C. Guo", "Jinghui Cheng"], "title": "Beyond Privacy Labels: How Users Perceive Different Information Sources for Understanding App's Privacy Practices", "comment": "5 pages, 1 figure, CHI EA 2026", "summary": "Despite having growing awareness and concerns about privacy, technology users are often insufficiently informed of the data practices of various digital products to protect themselves. Privacy policies and privacy labels, as two conventional ways of communicating data practices, are each criticized for important limitations -- one being lengthy and filled with legal jargon, and the other oversimplified and inaccurate -- causing users significant difficulty in understanding the privacy practices of the products and assessing their impact. To mitigate those issues, we explore ways to enhance privacy labels with the relevant content in complementary sources, including privacy policy, app reviews, and community-curated privacy assessments. Our user study results indicate that perceived usefulness and trust on those information sources are personal and influenced by past experience. Our work highlights the importance of considering various information needs for privacy practice and consolidating different sources for more useful privacy solutions."}
{"id": "2602.19354", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.19354", "abs": "https://arxiv.org/abs/2602.19354", "authors": ["Eun Jeong Kang", "Fengyang Lin", "Angel Hsing-Chi Hwang"], "title": "Policy or Community?: Supporting Individual Model Creators' Open Model Development in Model Marketplaces", "comment": null, "summary": "Lightweight fine-tuning techniques and the rise of 'open' AI model marketplaces have enabled individuals to easily build and release generative models. Yet, this accessibility also raises risks, including the production of harmful and infringing content. While platforms offer policies and responsible AI tools, their effectiveness may be limited, as creators engage with partially open models that vary widely in openness and transparency. To understand how platform governance can better support responsible practices, we conducted semi-structured interviews with 19 individual model creators. We identified three regulatory needs shaped by creators' workflows: reducing downstream harms, recognizing creators' contributions and originality, and securing model ownership. Creators also repurpose RAI tools primarily for self-protection and visibility, and their sense of responsibility is deeply shaped by community norms rather than formal policies. We argue that platforms' governance decisions must consider how policy interventions shape the practices and motivations of individual creators."}
{"id": "2602.19401", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.19401", "abs": "https://arxiv.org/abs/2602.19401", "authors": ["Grace Barkhuff"], "title": "Reassurance Robots: OCD in the Age of Generative AI", "comment": "8 pages, 1 figure, conditionally accepted for publication in CHI EA '26: Extended Abstracts of the ACM CHI Conference on Human Factors in Computing Systems April 2026", "summary": "Obsessive Compulsive Disorder (OCD) is a mental health disorder characterized by distressing repetitive patterns of thought, referred to as obsessions, and behaviors aimed to reduce the distress, referred to as compulsions. The explosion of artificial intelligence (AI) into the modern zeitgeist through the introduction of generative AI (GenAI) systems such as ChatGPT has led to novel obsessions and compulsions involving AI in individuals with OCD. Through an exploratory qualitative analysis of 100 Reddit posts related to AI on a popular subreddit for OCD, I examine the ways AI is impacting the presentation of OCD, including novel examples of AI-based obsessions and compulsions. I argue that GenAI in its current form harms individuals with OCD by becoming \"Reassurance Robots,\" and that future designs of GenAI must take OCD into account."}
{"id": "2602.19422", "categories": ["cs.HC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.19422", "abs": "https://arxiv.org/abs/2602.19422", "authors": ["Lingyun Chen", "Qing Xiao", "Zitao Zhang", "Eli Blevis", "Selma Šabanović"], "title": "Positioning Modular Co-Design in Future HRI Design Research", "comment": "4 pages, 1 figure, accepted by 3rd Workshop on Designerly HRI at HRI'26", "summary": "Design-oriented HRI is increasingly interested in robots as long-term companions, yet many designs still assume a fixed form and a stable set of functions. We present an ongoing design research program that treats modularity as a designerly medium - a way to make long-term human-robot relationships discussable and material through co-design. Across a series of lifespan-oriented co-design activities, participants repeatedly reconfigured the same robot for different life stages, using modular parts to express changing needs, values, and roles. From these outcomes, we articulate PAS (Personalization-Adaptability-Sustainability) as a human-centered lens on how people enact modularity in practice: configuring for self-expression, adapting across transitions, and sustaining robots through repair, reuse, and continuity. We then sketch next steps toward a fabrication-aware, community-extensible modular platform and propose evaluation criteria for designerly HRI work that prioritize expressive adequacy, lifespan plausibility, repairability-in-use, and responsible stewardship - not only usability or performance."}
{"id": "2602.19463", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.19463", "abs": "https://arxiv.org/abs/2602.19463", "authors": ["Emma Jiren Wang", "Siying Hu", "Zhicong Lu"], "title": "PuppetChat: Fostering Intimate Communication through Bidirectional Actions and Micronarratives", "comment": "19 pages, 8 figures; Accepted by ACM CHI 2026. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems (CHI'24)", "summary": "As a primary channel for sustaining modern intimate relationships, instant messaging facilitates frequent connection across distances. However, today's tools often dilute care; they favor single tap reactions and vague emojis that do not support two way action responses, do not preserve the feeling that the exchange keeps going without breaking, and are weakly tied to who we are and what we share. To address this challenge, we present PuppetChat, a dyadic messaging prototype that restores this expressive depth through embodied interaction. PuppetChat uses a reciprocity aware recommender to encourage responsive actions and generates personalized micronarratives from user stories to ground interactions in personal history. Our 10-day field study with 11 dyads of close partners or friends revealed that this approach enhanced social presence, supported more expressive self disclosure, and sustained continuity and shared memories."}
{"id": "2602.19507", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.19507", "abs": "https://arxiv.org/abs/2602.19507", "authors": ["David Fraile Navarro", "Mor Peleg"], "title": "Conversational AI for Automated Patient Questionnaire Completion: Development Insights and Design Principles", "comment": "13 pages", "summary": "Collecting patient-reported outcome measures (PROMs) is essential for clinical care and research, yet traditional form-based approaches are often tedious for patients and burdensome for clinicians. We developed a generative AI conversational agent(CA) using GPT-5 to collect back pain data according to the NIH Task Force's Recommended Minimal Dataset. Unlike prior CAs that ask questions one-by-one, our CA engages users in topic-based conversations, allowing multiple data items to be captured in a single exchange. Through iterative development and pilot testing with clinicians and a consumer panel, we identified key design principles for health data collection CAs. These principles extend established clinical decision support design guidelines to conversational interfaces, addressing: flexibility of interaction style, personality calibration, data quality assurance through confidence visualization, patient safety constraints, and interoperability requirements. We present our prompt design methodology and discuss challenges encountered, including managing conversation length, handling ambiguous responses, and adapting to LLM version changes. Our design principles provide a practical framework for developers creating conversational agents for patient questionnaire completion. The CA is available at https://chatgpt.com/g/g-68f4869548f48191af0544f110ee91c6-backpain-data-collection-assistant (requires ChatGPT registration and subscription for unlimited use)."}
{"id": "2602.19554", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.19554", "abs": "https://arxiv.org/abs/2602.19554", "authors": ["Daniel A. Muñoz"], "title": "Sound-first immersive training for blind and low-vision learners: A simulation flow for safe, standardized orientation, mobility, and daily living practice", "comment": null, "summary": "Orientation and mobility (O&M) instruction for blind and low-vision learners is effective but difficult to standardize and repeat at scale due to the reliance on instructor availability, physical mock-ups, and variable real-world outdoor conditions. This Technical Note presents a sound-first immersive training flow that uses spatial audio and sonification as the primary channel for action and feedback in pre-street O&M and daily-living practice. The approach specifies parameterized scenario templates (e.g., signalized street crossing, public transport boarding, and kitchen tasks), a compact and consistent cue vocabulary with clear spectral placement and timing to mitigate masking, and a lightweight safety protocol enabling graded exposure, content warnings, seated starts, opt-outs, and structured debriefs. The system assumes a head-mounted device with high-quality binaural rendering and head tracking; 3D scene geometry is used as an invisible scaffold to anchor sources, trigger events, define risk/guidance volumes, and govern physically plausible motion without visuals. Session difficulty is shaped via cue density, event tempo, and task complexity while preserving cue consistency to promote transfer across scenarios. The specification aims to enable safe repetition, reduce instructor burden, and support clearer standards across rehabilitation centers, aligning with evidence that audio-first interaction is essential for blind and visually impaired users and addressing gaps in HRTF personalization, evaluation standards, and accessibility integration. Although no behavioral outcomes are reported here, this implementable flow consolidates auditory science with center-ready design, offering a pragmatic foundation for standardized evaluation and future comparative studies."}
{"id": "2602.19560", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.19560", "abs": "https://arxiv.org/abs/2602.19560", "authors": ["Kynnedy Simone Smith", "Lydia B. Chilton", "Danielle Bragg"], "title": "Identifying, Explaining, and Correcting Ableist Language with AI", "comment": "17 pages, 6 figures, Accepted for publication in CHI'26, Barcelona, Spain, April 13 - 17, 2026; CHI '26: ACM CHI Conference on Human Factors in Computing Systems", "summary": "Ableist language perpetuates harmful stereotypes and exclusion, yet its nuanced nature makes it difficult to recognize and address. Artificial intelligence could serve as a powerful ally in the fight against ableist language, offering tools that detect and suggest alternatives to biased terms. This two-part study investigates the potential of large language models (LLMs), specifically ChatGPT, to rectify ableist language and educate users about inclusive communication. We compared GPT-4o generations with crowdsourced annotations from trained disability community members, then invited disabled participants to evaluate both. Participants reported equal agreement with human and AI annotations but significantly preferred the AI, citing its narrative consistency and accessible style. At the same time, they valued the emotional depth and cultural grounding of human annotations. These findings highlight the promise and limits of LLMs in handling culturally sensitive content. Our contributions include a dataset of nuanced ableism annotations and design considerations for inclusive writing tools."}
{"id": "2602.19629", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.19629", "abs": "https://arxiv.org/abs/2602.19629", "authors": ["Tatia Codreanu"], "title": "Cooperation After the Algorithm: Designing Human-AI Coexistence Beyond the Illusion of Collaboration", "comment": "11 pages, 2 tables", "summary": "Generative artificial intelligence systems increasingly participate in research, law, education, media, and governance. Their fluent and adaptive outputs create an experience of collaboration. However, these systems do not bear responsibility, incur liability, or share stakes in downstream consequences. This structural asymmetry has already produced sanctions, professional errors, and governance failures in high-stakes contexts We argue that stable human-AI coexistence is an institutional achievement that depends on governance infrastructure capable of distributing residual risk. Drawing on institutional analysis and evolutionary cooperation theory, we introduce a formal inequality that specifies when reliance on AI yields positive expected cooperative value. The model makes explicit how governance conditions, system policy, and accountability regimes jointly determine whether cooperation is rational or structurally defective. From this formalization we derive a cooperation ecology framework with six design principles: reciprocity contracts, visible trust infrastructure, conditional cooperation modes, defection-mitigation mechanisms, narrative literacy against authority theatre, and an Earth-first sustainability constraint. We operationalize the framework through three policy artefacts: a Human-AI Cooperation Charter, a Defection Risk Register, and a Cooperation Readiness Audit. Together, these elements shift the unit of analysis from the user-AI dyad to the institutional environment that shapes incentives, signals, accountability, and repair. The paper provides a theoretical foundation and practical toolkit for designing human-AI systems that can sustain accountable, trustworthy cooperation over time."}
{"id": "2602.19690", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.19690", "abs": "https://arxiv.org/abs/2602.19690", "authors": ["Qile Wang", "Prerana Khatiwada", "Avinash Chouhan", "Ashrey Mahesh", "Joy Mwaria", "Duy Duc Tran", "Kenneth E. Barner", "Matthew Louis Mauriello"], "title": "\"The explanation makes sense\": An Empirical Study on LLM Performance in News Classification and its Influence on Judgment in Human-AI Collaborative Annotation", "comment": null, "summary": "The spread of media bias is a significant concern as political discourse shapes beliefs and opinions. Addressing this challenge computationally requires improved methods for interpreting news. While large language models (LLMs) can scale classification tasks, concerns remain about their trustworthiness. To advance human-AI collaboration, we investigate the feasibility of using LLMs to classify U.S. news by political ideology and examine their effect on user decision-making. We first compared GPT models with prompt engineering to state-of-the-art supervised machine learning on a 34k public dataset. We then collected 17k news articles and tested GPT-4 predictions with brief and detailed explanations. In a between-subjects study (N=124), we evaluated how LLM-generated explanations influence human annotation, judgment, and confidence. Results show that AI assistance significantly increases confidence ($p<.001$), with detailed explanations more persuasive and more likely to alter decisions. We highlight recommendations for AI explanations through thematic analysis and provide our dataset for further research."}
{"id": "2602.19695", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.19695", "abs": "https://arxiv.org/abs/2602.19695", "authors": ["William Seymour", "Martin J. Kraemer"], "title": "Shifting Engagement With Cybersecurity: How People Discover and Share Cybersecurity Content at Work and at Home", "comment": "To appear in the extended abstracts of the 2026 ACM CHI Conference on Human Factors in Computing Systems", "summary": "Cybersecurity awareness is shaped by a wide range of professional and personal experiences, including information and training at work and the sharing of news and other content at home. In order to explore how people discover cybersecurity content and the effect that participation in workplace training may have on this we present an online study of 1200 participants from the UK, US, France, and Germany. Those undertaking cybersecurity training at work showed reduced intention to share information at home, shifting the focus towards the workplace. They were also more likely to recall cybersecurity information shared by their employer than from any other source, which in turn correlated with content type and distribution channel. We critically reflect on this shift, highlighting opportunities to improve cybersecurity information sharing at work and at home."}
{"id": "2602.19714", "categories": ["cs.HC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.19714", "abs": "https://arxiv.org/abs/2602.19714", "authors": ["Joel Bucher", "Lahari Goswami", "Sverrir Thorgeirsson", "April Yi Wang"], "title": "Git Takes Two: Split-View Awareness for Collaborative Learning of Distributed Workflows in Git", "comment": "First two authors contributed equally", "summary": "Git is widely used for collaborative software development, but it can be challenging for newcomers. While most learning tools focus on individual workflows, Git is inherently collaborative. We present GitAcademy, a browser-based learning platform that embeds a full Git environment with a split-view collaborative mode: learners work on their own local repositories connected to a shared remote repository, while simultaneously seeing their partner's actions mirrored in real time. This design is not intended for everyday software development, but rather as a training simulator to build awareness of distributed states, coordination, and collaborative troubleshooting. In a within-subjects study with 13 pairs of learners, we found that the split-view interface enhanced social presence, supported peer teaching, and was consistently preferred over a single-view baseline, even though performance gains were mixed. We further discuss how split-view awareness can serve as a training-only scaffold for collaborative learning of Git and other distributed technical systems."}
{"id": "2602.19745", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.19745", "abs": "https://arxiv.org/abs/2602.19745", "authors": ["Jules Wulms", "Wouter Meulemans", "Bettina Speckmann"], "title": "Unfolding Ordered Matrices into BioFabric Motifs", "comment": null, "summary": "BioFabrics were introduced by Longabaugh in 2012 as a way to draw large graphs in a clear and uncluttered manner. The visual quality of BioFabrics crucially depends on the order of vertices and edges, which can be chosen independently. Effective orders can expose salient patterns, which in turn can be summarized by motifs, allowing users to take in complex networks at-a-glance. However, so far there is no efficient layout algorithm which automatically recognizes patterns and delivers both a vertex and an edge ordering that allows these patterns to be expressed as motifs. In this paper we show how to use well-ordered matrices as a tool to efficiently find good vertex and edge orders for BioFabrics. Specifically, we order the adjacency matrix of the input graph using Moran's $I$ and detect (noisy) patterns with our recent algorithm. In this note we show how to \"unfold\" the ordered matrix and its patterns into a high-quality BioFabric. Our pipelines easily handles graphs with up to 250 vertices."}
{"id": "2602.19809", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.19809", "abs": "https://arxiv.org/abs/2602.19809", "authors": ["Sebastian Hubenschmid", "Arvind Srinivasan", "Niklas Elmqvist", "Dieter Schmalstieg", "Michael Sedlmair"], "title": "Ambient Analytics: Calm Technology for Immersive Visualization and Sensemaking", "comment": "Accepted at \"Visualization Viewpoints\" in IEEE Computer Graphics and Applications", "summary": "Augmented reality has great potential for embedding data visualizations in the world around the user. While this can enhance users' understanding of their surroundings, it also bears the risk of overwhelming their senses with a barrage of information. In contrast, calm technologies aim to place information in the user's attentional periphery, minimizing cognitive load instead of demanding focused engagement. In this column, we explore how visualizations can be harmoniously integrated into our everyday life through augmented reality, progressing from visual analytics to ambient analytics."}
{"id": "2602.19853", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.19853", "abs": "https://arxiv.org/abs/2602.19853", "authors": ["Leni Yang", "Aymeric Ferron", "Yvonne Jansen", "Pierre Dragicevic"], "title": "Progressive Value Reading: The Use of Motion to Gradually Examine Data Involving Large Magnitudes", "comment": null, "summary": "People often struggle to interpret data with extremely large or small values, or ranges spanning multiple orders of magnitude. While traditional approaches, such as log scales and multiscale visualizations, can help, we explore in this article a different approach used in some emerging designs: the use of motion to let viewers gradually experience magnitude -- for example, interactive graphics that require long scrolling or street paintings stretching hundreds of meters. This approach typically demands substantial time and sustained interaction, translating differences in magnitude into a visceral sense of duration and effort. Although largely underexplored, this design strategy offers new opportunities. We introduce the term progressive value reading to refer to the use of motion to progressively examine an information object that encodes a value, where the amount of motion reflects the value. We compiled a corpus of 55 real-life and hypothetical visualization examples that allow, encourage, or require progressive value reading. From this corpus, we derived a design space of ten design dimensions, providing a shared vocabulary, inspiration for novel techniques, and a foundation for empirical evaluation. An online corpus is also available for exploration."}
{"id": "2602.19966", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.19966", "abs": "https://arxiv.org/abs/2602.19966", "authors": ["Joydeep Chandra", "Satyam Kumar Navneet", "Yong Zhang"], "title": "GazeFlow: Personalized Ambient Soundscape Generation for Passive Strabismus Self-Monitoring", "comment": null, "summary": "Strabismus affects 2-4% of the population, yet individuals recovering from corrective surgery lack accessible tools for monitoring eye alignment. Dichoptic therapies require active engagement & clinical supervision, limiting their adoption for passive self-awareness. We present GazeFlow, a browser-based self-monitoring system that uses a personalized temporal autoencoder to detect eye drift patterns from webcam-based gaze tracking & provides ambient audio feedback. Unlike alert-based systems, GazeFlow operates according to calm computing principles, morphing musical parameters in proportion to drift severity while remaining in peripheral awareness. We address the challenges of inter-individual variability & domain transfer (1000Hz research to 30Hz webcam) by introducing Binocular Temporal-Frequency Disentanglement (BTFD), Contrastive Biometric Pre-training (CBP), & Gaze-MAML. We validate our approach on the GazeBase dataset (N=50) achieving F1=0.84 for drift detection, & conduct a preliminary user study (N=6) with participants having intermittent strabismus. Participants reported increased awareness of their eye behaviour (M=5.8/7) & preference for ambient feedback over alerts (M=6.2/7). We discuss the system's potential for self-awareness applications & outline directions for clinical validation."}
{"id": "2602.20014", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.20014", "abs": "https://arxiv.org/abs/2602.20014", "authors": ["Olga Viberg", "Mutlu Cukurova", "Rene F. Kizilcec", "Simon Buckingham Shum", "Dorottya Demszky", "Dragan Gašević", "Thorben Jansen", "Ioana Jivet", "Jelena Jovanovic", "Jennifer Meyer", "Kou Murayama", "Zach Pardos", "Chris Piech", "Nikol Rummel", "Naomi E. Winstone"], "title": "Protecting and Promoting Human Agency in Education in the Age of Artificial Intelligence", "comment": "O.V., M.C., and R.F.K. organized the meeting and wrote the first version of the report. All authors contributed to the revision of the manuscript, and read and approved the final version", "summary": "Human agency is crucial in education and increasingly challenged by the use of generative AI. This meeting report synthesizes interdisciplinary insights and conceptualizes four aspects that delineate human agency: human oversight, AI-human complementarity, AI competencies, and relational emergence. We explore practical dilemmas for protecting and promoting agency, focusing on normative constraints, transparency, and cognitive offloading, and highlight key tensions and implications to inform ethical and effective AI integration in education."}
{"id": "2602.20022", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.20022", "abs": "https://arxiv.org/abs/2602.20022", "authors": ["Poorna Talkad Sukumar", "Maurizio Porfiri", "Oded Nov"], "title": "Studying the Separability of Visual Channel Pairs in Symbol Maps", "comment": null, "summary": "Visualizations often encode multivariate data by mapping attributes to distinct visual channels such as color, size, or shape. The effectiveness of these encodings depends on separability--the extent to which channels can be perceived independently. Yet systematic evidence for separability, especially in map-based contexts, is lacking. We present a crowdsourced experiment that evaluates the separability of four channel pairs--color (ordered) x shape, color (ordered) x size, size x shape, and size x orientation--in the context of bivariate symbol maps. Both accuracy and speed analyses show that color x shape is the most separable and size x orientation the least separable, while size x color and size x shape do not differ. Separability also proved asymmetric--performance depended on which channel encoded the task-relevant variable, with color and shape outperforming size, and square shape especially difficult to discriminate. Our findings advance the empirical understanding of visual separability, with implications for multivariate map design."}
