{"id": "2602.06047", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06047", "abs": "https://arxiv.org/abs/2602.06047", "authors": ["Sankar B", "Amogh A S", "Sandhya Baranwal", "Dibakar Sen"], "title": "Git for Sketches: An Intelligent Tracking System for Capturing Design Evolution", "comment": "49 pages, 25 figures", "summary": "During product conceptualization, capturing the non-linear history and cognitive intent is crucial. Traditional sketching tools often lose this context. We introduce DIMES (Design Idea Management and Evolution capture System), a web-based environment featuring sGIT (SketchGit), a custom visual version control architecture, and Generative AI. sGIT includes AEGIS, a module using hybrid Deep Learning and Machine Learning models to classify six stroke types. The system maps Git primitives to design actions, enabling implicit branching and multi-modal commits (stroke data + voice intent). In a comparative study, experts using DIMES demonstrated a 160% increase in breadth of concept exploration. Generative AI modules generated narrative summaries that enhanced knowledge transfer; novices achieved higher replication fidelity (Neural Transparency-based Cosine Similarity: 0.97 vs. 0.73) compared to manual summaries. AI-generated renderings also received higher user acceptance (Purchase Likelihood: 4.2 vs 3.1). This work demonstrates that intelligent version control bridges creative action and cognitive documentation, offering a new paradigm for design education.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.06134", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06134", "abs": "https://arxiv.org/abs/2602.06134", "authors": ["Zhihan Jiang", "Qianhui Chen", "Chu Zhang", "Yanheng Li", "Ray LC"], "title": "Hear You in Silence: Designing for Active Listening in Human Interaction with Conversational Agents Using Context-Aware Pacing", "comment": "29 pages, 10 figures. Conditionally Accepted to CHI '26", "summary": "In human conversation, empathic dialogue requires nuanced temporal cues indicating whether the conversational partner is paying attention. This type of \"active listening\" is overlooked in the design of Conversational Agents (CAs), which use the same pacing for one conversation. To model the temporal cues in human conversation, we need CAs that dynamically adjust response pacing according to user input. We qualitatively analyzed ten cases of active listening to distill five context-aware pacing strategies: Reflective Silence, Facilitative Silence, Empathic Silence, Holding Space, and Immediate Response. In a between-subjects study (N=50) with two conversational scenarios (relationship and career-support), the context-aware agent scored higher than static-pacing control on perceived human-likeness, smoothness, and interactivity, supporting deeper self-disclosure and higher engagement. In the career support scenario, the CA yielded higher perceived listening quality and affective trust. This work shows how insights from human conversation like context-aware pacing can empower the design of more empathic human-AI communication.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.06735", "categories": ["cs.GR", "astro-ph.EP", "astro-ph.IM"], "pdf": "https://arxiv.org/pdf/2602.06735", "abs": "https://arxiv.org/abs/2602.06735", "authors": ["Hanno Rein"], "title": "Real time, cross platform visualizations with zero dependencies for the N-body package REBOUND", "comment": "9 pages, 2 figures. Published in JoVI. Interactive article available at https://journals.aau.dk/index.php/jovi/article/view/8312/8847", "summary": "Visualizations have become an indispensable part of the scientific process. A vibrant ecosystem of visualization tools exists, catering to a wide variety of different needs. Real-time visualizations of numerical simulations offer scientists immediate feedback about the status of their simulations and can also be valuable educational and outreach tools. Developing a visualization tool with support for different operating systems, CPU/GPU architectures, and programming languages can be a challenge. It is common to use one or more graphics or UI libraries to act as abstraction layers and hide the underlying complexity. Whereas external libraries greatly simplify the initial programming effort, we argue that relying on them introduces new dependencies and problems, such as a higher entry barriers for new developers and users, and uncertainty regarding long-term support. In this paper we present a new approach for real time visualizations which we have implemented for the N-body package REBOUND. We propose to use a web browser to handle GPU accelerated rendering. This enables us to offer 3D, interactive visualizations on all major operating systems. What makes our new approach unique is that we achieve this without the need for any external libraries. We utilize WebAssembly to reuse existing OpenGL visualization code. Using communication via HTTP and a custom built-in web server, we are able to provide both local and remote real time visualizations. In addition to the browser based real time visualization, our approach offers other additional operating modes, including simulations running entirely within the browser, visualizations within jupyter notebooks, and traditional standalone visualizations using OpenGL. We focus on the implementation in REBOUND but the concepts and ideas discussed can be applied to many other areas in need of scientific and non-scientific real time visualizations.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.06081", "categories": ["cs.MA", "cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2602.06081", "abs": "https://arxiv.org/abs/2602.06081", "authors": ["Nunzio Lore", "Babak Heydari"], "title": "Communication Enhances LLMs' Stability in Strategic Thinking", "comment": "15 pages, 1 figure, 6 tables", "summary": "Large Language Models (LLMs) often exhibit pronounced context-dependent variability that undermines predictable multi-agent behavior in tasks requiring strategic thinking. Focusing on models that range from 7 to 9 billion parameters in size engaged in a ten-round repeated Prisoner's Dilemma, we evaluate whether short, costless pre-play messages emulating the cheap-talk paradigm affect strategic stability. Our analysis uses simulation-level bootstrap resampling and nonparametric inference to compare cooperation trajectories fitted with LOWESS regression across both the messaging and the no-messaging condition. We demonstrate consistent reductions in trajectory noise across a majority of the model-context pairings being studied. The stabilizing effect persists across multiple prompt variants and decoding regimes, though its magnitude depends on model choice and contextual framing, with models displaying higher baseline volatility gaining the most. While communication rarely produces harmful instability, we document a few context-specific exceptions and identify the limited domains in which communication harms stability. These findings position cheap-talk style communication as a low-cost, practical tool for improving the predictability and reliability of strategic behavior in multi-agent LLM systems.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.06164", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.06164", "abs": "https://arxiv.org/abs/2602.06164", "authors": ["Jinghui Hu", "Ludwig Sidenmark", "Hock Siang Lee", "Hans Gellersen"], "title": "The Eye-Head Mover Spectrum: Modelling Individual and Population Head Movement Tendencies in Virtual Reality", "comment": null, "summary": "People differ in how much they move their head versus their eyes when shifting gaze, yet such tendencies remain largely unexplored in HCI. We introduce head movement tendencies as a fundamental dimension of individual difference in VR and provide a quantitative account of their population-level distribution. Using a 360\u00b0 video free-viewing dataset (N=87), we model head contributions to gaze shifts with a hinge-based parametric function, revealing a spectrum of strategies from eye-movers to head-movers. We then conduct a user study (N=28) combining 360\u00b0 video viewing with a short controlled task using gaze targets. While parameter values differ across tasks, individuals show partial alignment in their relative positions within the population, indicating that tendencies are meaningful but shaped by context. Our findings establish head movement tendencies as an important concept for VR and highlight implications for adaptive systems such as foveated rendering, viewport alignment, and multi-user experience design.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.06177", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.06177", "abs": "https://arxiv.org/abs/2602.06177", "authors": ["Sujay Shalawadi", "Katrina Hv\u00edtklett", "Anna Stentoft Ries", "Aisho Mohamed Ali", "Florian Echtler"], "title": "DataCrumb: A Physical Probe for Reflections on Background Web Tracking", "comment": null, "summary": "Cookie banners and privacy settings attempt to give users a sense of control over how their personal data is collected and used, but background tracking of personal information often continues unnoticed. To explore how such invisible data collection might be made more perceptible, we present DataCrumb, a physical probe that reacts in real-time to data tracking with visual and auditory feedback. Using a research-through-design approach, we deployed the artifact in three households and studied participants' responses. Instead of providing details about what data was being tracked, the artifact introduced subtle disruptions that made background data flows harder to ignore. Participants described new forms of awareness, contradiction, and fatigue. Our findings show how sensory feedback can support reflection by drawing attention to tracking data flows that are usually hidden. We argue for designing systems that foster awareness and interpretation, especially when the users' control and understanding are limited.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.06599", "categories": ["cs.MA", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.06599", "abs": "https://arxiv.org/abs/2602.06599", "authors": ["Ariyan Bighashdel", "Thiago D. Sim\u00e3o", "Frans A. Oliehoek"], "title": "Sample-Efficient Policy Space Response Oracles with Joint Experience Best Response", "comment": "Accepted at the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026)", "summary": "Multi-agent reinforcement learning (MARL) offers a scalable alternative to exact game-theoretic analysis but suffers from non-stationarity and the need to maintain diverse populations of strategies that capture non-transitive interactions. Policy Space Response Oracles (PSRO) address these issues by iteratively expanding a restricted game with approximate best responses (BRs), yet per-agent BR training makes it prohibitively expensive in many-agent or simulator-expensive settings. We introduce Joint Experience Best Response (JBR), a drop-in modification to PSRO that collects trajectories once under the current meta-strategy profile and reuses this joint dataset to compute BRs for all agents simultaneously. This amortizes environment interaction and improves the sample efficiency of best-response computation. Because JBR converts BR computation into an offline RL problem, we propose three remedies for distribution-shift bias: (i) Conservative JBR with safe policy improvement, (ii) Exploration-Augmented JBR that perturbs data collection and admits theoretical guarantees, and (iii) Hybrid BR that interleaves JBR with periodic independent BR updates. Across benchmark multi-agent environments, Exploration-Augmented JBR achieves the best accuracy-efficiency trade-off, while Hybrid BR attains near-PSRO performance at a fraction of the sample cost. Overall, JBR makes PSRO substantially more practical for large-scale strategic learning while preserving equilibrium robustness.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.06190", "categories": ["cs.HC", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.06190", "abs": "https://arxiv.org/abs/2602.06190", "authors": ["Uwe Peters", "Andrea Bertazzoli", "Jasmine M. DeJesus", "Gisela J. van der Velden", "Benjamin Chin-Yee"], "title": "Generics in science communication: Misaligned interpretations across laypeople, scientists, and large language models", "comment": null, "summary": "Scientists often use generics, that is, unquantified statements about whole categories of people or phenomena, when communicating research findings (e.g., \"statins reduce cardiovascular events\"). Large language models (LLMs), such as ChatGPT, frequently adopt the same style when summarizing scientific texts. However, generics can prompt overgeneralizations, especially when they are interpreted differently across audiences. In a study comparing laypeople, scientists, and two leading LLMs (ChatGPT-5 and DeepSeek), we found systematic differences in interpretation of generics. Compared to most scientists, laypeople judged scientific generics as more generalizable and credible, while LLMs rated them even higher. These mismatches highlight significant risks for science communication. Scientists may use generics and incorrectly assume laypeople share their interpretation, while LLMs may systematically overgeneralize scientific findings when summarizing research. Our findings underscore the need for greater attention to language choices in both human and LLM-mediated science communication.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.06194", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.06194", "abs": "https://arxiv.org/abs/2602.06194", "authors": ["Bo Shui", "Xinran Zhu"], "title": "Knowledge Synthesis Graph: An LLM-Based Approach for Modeling Student Collaborative Discourse", "comment": null, "summary": "Asynchronous, text-based discourse-such as students' posts in discussion forums-is widely used to support collaborative learning. However, the distributed and evolving nature of such discourse often makes it difficult to see how ideas connect, develop, and build on one another over time. As a result, learners may struggle to recognize relationships among ideas-a process that is critical for idea advancement in productive collaborative discourse. To address this challenge, we explore how large language models (LLMs) can provide representational guidance by modeling student discourse as a Knowledge Synthesis Graph (KSG). The KSG identifies ideas from student discourse and visualizes their epistemic relationships, externalizing the current state of collaborative knowledge in a form that can support further inquiry and idea advancement. In this study, we present the design of the KSG and evaluate the LLM-based approach for constructing KSGs from authentic student discourse data. Through multi-round human-expert coding and prompt iteration, our results demonstrate the feasibility of using our approach to construct reliable KSGs across different models. This work provides a technical foundation for modeling collaborative discourse with LLMs and offers pedagogical implications for augmenting complex knowledge work in collaborative learning environments.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.06197", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06197", "abs": "https://arxiv.org/abs/2602.06197", "authors": ["Taewook Kim", "Matthew K. Hong", "Yan-Ying Chen", "Jonathan Q. Li", "Monica P Van", "Shabnam Hakimi", "Matthew Kay", "Matthew Klenk"], "title": "Personagram: Bridging Personas and Product Design for Creative Ideation with Multimodal LLMs", "comment": "22 pages, 10 figures, 4 tables", "summary": "Product designers often begin their design process with handcrafted personas. While personas are intended to ground design decisions in consumer preferences, they often fall short in practice by remaining abstract, expensive to produce, and difficult to translate into actionable design features. As a result, personas risk serving as static reference points rather than tools that actively shape design outcomes. To address these challenges, we built Personagram, an interactive system powered by multimodal large language models (MLLMs) that helps designers explore detailed census-based personas, extract product features inferred from persona attributes, and recombine them for specific customer segments. In a study with 12 professional designers, we show that Personagram facilitates more actionable ideation workflows by structuring multimodal thinking from persona attributes to product design features, achieving higher engagement with personas, perceived transparency, and satisfaction compared to a chat-based baseline. We discuss implications of integrating AI-generated personas into product design workflows.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.06254", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.06254", "abs": "https://arxiv.org/abs/2602.06254", "authors": ["Mengyu Chen", "Youngwook Do", "Feiyu Lu", "Kaiming Cheng", "Blair MacIntyre"], "title": "Secure and Private Spatial Sharing for Mixed Reality Remote Collaboration in Enterprise Settings", "comment": null, "summary": "Mixed Reality (MR) technologies are increasingly adopted by enterprises to enhance remote collaboration, enabling users to share real-time views of their physical environments through head-mounted displays (HMDs). While MR spatial sharing offers significant benefits, it introduces complex security and privacy risks, particularly in balancing employee collaboration needs with enterprise data protection requirements across office and personal spaces. This paper investigates these challenges through formative interviews with employees and expert consultations with professionals in cybersecurity, IoT, technology risk, and corporate legal domains. We present a conceptual framework for secure MR spatial sharing in enterprise contexts and identify critical concerns and requirements for system design. Based on our findings, we offer actionable recommendations to guide the development of secure and privacy-preserving MR spatial sharing solutions for future enterprise deployments.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.06278", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.06278", "abs": "https://arxiv.org/abs/2602.06278", "authors": ["Tram Thi Minh Tran", "Debargha Dey", "Martin Tomitsch"], "title": "Rethinking External Communication of Autonomous Vehicles: Is the Field Converging, Diverging, or Stalling?", "comment": null, "summary": "As autonomous vehicles enter public spaces, external human-machine interfaces are proposed to support communication with external road users. A decade of research has produced hundreds of studies and reviews, yet it remains unclear whether the field is converging on shared principles or diverging across approaches. We present a multi-dimensional analysis of 620 publications, complemented by industry deployments and regulatory documents, to track research evolution and identify convergence. The analysis reveals several field-level patterns. First, convergence on a safety-first core: simple visual cues that clarify intent. Second, sustained divergence in necessity and implementation. Third, a progressive filtering funnel: broad exploration in research and concepts narrows in deployment and is codified by regulation into a minimal set of permitted signals. These insights point to a shift in emphasis for future work, from producing new prototypes toward consolidating evidence, clarifying points of contention, and developing frameworks that can adapt across contexts.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.06305", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.06305", "abs": "https://arxiv.org/abs/2602.06305", "authors": ["Sirui Han", "Yuyao Zhang", "Yidan Huang", "Xueyan Li", "Chengzhong Liu", "Yike Guo"], "title": "Reimagining Legal Fact Verification with GenAI: Toward Effective Human-AI Collaboration", "comment": null, "summary": "Fact verification is a critical yet underexplored component of non-litigation legal practice. While existing research has examined automation in legal workflow and human-AI collaboration in high-stakes domains, little is known about how GenAI can support fact verification, a task that demands prudent judgment and strict accountability. To address this, we conducted semi-structured interviews with 18 lawyers to understand their current verification practices, attitudes toward GenAI adoption, and expectations for future systems. We found that while lawyers use GenAI for low-risk tasks like drafting and language optimization, concerns over accuracy, confidentiality, and liability are currently limiting its adoption for fact verification. These concerns translate into core design requirements for AI systems that are trustworthy and accountable. Based on these, we contribute design insights for human-AI collaboration in legal fact verification, emphasizing the development of auditable systems that balance efficiency with professional judgment and uphold ethical and legal accountability in high-stakes practice.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.06327", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.06327", "abs": "https://arxiv.org/abs/2602.06327", "authors": ["Yuying Tang", "Jiayi Zhou", "Haotian Li", "Xing Xie", "Xiaojuan Ma", "Huamin Qu"], "title": "How Do Human Creators Embrace Human-AI Co-Creation? A Perspective on Human Agency of Screenwriters", "comment": "Accepted by CHI 2026", "summary": "Generative AI has greatly transformed creative work in various domains, such as screenwriting. To understand this transformation, prior research often focused on capturing a snapshot of human-AI co-creation practice at a specific moment, with less attention to how humans mobilize, regulate, and reflect to form the practice gradually. Motivated by Bandura's theory of human agency, we conducted a two-week study with 19 professional screenwriters to investigate how they embraced AI in their creation process. Our findings revealed that screenwriters not only mindfully planned, foresaw, and responded to AI usage, but, more importantly, through reflections on practice, they developed themselves and human-AI co-creation paradigms, such as cognition, strategies, and workflows. They also expressed various expectations for how future AI should better support their agency. Based on our findings, we conclude this paper with extensive discussion and actionable suggestions to screenwriters, tool developers, and researchers for sustainable human-AI co-creation.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.06396", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.06396", "abs": "https://arxiv.org/abs/2602.06396", "authors": ["Yi Wen", "Yu Zhang", "Sriram Suresh", "Zhicong Lu", "Can Liu", "Meng Xia"], "title": "InterFlow: Designing Unobtrusive AI to Empower Interviewers in Semi-Structured Interviews", "comment": "Accepted to CHI 2026", "summary": "Semi-structured interviews are a common method in qualitative research. However, conducting high-quality interviews is challenging, as it requires interviewers to actively listen to participants, adapt their plans as the conversation unfolds, and probe effectively. We propose InterFlow, an AI-powered visual scaffold that helps interviewers manage the interview flow and facilitates real-time data sensemaking. The system dynamically adapts the interview script to the ongoing conversation and provides a visual timer to track interview progress and conversational balance. It further supports information capture with three levels of automation: manual entry, AI-assisted summary with user-specified focus, and a co-interview agent that proactively surfaces potential follow-up points. A within-subject user study (N = 12) indicates that InterFlow reduces interviewers' cognitive load and facilitates the interview process. Based on the user study findings, we provide design implications for unobtrusive and agency-preserving AI assistance under time-sensitive and cognitively demanding situations.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.06489", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.06489", "abs": "https://arxiv.org/abs/2602.06489", "authors": ["Yang Li", "Anna Maria Feit"], "title": "Simulating Word Suggestion Usage in Mobile Typing to Guide Intelligent Text Entry Design", "comment": null, "summary": "Intelligent text entry (ITE) methods, such as word suggestions, are widely used in mobile typing, yet improving ITE systems is challenging because the cognitive mechanisms behind suggestion use remain poorly understood, and evaluating new systems often requires long-term user studies to account for behavioral adaptation. We present WSTypist, a reinforcement learning-based model that simulates how typists integrate word suggestions into typing. It builds on recent hierarchical control models of typing, but focuses on the cognitive mechanisms that underlie the high-level decision-making for effectively integrating word suggestions into manual typing: assessing efficiency gains, considering orthographic uncertainties, and including personal reliance on AI support. Our evaluations show that WSTypist simulates diverse human-like suggestion-use strategies, reproduces individual differences, and generalizes across different systems. Importantly, we demonstrate on four design cases how computational rationality models can be used to inform what-if analyses during the design process, by simulating how users might adapt to changes in the UI or in the algorithmic support, reducing the need for long-term user studies.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.06506", "categories": ["cs.HC", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.06506", "abs": "https://arxiv.org/abs/2602.06506", "authors": ["Han Meng", "Qiuyuan Lyu", "Peinuan Qin", "Yitian Yang", "Renwen Zhang", "Wen-Chieh Lin", "Yi-Chieh Lee"], "title": "Designing Computational Tools for Exploring Causal Relationships in Qualitative Data", "comment": "19 pages, 5 figures, conditionally accepted by CHI26", "summary": "Exploring causal relationships for qualitative data analysis in HCI and social science research enables the understanding of user needs and theory building. However, current computational tools primarily characterize and categorize qualitative data; the few systems that analyze causal relationships either inadequately consider context, lack credibility, or produce overly complex outputs. We first conducted a formative study with 15 participants interested in using computational tools for exploring causal relationships in qualitative data to understand their needs and derive design guidelines. Based on these findings, we designed and implemented QualCausal, a system that extracts and illustrates causal relationships through interactive causal network construction and multi-view visualization. A feedback study (n = 15) revealed that participants valued our system for reducing the analytical burden and providing cognitive scaffolding, yet navigated how such systems fit within their established research paradigms, practices, and habits. We discuss broader implications for designing computational tools that support qualitative data analysis.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.06596", "categories": ["cs.HC", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.06596", "abs": "https://arxiv.org/abs/2602.06596", "authors": ["Dominik P. Hofer", "David Haag", "Rania Islambouli", "Jan D. Smeddinck"], "title": "Personality as Relational Infrastructure: User Perceptions of Personality-Trait-Infused LLM Messaging", "comment": "Currently under review", "summary": "Digital behaviour change systems increasingly rely on repeated, system-initiated messages to support users in everyday contexts. LLMs enable these messages to be personalised consistently across interactions, yet it remains unclear whether such personalisation improves individual messages or instead shapes users' perceptions through patterns of exposure. We explore this question in the context of LLM-generated JITAIs, which are short, context-aware messages delivered at moments deemed appropriate to support behaviour change, using physical activity as an application domain. In a controlled retrospective study, 90 participants evaluated messages generated using four LLM strategies: baseline prompting, few-shot prompting, fine-tuned models, and retrieval augmented generation, each implemented with and without Big Five Personality Traits to produce personality-aligned communication across multiple scenarios. Using ordinal multilevel models with within-between decomposition, we distinguish trial-level effects, whether personality information improves evaluations of individual messages, from person-level exposure effects, whether participants receiving higher proportions of personality-informed messages exhibit systematically different overall perceptions. Results showed no trial-level associations, but participants who received higher proportions of BFPT-informed messages rated the messages as more personalised, appropriate, and reported less negative affect. We use Communication Accommodation Theory for post-hoc analysis. These results suggest that personality-based personalisation in behaviour change systems may operate primarily through aggregate exposure rather than per-message optimisation, with implications for how adaptive systems are designed and evaluated in sustained human-AI interaction. In-situ longitudinal studies are needed to validate these findings in real-world contexts.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.06678", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.06678", "abs": "https://arxiv.org/abs/2602.06678", "authors": ["Shayla Sharmin", "Sadia Afrin"], "title": "Beyond Judgment: Exploring LLM as a Support System for Maternal Mental Health", "comment": null, "summary": "In the age of Large Language Models (LLMs), much work has already been done on how LLMs support medication advice and serve as information providers; however, how mothers use these tools for emotional and informational support to avoid social judgment remains underexplored. In this study, we have conducted a 10-day mixed-methods exploratory survey (N=107) to investigate how mothers use LLMs as a non-judgmental resource for emotional support and regulation, as well as situational reassurance. Our findings show that mothers are asking LLMs various questions about childcare to reassure themselves and avoid judgment, particularly around childcare decisions, maternal guilt, and late-night caregiving. Open-ended responses also show that mothers are comfortable with LLMs because they do not have to think about social consequences or judgment. Although they use LLMs for quick information or reassurance to avoid judgment, the results also show that more than half of the participants value human warmth over LLMs; however, a significant minority, especially those who live in a joint family, consider LLMs to avoid human judgment. These findings help us understand how we can frame LLMs as low-risk interaction support rather than as a replacement for human support, and highlight the role of social context in shaping emotional technology use.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.06714", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.06714", "abs": "https://arxiv.org/abs/2602.06714", "authors": ["Jialin Li", "Zhenhao Chen", "Hanjun Luo", "Hanan Salam"], "title": "PrefIx: Understand and Adapt to User Preference in Human-Agent Interaction", "comment": null, "summary": "LLM-based agents can complete tasks correctly yet still frustrate users through poor interaction patterns, such as excessive confirmations, opaque reasoning, or misaligned pacing. Current benchmarks evaluate task accuracy but overlook how agents interact: whether they infer preferences from implicit cues, adapt dynamically, or maintain fine-grained interaction quality. We introduce Prefix, a configurable environment that evaluates both what agents accomplish and how they interact. Central to Prefix is the Interaction-as-a-Tool (IaaT) paradigm, which treats interaction behaviors as structured tool calls, unifying them with existing evaluation frameworks. We define 31 preference settings across 14 attributes and formalize user experience (UX) as a core metric alongside task accuracy. A composite LLM-as-a-Judge mechanism across seven UX dimensions achieves strong aggregate reliability (ICC > 0.79), high internal consistency (alpha = 0.943), and human correlation (rho = 0.52-0.78). Preference-aware agents show 7.6% average UX improvement and 18.5% gain in preference alignment. Our work is openly accessible.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.06734", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.06734", "abs": "https://arxiv.org/abs/2602.06734", "authors": ["Gefei Zhang", "Guodao Sun", "Meng Xia", "Ronghua Liang"], "title": "ClassAid: A Real-time Instructor-AI-Student Orchestration System for Classroom Programming Activities", "comment": null, "summary": "Generative AI is reshaping education, but it also raises concerns about instability and overreliance. In programming classrooms, we aim to leverage its feedback capabilities while reinforcing the educator's role in guiding student-AI interactions. We developed ClassAid, a real-time orchestration system that integrates TA Agents to provide personalized support and an AI-driven dashboard that visualizes student-AI interactions, enabling instructors to dynamically adjust TA Agent modes. Instructors can configure the Agent to provide technical feedback (direct coding solutions), heuristic feedback (hint-based guidance), automatic feedback (autonomously selecting technical or heuristic support), or silent operation (no AI support). We evaluated ClassAid through three aspects: (1) the TA Agents' performance, (2) feedback from 54 students and one instructor during a classroom deployment, and (3) interviews with eight educators. Results demonstrate that dynamic instructor control over AI supports effective real-time personalized feedback and provides design implications for integrating AI into authentic educational settings.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.06792", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.06792", "abs": "https://arxiv.org/abs/2602.06792", "authors": ["Chin Tseng", "Arran Zeyu Wang", "Ghulam Jilani Quadri", "Danielle Albers Szafir"], "title": "Redundant is Not Redundant: Automating Efficient Categorical Palette Design Unifying Color & Shape Encodings with CatPAW", "comment": "Conditionally accepted to ACM CHI 2026", "summary": "Colors and shapes are commonly used to encode categories in multi-class scatterplots. Designers often combine the two channels to create redundant encodings, aiming to enhance class distinctions. However, evidence for the effectiveness of redundancy remains conflicted, and guidelines for constructing effective combinations are limited. This paper presents four crowdsourced experiments evaluating redundant color-shape encodings and identifying high-performing configurations across different category numbers. Results show that redundancy significantly improves accuracy in assessing class-level correlations, with the strongest benefits for 5-8 categories. We also find pronounced interaction effects between colors and shapes, underscoring the need for careful pairing in designing redundant encodings. Drawing on these findings, we introduce a categorical palette design tool that enables designers to construct empirically grounded palettes for effective categorical visualization. Our work advances understanding of categorical perception in data visualization by systematically identifying effective redundant color-shape combinations and embedding these insights into a practical palette design tool.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.06915", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.06915", "abs": "https://arxiv.org/abs/2602.06915", "authors": ["Pavlos Panagiotidis", "Jocelyn Spence", "Nils Jaeger", "Paul Tennent"], "title": "Directing Space: Rehearsing Architecture as Performer with Explainable AI", "comment": null, "summary": "As AI systems increasingly become embedded in interactive and im-mersive artistic environments, artists and technologists are discovering new opportunities to engage with their interpretive and autonomous capacities as creative collaborators in live performance. The focus of this work-in-progress is on outlining conceptual and technical foundations under which performance-makers and interactive architecture can collaborate within rehearsal settings. It introduces a rehearsal-oriented prototype system for shaping and testing AI-mediated environments within creative practice. This approach treats interactive architecture as a performative agent that senses spatial behaviour and speech, interprets these signals through a large language model, and generates real-time environmental adaptations. Designed for deployment in physical performance spaces, the system employs virtual blueprints to support iterative experimentation and creative dialogue between artists and AI agents, using reasoning traces to inform architectural interaction design grounded in dramaturgical principles.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.06916", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.06916", "abs": "https://arxiv.org/abs/2602.06916", "authors": ["Zheyuan Zhang", "Dorian Peters", "Lan Xiao", "Jingjing Sun", "Laura Moradbakhti", "Andrew Hall", "Rafael A. Calvo"], "title": "Understanding Workplace Relatedness Support among Healthcare Professionals: A Four-Layer Model and Implications for Technology Design", "comment": null, "summary": "Healthcare professionals (HCPs) face increasing occupational stress and burnout. Supporting HCPs need for relatedness is fundamental to their psychological wellbeing and resilience. However, how technologies could support HCPs relatedness in the workplace remains less explored. This study incorporated semi-structured interviews (n = 15) and co-design workshops (n = 21) with HCPs working in the UK National Health Service (NHS), to explore their current practices and preferences for workplace relatedness support, and how technology could be utilized to benefit relatedness. Qualitative analysis yielded a four-layer model of HCPs relatedness need, which includes Informal Interactions, Camaraderie and Bond, Community and Organizational Care, and Shared Identity. Workshops generated eight design concepts (e.g., Playful Encounter, Collocated Action, and Memories and Stories) that operationalize the four relatedness need layers. We conclude by highlighting the theoretical relevance, practical design implications, and the necessity to strengthen relatedness support for HCPs in the era of digitalization and artificial intelligence.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
