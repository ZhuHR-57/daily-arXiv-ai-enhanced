{"id": "2511.15036", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2511.15036", "abs": "https://arxiv.org/abs/2511.15036", "authors": ["Kamal Mammadov", "Damith C. Ranasinghe"], "title": "Area-Optimal Control Strategies for Heterogeneous Multi-Agent Pursuit", "comment": null, "summary": "This paper presents a novel strategy for a multi-agent pursuit-evasion game involving multiple faster pursuers with heterogenous speeds and a single slower evader. We define a geometric region, the evader's safe-reachable set, as the intersection of Apollonius circles derived from each pursuer-evader pair. The capture strategy is formulated as a zero-sum game where the pursuers cooperatively minimize the area of this set, while the evader seeks to maximize it, effectively playing a game of spatial containment. By deriving the analytical gradients of the safe-reachable set's area with respect to agent positions, we obtain closed-form, instantaneous optimal control laws for the heading of each agent. These strategies are computationally efficient, allowing for real-time implementation. Simulations demonstrate that the gradient-based controls effectively steer the pursuers to systematically shrink the evader's safe region, leading to guaranteed capture. This area-minimization approach provides a clear geometric objective for cooperative capture.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.15053", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2511.15053", "abs": "https://arxiv.org/abs/2511.15053", "authors": ["Pengcheng Dai", "He Wang", "Dongming Wang", "Wenwu Yu"], "title": "Distributed primal-dual algorithm for constrained multi-agent reinforcement learning under coupled policies", "comment": null, "summary": "In this work, we investigate constrained multi-agent reinforcement learning (CMARL), where agents collaboratively maximize the sum of their local objectives while satisfying individual safety constraints. We propose a framework where agents adopt coupled policies that depend on both local states and parameters, as well as those of their $\u03ba_p$-hop neighbors, with $\u03ba_p>0$ denoting the coupling distance. A distributed primal-dual algorithm is further developed under this framework, wherein each agent has access only to state-action pairs within its $2\u03ba_p$-hop neighborhood and to reward information within its $\u03ba+ 2\u03ba_p$-hop neighborhood, with $\u03ba> 0$ representing the truncation distance. Moreover, agents are not permitted to directly share their true policy parameters or Lagrange multipliers. Instead, each agent constructs and maintains local estimates of these variables for other agents and employs such estimates to execute its policy. Additionally, these estimates are further updated and exchanged exclusively through an independent, time-varying networks, which enhances the overall system security. We establish that, with high probability, our algorithm can achieve an $\u03b5$-first-order stationary convergence with an approximation error of $\\mathcal{O}(\u03b3^{\\frac{\u03ba+1}{\u03ba_{p}}})$ for discount factor $\u03b3\\in(0,1)$. Finally, simulations in GridWorld environment are conducted to demonstrate the effectiveness of the proposed algorithm.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.15292", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2511.15292", "abs": "https://arxiv.org/abs/2511.15292", "authors": ["Jianming Chen", "Yawen Wang", "Junjie Wang", "Xiaofei Xie", "Yuanzhe Hu", "Qing Wang", "Fanjiang Xu"], "title": "Adversarial Attack on Black-Box Multi-Agent by Adaptive Perturbation", "comment": null, "summary": "Evaluating security and reliability for multi-agent systems (MAS) is urgent as they become increasingly prevalent in various applications. As an evaluation technique, existing adversarial attack frameworks face certain limitations, e.g., impracticality due to the requirement of white-box information or high control authority, and a lack of stealthiness or effectiveness as they often target all agents or specific fixed agents. To address these issues, we propose AdapAM, a novel framework for adversarial attacks on black-box MAS. AdapAM incorporates two key components: (1) Adaptive Selection Policy simultaneously selects the victim and determines the anticipated malicious action (the action would lead to the worst impact on MAS), balancing effectiveness and stealthiness. (2) Proxy-based Perturbation to Induce Malicious Action utilizes generative adversarial imitation learning to approximate the target MAS, allowing AdapAM to generate perturbed observations using white-box information and thus induce victims to execute malicious action in black-box settings. We evaluate AdapAM across eight multi-agent environments and compare it with four state-of-the-art and commonly-used baselines. Results demonstrate that AdapAM achieves the best attack performance in different perturbation rates. Besides, AdapAM-generated perturbations are the least noisy and hardest to detect, emphasizing the stealthiness.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.14972", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14972", "abs": "https://arxiv.org/abs/2511.14972", "authors": ["W. Bradley Knox", "Katie Bradford", "Samanta Varela Castro", "Desmond C. Ong", "Sean Williams", "Jacob Romanow", "Carly Nations", "Peter Stone", "Samuel Baker"], "title": "Harmful Traits of AI Companions", "comment": null, "summary": "Amid the growing prevalence of human -- AI interaction, large language models and other AI-based entities increasingly provide forms of companionship to human users. Such AI companionship -- i.e., bonded relationships between humans and AI systems that resemble the relationships people have with family members, friends, and romantic partners -- might substantially benefit humans. Yet such relationships can also do profound harm. We propose a framework for analyzing potential negative impacts of AI companionship by identifying specific harmful traits of AI companions and speculatively mapping causal pathways back from these traits to possible causes and forward to potential harmful effects. We provide detailed, structured analysis of four potentially harmful traits -- the absence of natural endpoints for relationships, vulnerability to product sunsetting, high attachment anxiety, and propensity to engender protectiveness -- and briefly discuss fourteen others. For each trait, we propose hypotheses connecting causes -- such as misaligned optimization objectives and the digital nature of AI companions -- to fundamental harms -- including reduced autonomy, diminished quality of human relationships, and deception. Each hypothesized causal connection identifies a target for potential empirical evaluation. Our analysis examines harms at three levels: to human partners directly, to their relationships with other humans, and to society broadly. We examine how existing law struggles to address these emerging harms, discuss potential benefits of AI companions, and conclude with design recommendations for mitigating risks. This analysis offers immediate suggestions for reducing risks while laying a foundation for deeper investigation of this critical but understudied topic.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.15012", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2511.15012", "abs": "https://arxiv.org/abs/2511.15012", "authors": ["Gi-Hwan Shin"], "title": "A Quantitative Framework for Assessing Sleep Quality from EEG Time Series in Complex Dynamic Systems", "comment": "Doctoral dissertation, Korea University, 2025", "summary": "Modern lifestyles contribute to insufficient sleep, impairing cognitive function and weakening the immune system. Sleep quality (SQ) is vital for physiological and mental health, making its understanding and accurate assessment critical. However, its multifaceted nature, shaped by neurological and environmental factors, makes precise quantification challenging. Here, we address this challenge by utilizing electroencephalography (EEG) for phase-amplitude coupling (PAC) analysis to elucidate the neurological basis of SQ, examining both states of sleep and wakefulness, including resting state (RS) and working memory. Our results revealed distinct patterns in beta power and delta connectivity in sleep and RS, together with the reaction time of working memory. A notable finding was the pronounced delta-beta PAC, a feature markedly stronger in individuals with good SQ. We further observed that SQ was positively correlated with increased delta-beta PAC. Leveraging these insights, we applied machine learning models to classify SQ at an individual level, demonstrating that the delta-beta PAC outperformed other EEG characteristics. These findings establish delta-beta PAC as a robust electrophysiological marker to quantify SQ and elucidate its neurological determinants.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.15189", "categories": ["cs.GR", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2511.15189", "abs": "https://arxiv.org/abs/2511.15189", "authors": ["Yixin Chen", "David I. W. Levin", "Timothy R. Langlois"], "title": "Fluid Control with Localized Spacetime Windows", "comment": null, "summary": "We present a physics-based fluid control method utilizing localized spacetime windows, extending force-based spacetime control to simulation scales that were previously intractable. Building on the observation that optimal control force distributions are often localized, we show that operating only in a localized spacetime window around the edit of interest can improve performance. To determine the optimal spacetime window size, we employ the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) method to search for the optimal temporal window size within a user-defined spatial region. Instead of using a Lagrangian representation, we optimize and apply control forces on a \"floating\" background grid, decoupling the control dimensionality from the simulation and enabling seamless integration with particle-based methods. Moreover, since the boundary conditions of the localized areas are encoded in the objective function, no extra effort is required to ensure consistency between the local control region and the global simulation domain. We demonstrate the effectiveness and efficiency of our method with various 2D and 3D particle-based free-surface simulation examples.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.15266", "categories": ["cs.MM", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.15266", "abs": "https://arxiv.org/abs/2511.15266", "authors": ["Liangyu Chen", "Yichen Xu", "Jianzhe Ma", "Yuqi Liu", "Donglu Yang", "Liang Zhang", "Wenxuan Wang", "Qin Jin"], "title": "ChartEditor: A Reinforcement Learning Framework for Robust Chart Editing", "comment": "Accept to AAAI 2026 Main Track", "summary": "Chart editing reduces manual effort in visualization design. Typical benchmarks limited in data diversity and assume access to complete chart code, which is seldom in real-world scenarios. To address this gap, we present ChartEditVista, a comprehensive benchmark consisting of 7,964 samples spanning 31 chart categories. It encompasses diverse editing instructions and covers nearly all editable chart elements. The inputs in ChartEditVista include only the original chart image and natural language editing instructions, without the original chart codes. ChartEditVista is generated through a fully automated pipeline that produces, edits, and verifies charts, ensuring high-quality chart editing data. Besides, we introduce two novel fine-grained, rule-based evaluation metrics: the layout metric, which evaluates the position, size and color of graphical components; and the text metric, which jointly assesses textual content and font styling. Building on top of ChartEditVista, we present ChartEditor, a model trained using a reinforcement learning framework that incorporates a novel rendering reward to simultaneously enforce code executability and visual fidelity. Through extensive experiments and human evaluations, we demonstrate that ChartEditVista provides a robust evaluation, while ChartEditor consistently outperforms models with similar-scale and larger-scale on chart editing tasks.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.15013", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2511.15013", "abs": "https://arxiv.org/abs/2511.15013", "authors": ["Gi-Hwan Shin", "Young-Seok Kweon", "Seungwon Oh", "Seong-Whan Lee"], "title": "Personalized targeted memory reactivation enhances consolidation of challenging memories via slow wave and spindle dynamics", "comment": null, "summary": "Sleep is crucial for memory consolidation, underpinning effective learning. Targeted memory reactivation (TMR) can strengthen neural representations by re-engaging learning circuits during sleep. However, TMR protocols overlook individual differences in learning capacity and memory trace strength, limiting efficacy for difficult-to-recall memories. Here, we present a personalized TMR protocol that adjusts stimulation frequency based on individual retrieval performance and task difficulty during a word-pair memory task. In an experiment comparing personalized TMR, TMR, and control groups, the personalized protocol significantly reduced memory decay and improved error correction under challenging recall. Electroencephalogram (EEG) analyses revealed enhanced synchronization of slow waves and spindles, with a significant positive correlation between behavioral and EEG features for challenging memories. Multivariate classification identified distinct neural signatures linked to the personalized approach, highlighting its ability to target memory-specific circuits. These findings provide novel insights into sleep-dependent memory consolidation and support personalized TMR interventions to optimize learning outcomes.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.15398", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2511.15398", "abs": "https://arxiv.org/abs/2511.15398", "authors": ["Manos Kamarianakis", "Antonis Protopsaltis", "George Papagiannakis"], "title": "One algebra for all : Geometric Algebra methods for neurosymbolic XR scene authoring, animation and neural rendering", "comment": "10 pages, 9 Figures", "summary": "This position paper delves into the transformative role of Geometric Algebra (GA) in advancing specific areas of Computer Graphics (CG) and Extended Reality (XR), particularly in character animation, rendering, rigging, neural rendering, and generative AI-driven scene editing. Common CG algorithms require handling rotations, translations, and dilations (uniform scalings) in operations such as object rendering, rigged model animation, soft-body deformation, and XR simulations. Traditional representation forms - such as matrices, quaternions, and vectors - often introduce limitations in precision and performance. Recent breakthroughs in the use of GA suggest it can significantly enhance these processes by encapsulating geometric forms and transformations into uniform algebraic expressions, which maintain critical geometric properties throughout multi-step transformations. Furthermore, we explore how GA can serve as a unifying mathematical substrate for neurosymbolic XR scene authoring, bridging learned neural representations and explicit geometric reasoning. This paper outlines how GA-based approaches can improve the fidelity of rigged character animations, enhance soft-body simulations, streamline real-time rendering, and optimize neural and generative AI scene editing. GA offers a coherent and efficient framework for these processes, resulting in superior visual outcomes and computational efficiency, particularly in XR environments.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.15341", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2511.15341", "abs": "https://arxiv.org/abs/2511.15341", "authors": ["Wen Shang", "Yuan Liao", "Vasilis Friderikos", "Halim Yanikomeroglu"], "title": "Anchor-and-Connect: Robotic Aerial Base Stations Transforming 6G Infrastructure", "comment": null, "summary": "Despite the significant attention that aerial base stations (ABSs) have received recently, their practical implementation is severely weakened by their limited endurance due to the battery constraints of drones. To overcome this fundamental limitation and barrier for wider adoption, we propose the concept of robotic aerial base stations (RABSs) that are equipped with energy-neutral anchoring end-effectors able to autonomously grasp or perch on tall urban landforms. Thanks to the energy-efficient anchoring operation, RABSs could offer seamless wireless connectivity for multiple hours compared to minutes of the typical hovering-based ABSs. Therefore, the prolonged service capabilities of RABSs allowing them to integrate into the radio access network and augment the network capacity where and when needed. To set the scene, we discuss the key components of the proposed RABS concept including hardware, workflow, communication considerations, and regulation issues. Then, the advantages of RABSs are highlighted which is followed by case studies that compare RABSs with terrestrial micro BSs and other types of non-terrestrial communication infrastructure, such as hovering-based, tethered, and laser-powered ABSs.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.15110", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15110", "abs": "https://arxiv.org/abs/2511.15110", "authors": ["Ting-An Lin", "Pei-Lin Tsai", "Yi-An Chen", "Feng-Yu Chen", "Lyn Chao-ling Chen"], "title": "Eye Care You: Voice Guidance Application Using Social Robot for Visually Impaired People", "comment": "Accepted in the 35th IPPR Conference on Computer Vision, Graphics, and Image Processing (CVGIP2022)", "summary": "In the study, the device of social robot was designed for visually impaired users, and along with a mobile application for provide functions to assist their lives. Both physical and mental conditions of visually impaired users are considered, and the mobile application provides functions: photo record, mood lift, greeting guest and today highlight. The application was designed for visually impaired users, and uses voice control to provide a friendly interface. Photo record function allows visually impaired users to capture image immediately when they encounter danger situations. Mood lift function accompanies visually impaired users by asking questions, playing music and reading articles. Greeting guest function answers to the visitors for the inconvenient physical condition of visually impaired users. In addition, today highlight function read news including weather forecast, daily horoscopes and daily reminder for visually impaired users. Multiple tools were adopted for developing the mobile application, and a website was developed for caregivers to check statues of visually impaired users and for marketing of the application.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.15586", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.15586", "abs": "https://arxiv.org/abs/2511.15586", "authors": ["Aaron Ferguson", "Ahmed A. A. Osman", "Berta Bescos", "Carsten Stoll", "Chris Twigg", "Christoph Lassner", "David Otte", "Eric Vignola", "Federica Bogo", "Igor Santesteban", "Javier Romero", "Jenna Zarate", "Jeongseok Lee", "Jinhyung Park", "Jinlong Yang", "John Doublestein", "Kishore Venkateshan", "Kris Kitani", "Ladislav Kavan", "Marco Dal Farra", "Matthew Hu", "Matthew Cioffi", "Michael Fabris", "Michael Ranieri", "Mohammad Modarres", "Petr Kadlecek", "Rinat Abdrashitov", "Romain Pr\u00e9vost", "Roman Rajbhandari", "Ronald Mallet", "Russel Pearsall", "Sandy Kao", "Sanjeev Kumar", "Scott Parrish", "Te-Li Wang", "Tony Tung", "Yuan Dong", "Yuhua Chen", "Yuanlu Xu", "Yuting Ye", "Zhongshi Jiang"], "title": "MHR: Momentum Human Rig", "comment": null, "summary": "We present MHR, a parametric human body model that combines the decoupled skeleton/shape paradigm of ATLAS with a flexible, modern rig and pose corrective system inspired by the Momentum library. Our model enables expressive, anatomically plausible human animation, supporting non-linear pose correctives, and is designed for robust integration in AR/VR and graphics pipelines.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.15182", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15182", "abs": "https://arxiv.org/abs/2511.15182", "authors": ["Subhashis Hazarika", "Leonard Lupin-Jimenez", "Rohit Vuppala", "Ashesh Chattopadhyay", "Hon Yung Wong"], "title": "SWR-Viz: AI-assisted Interactive Visual Analytics Framework for Ship Weather Routing", "comment": null, "summary": "Efficient and sustainable maritime transport increasingly depends on reliable forecasting and adaptive routing, yet operational adoption remains difficult due to forecast latencies and the need for human judgment in rapid decision-making under changing ocean conditions. We introduce SWR-Viz, an AI-assisted visual analytics framework that combines a physics-informed Fourier Neural Operator wave forecast model with SIMROUTE-based routing and interactive emissions analytics. The framework generates near-term forecasts directly from current conditions, supports data assimilation with sparse observations, and enables rapid exploration of what-if routing scenarios. We evaluate the forecast models and SWR-Viz framework along key shipping corridors in the Japan Coast and Gulf of Mexico, showing both improved forecast stability and realistic routing outcomes comparable to ground-truth reanalysis wave products. Expert feedback highlights the usability of SWR-Viz, its ability to isolate voyage segments with high emission reduction potential, and its value as a practical decision-support system. More broadly, this work illustrates how lightweight AI forecasting can be integrated with interactive visual analytics to support human-centered decision-making in complex geospatial and environmental domains.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.15218", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2511.15218", "abs": "https://arxiv.org/abs/2511.15218", "authors": ["Byoung-Hee Kwon"], "title": "Efficient Transformer-Integrated Deep Neural Architectures for Robust EEG Decoding of Complex Visual Imagery", "comment": "Doctoral dissertation, Korea University, 2025", "summary": "This study introduces a pioneering approach in brain-computer interface (BCI) technology, featuring our novel concept of complex visual imagery for non-invasive electroencephalography (EEG)-based communication. Complex visual imagery, as proposed in our work, involves the user engaging in the mental visualization of complex upper limb movements. This innovative approach significantly enhances the BCI system, facilitating the extension of its applications to more sophisticated tasks such as EEG-based robotic arm control. By leveraging this advanced form of visual imagery, our study opens new horizons for intricate and intuitive mind-controlled interfaces. We developed an advanced deep learning architecture that integrates functional connectivity metrics with a convolutional neural network-image transformer. This framework is adept at decoding subtle user intentions, addressing the spatial variability in complex visual tasks, and effectively translating these into precise commands for robotic arm control. Our comprehensive offline and pseudo-online evaluations demonstrate the framework's efficacy in real-time applications, including the nuanced control of robotic arms. The robustness of our approach is further validated through leave-one-subject-out cross-validation, marking a significant step towards versatile, subject-independent BCI applications. This research highlights the transformative impact of advanced visual imagery and deep learning in enhancing the usability and adaptability of BCI systems, particularly in robotic arm manipulation.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.15253", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15253", "abs": "https://arxiv.org/abs/2511.15253", "authors": ["Sirui Chen", "Jinsong Zhou", "Xinli Xu", "Xiaoyu Yang", "Litao Guo", "Ying-Cong Chen"], "title": "PresentCoach: Dual-Agent Presentation Coaching through Exemplars and Interactive Feedback", "comment": "13pages,6figures", "summary": "Effective presentation skills are essential in education, professional communication, and public speaking, yet learners often lack access to high-quality exemplars or personalized coaching. Existing AI tools typically provide isolated functionalities such as speech scoring or script generation without integrating reference modeling and interactive feedback into a cohesive learning experience. We introduce a dual-agent system that supports presentation practice through two complementary roles: the Ideal Presentation Agent and the Coach Agent. The Ideal Presentation Agent converts user-provided slides into model presentation videos by combining slide processing, visual-language analysis, narration script generation, personalized voice synthesis, and synchronized video assembly. The Coach Agent then evaluates user-recorded presentations against these exemplars, conducting multimodal speech analysis and delivering structured feedback in an Observation-Impact-Suggestion (OIS) format. To enhance the authenticity of the learning experience, the Coach Agent incorporates an Audience Agent, which simulates the perspective of a human listener and provides humanized feedback reflecting audience reactions and engagement. Together, these agents form a closed loop of observation, practice, and feedback. Implemented on a robust backend with multi-model integration, voice cloning, and error handling mechanisms, the system demonstrates how AI-driven agents can provide engaging, human-centered, and scalable support for presentation skill development in both educational and professional contexts.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.15331", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2511.15331", "abs": "https://arxiv.org/abs/2511.15331", "authors": ["Anqi Wang", "Zhengyi Li", "Xin Tong", "Pan Hui"], "title": "DesignerlyLoop: Bridging the Cognitive Gap through Visual Node-Based Reasoning in Human-AI Collaborative Design", "comment": null, "summary": "Large language models (LLMs) offer powerful support for design tasks, yet their goal-oriented, single-turn responses often misalign with the nonlinear, exploratory nature of design processes. This mismatch creates a cognitive gap, limiting designers' ability to articulate evolving intentions, critically evaluate outputs, and maintain creative agency. To address these challenges, we developed DesignerlyLoop, a visual node-based system that embeds LLM reasoning chains into the design workflow. The system enables designers to externalize and curate reasoning structures, iteratively organize intentions, and interact with LLMs as dynamic cognitive engines rather than static answer providers. We conducted a within-subject study with 20 designers, combining qualitative and quantitative methods, and found that DesignerlyLoop enhanced creative reflection, design quality, and interaction experience by supporting systematic engagement with both human and machine reasoning. These findings highlight the potential of structured, interactive visualization to transform human-AI co-creation into a reflective and iterative design process.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.15342", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15342", "abs": "https://arxiv.org/abs/2511.15342", "authors": ["Shan Shan"], "title": "Reflexive Evidence-Based Multimodal Learning for Clean Energy Transitions: Causal Insights on Cooking Fuel Access, Urbanization, and Carbon Emissions", "comment": null, "summary": "Achieving Sustainable Development Goal 7 (Affordable and Clean Energy) requires not only technological innovation but also a deeper understanding of the socioeconomic factors influencing energy access and carbon emissions. While these factors are gaining attention, critical questions remain, particularly regarding how to quantify their impacts on energy systems, model their cross-domain interactions, and capture feedback dynamics in the broader context of energy transitions. To address these gaps, this study introduces ClimateAgents, an AI-based framework that combines large language models with domain-specialized agents to support hypothesis generation and scenario exploration. Leveraging 20 years of socioeconomic and emissions data from 265 economies, countries and regions, and 98 indicators drawn from the World Bank database, the framework applies a machine learning based causal inference approach to identify key determinants of carbon emissions in an evidence-based, data driven manner. The analysis highlights three primary drivers: access to clean cooking fuels in rural areas, access to clean cooking fuels in urban areas, and the percentage of population living in urban areas. These findings underscore the critical role of clean cooking technologies and urbanization patterns in shaping emission outcomes. In line with growing calls for evidence-based AI policy, ClimateAgents offers a modular and reflexive learning system that supports the generation of credible and actionable insights for policy. By integrating heterogeneous data modalities, including structured indicators, policy documents, and semantic reasoning, the framework contributes to adaptive policymaking infrastructures that can evolve with complex socio-technical challenges. This approach aims to support a shift from siloed modeling to reflexive, modular systems designed for dynamic, context-aware climate action.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.15352", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2511.15352", "abs": "https://arxiv.org/abs/2511.15352", "authors": ["Lennart Luettgau", "Vanessa Cheung", "Magda Dubois", "Keno Juechems", "Jessica Bergs", "Henry Davidson", "Bessie O'Dell", "Hannah Rose Kirk", "Max Rollwage", "Christopher Summerfield"], "title": "People readily follow personal advice from AI but it does not improve their well-being", "comment": null, "summary": "People increasingly seek personal advice from large language models (LLMs), yet whether humans follow their advice, and its consequences for their well-being, remains unknown. In a longitudinal randomised controlled trial with a representative UK sample (N = 2,302), 75% of participants who had a 20-minute discussion with GPT-4o about health, careers or relationships subsequently reported following its advice. Based on autograder evaluations of chat transcripts, LLM advice rarely violated safety best practice. When queried 2-3 weeks later, participants who had interacted with personalised AI (with access to detailed user information) followed its advice more often in the real world and reported higher well-being than those advised by non-personalised AI. However, while receiving personal advice from AI temporarily reduced well-being, no differential long-term effects compared to a control emerged. Our results suggest that humans readily follow LLM advice about personal issues but doing so shows no additional well-being benefit over casual conversations.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.15504", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2511.15504", "abs": "https://arxiv.org/abs/2511.15504", "authors": ["Amir Tahmasbi", "Milad Esrafilian", "Judson Wright", "Sooyeon Jeong", "Aniket Bera"], "title": "Game Master LLM: Task-Based Role-Playing for Natural Slang Learning", "comment": null, "summary": "Natural and idiomatic expressions are essential for fluent, everyday communication, yet many second-language learners struggle to acquire and spontaneously use casual slang despite strong formal proficiency. To address this gap, we designed and evaluated an LLM-powered, task-based role-playing game in which a GPT-4o-based Game Master guides learners through an immersive, three-phase spoken narrative. After selecting five unfamiliar slang phrases to practice, participants engage in open-ended dialogue with non-player characters; the Game Master naturally incorporates the target phrases in rich semantic contexts (implicit input enhancement) while a dedicated Practice Box provides real-time explicit tracking and encouragement. Post-session, learners receive multi-level formative feedback analyzing the entire interaction.\n  We evaluated the system in a between-subjects study with 14 international graduate students, randomly assigned to either the RPG condition or a control condition consisting of a traditional AI-led virtual classroom. Results from an immediate post-test show that the RPG group achieved greater gains in both comprehension of the target phrases and their accurate, contextual use in sentences. Quantitative analysis of in-activity word-usage frequency, combined with qualitative survey responses, further indicates that the game-based approach provided more practice opportunities and higher perceived engagement, resulting in a more natural learning experience. These findings highlight the potential of narrative-driven LLM interactions in vocabulary acquisition.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
