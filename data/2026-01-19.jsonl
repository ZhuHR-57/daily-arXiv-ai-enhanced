{"id": "2601.10824", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.10824", "abs": "https://arxiv.org/abs/2601.10824", "authors": ["Wanqi Zhang", "Jiangen He", "Marielle Santos"], "title": "Bridging Psychological Safety and Skill Guidance: An Adaptive Robotic Interview Coach", "comment": "4 pages, report", "summary": "Social robots hold promise for reducing job interview anxiety, yet designing agents that provide both psychological safety and instructional guidance remains challenging. Through a three-phase iterative design study (N = 8), we empirically mapped this tension. Phase I revealed a \"Safety-Guidance Gap\": while a Person-Centered Therapy (PCT) robot established safety (d = 3.27), users felt insufficiently coached. Phase II identified a \"Scaffolding Paradox\": rigid feedback caused cognitive overload, while delayed feedback lacked specificity. In Phase III, we resolved these tensions by developing an Agency-Driven Interaction Layer. Synthesizing our empirical findings, we propose the Adaptive Scaffolding Ecosystem, a conceptual framework that redefines robotic coaching not as a static script, but as a dynamic balance between affective support and instructional challenge, mediated by user agency."}
{"id": "2601.10956", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.10956", "abs": "https://arxiv.org/abs/2601.10956", "authors": ["Yao Lyu", "Tawanna Dillahunt", "Jiaying Liu", "John M. Carroll"], "title": "\"My Brother Is a School Principal, Earns About $80,000 Per Year... But When the Kids See Me, 'Wow, Uncle, You Have 1500 Followers on TikTok!'\": A Study of Blind TikTokers' Alternative Professional Development Experiences", "comment": "Accepted to CHI'26", "summary": "One's profession is an essential part of modern life. Traditionally, professional development has been criticized for excluding people with disabilities. People with visual impairments, for example, face disproportionately low employment rates, highlighting persistent gaps in professional opportunities. Recently, there has been growing research on social media platforms as spaces for more equitable career development approaches. In this paper, we present an interview study on the professional development experiences of 60 people with visual impairments on TikTok (also known as \"BlindTokers\"). We report BlindTokers' goals, strategies, and challenges, supported by detailed examples and in-depth analysis. Based on the findings, we identify that BlindTokers' practices reveal an alternative professional development approach that is more flexible, inclusive, personalized, and diversified than traditional models. Our study also extends professional development research by foregrounding emerging digital skills and proposing design implications to foster more equitable and inclusive professional opportunities."}
{"id": "2601.10957", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.10957", "abs": "https://arxiv.org/abs/2601.10957", "authors": ["Yao Lyu", "Jessica Shen", "Alina Faisal", "John M. Carroll"], "title": "\"I'm Constantly Getting Comments Like, 'Oh, You're Blind. You're Like the Only Woman That I Stand a Chance With.'\": A Study of Blind TikTokers' Intersectional Experiences of Gender and Sexuality", "comment": "Accepted to CHI'26", "summary": "Social media platforms are important venues for identity expression, and the Human-Computer Interaction community has been paying growing attention to how marginalized groups express their identities on these platforms. Joining the emerging literature on intersectional experiences, we study blind TikTokers (\"BlindTokers\") who are also women and/or LGBTQ+. Using interview data from \\rev{41} participants, we identify their intersectional experiences as mediated by TikTok's socio-technical affordances. We argue that BlindTokers' intersectional marginalization is infrastructural: TikTok's classification and moderation features interact with social norms in ways that push them aside and distort how they are treated on the platform. We use this infrastructure perspective to understand what these experiences are, how they were formed, and how they become harmful. We further recognize participants' infrastructuring work to address these problems. This study guides future social media design with accessible creator tools, inclusive identity options, and context-aware moderation developed in partnership with communities."}
{"id": "2601.11043", "categories": ["cs.HC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.11043", "abs": "https://arxiv.org/abs/2601.11043", "authors": ["Max Linnander", "Yon Visell"], "title": "Haptic Light-Emitting Diodes: Miniature, Luminous Tactile Actuators", "comment": null, "summary": "We present Haptic Light-Emitting Diodes (HLEDs), luminous thermopneumatic actuators that directly convert pulsed light into mechanical forces and displacements. Each device packages a miniature surface-mount LED in a gas-filled cavity that contains a low-inertia graphite photoabsorber. The cavity is sealed by an elastic membrane, which functions as a working diaphragm. Brief optical pulses heat the photoabsorber, which heats the gas. The resulting rapid pressure increases generate forces and displacements at the working diaphragm. Millimeter-scale HLEDs produce forces exceeding 0.4 N and displacements of 1 mm at low voltages, with 5 to 100 ms response times, making them attractive as actuators providing tactile feedback in human-machine interfaces. Perceptual testing revealed that the strength of tactile feedback increased linearly with optical power. HLEDs devices are mechanically simple and efficient to fabricate. Unusually, these actuators are also light-emitting, as a fraction of optical energy is transmitted through the membrane. These opto-mechanical actuators have many potential applications in tactile displays, human interface engineering, wearable computing, and other areas."}
{"id": "2601.10849", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.10849", "abs": "https://arxiv.org/abs/2601.10849", "authors": ["Cuong Le", "Symeon Chatzinotas", "Thang X. Vu"], "title": "Cooperative UAVs for Remote Data Collection under Limited Communications: An Asynchronous Multiagent Learning Framework", "comment": "Accepted to IEEE Transactions on Wireless Communications", "summary": "This paper addresses the joint optimization of trajectories and bandwidth allocation for multiple Unmanned Aerial Vehicles (UAVs) to enhance energy efficiency in the cooperative data collection problem. We focus on an important yet underestimated aspect of the system, where action synchronization across all UAVs is impossible. Since most existing learning-based solutions are not designed to learn in this asynchronous environment, we formulate the trajectory planning problem as a Decentralized Partially Observable Semi-Markov Decision Process and introduce an asynchronous multi-agent learning algorithm to learn UAVs' cooperative policies. Once the UAVs' trajectory policies are learned, the bandwidth allocation can be optimally solved based on local observations at each collection point. Comprehensive empirical results demonstrate the superiority of the proposed method over other learning-based and heuristic baselines in terms of both energy efficiency and mission completion time. Additionally, the learned policies exhibit robustness under varying environmental conditions."}
{"id": "2601.11049", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11049", "abs": "https://arxiv.org/abs/2601.11049", "authors": ["Stephen Pilli", "Vivek Nallur"], "title": "Predicting Biased Human Decision-Making with Large Language Models in Conversational Settings", "comment": "Accepted at ACM IUI 2026", "summary": "We examine whether large language models (LLMs) can predict biased decision-making in conversational settings, and whether their predictions capture not only human cognitive biases but also how those effects change under cognitive load. In a pre-registered study (N = 1,648), participants completed six classic decision-making tasks via a chatbot with dialogues of varying complexity. Participants exhibited two well-documented cognitive biases: the Framing Effect and the Status Quo Bias. Increased dialogue complexity resulted in participants reporting higher mental demand. This increase in cognitive load selectively, but significantly, increased the effect of the biases, demonstrating the load-bias interaction. We then evaluated whether LLMs (GPT-4, GPT-5, and open-source models) could predict individual decisions given demographic information and prior dialogue. While results were mixed across choice problems, LLM predictions that incorporated dialogue context were significantly more accurate in several key scenarios. Importantly, their predictions reproduced the same bias patterns and load-bias interactions observed in humans. Across all models tested, the GPT-4 family consistently aligned with human behavior, outperforming GPT-5 and open-source models in both predictive accuracy and fidelity to human-like bias patterns. These findings advance our understanding of LLMs as tools for simulating human decision-making and inform the design of conversational agents that adapt to user biases."}
{"id": "2601.11327", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.11327", "abs": "https://arxiv.org/abs/2601.11327", "authors": ["Agata Żywot", "Xinyi Chen", "Maarten de Rijke"], "title": "Can Small Agent Collaboration Beat a Single Big LLM?", "comment": null, "summary": "This report studies whether small, tool-augmented agents can match or outperform larger monolithic models on the GAIA benchmark. Using Qwen3 models (4B-32B) within an adapted Agentic-Reasoning framework, we isolate the effects of model scale, explicit thinking (no thinking, planner-only, or full), and tool use (search, code, mind-map). Tool augmentation provides the largest and most consistent gains. Using tools, 4B models can outperform 32B models without tool access on GAIA in our experimental setup. In contrast, explicit thinking is highly configuration- and difficulty-dependent: planner-only thinking can improve decomposition and constraint tracking, while unrestricted full thinking often degrades performance by destabilizing tool orchestration, leading to skipped verification steps, excessive tool calls, non-termination, and output-format drift."}
{"id": "2601.11060", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.11060", "abs": "https://arxiv.org/abs/2601.11060", "authors": ["Emelie Fälton", "Isabelle Strömstedt", "Mathis Brossier", "Andreas Göransson", "Konrad Schönborn", "Amy Loutfi", "Erik Sunden", "Mujtaba Fadhil Jawad", "Yadgar Suleiman", "Johanna Björklund", "Mario Romero", "Anders Ynnerman", "Lonni Besançon"], "title": "Children's Expectations, Engagement, and Evaluation of an LLM-enabled Spherical Visualization Platform in the Classroom", "comment": null, "summary": "We present our first stage results from deploying an LLM-augmented visualization software in a classroom setting to engage primary school children with earth-related datasets. Motivated by the growing interest in conversational AI as a means to support inquiry-based learning, we investigate children's expectations, engagement, and evaluation of a spoken LLM interface with a shared, immersive visualization system in a formal educational context. Our system integrates a speech-capable large language model with an interactive spherical display. It enables children to ask natural-language questions and receive coordinated verbal explanations and visual responses through the LLM-augmented visualization updating in real time based on spoken queries. We report on a classroom study with Swedish children aged 9-10, combining structured observation and small-group discussions to capture expectations prior to interaction, interaction patterns during facilitated sessions, and children's reflections on their encounter afterward. Our results provide empirical insights into children's initial encounters with an LLM-enabled visualization platform within a classroom setting and their expectations, interactions, and evaluations of the system. These findings inform the technology's potential for educational use and highlight important directions for future research."}
{"id": "2601.11072", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.11072", "abs": "https://arxiv.org/abs/2601.11072", "authors": ["Amber Kusters", "Pooja Prajod", "Pablo Cesar", "Abdallah El Ali"], "title": "More Human or More AI? Visualizing Human-AI Collaboration Disclosures in Journalistic News Production", "comment": "Accepted to ACM CHI 2026 - Preprint", "summary": "Within journalistic editorial processes, disclosing AI usage is currently limited to simplistic labels, which misses the nuance of how humans and AI collaborated on a news article. Through co-design sessions (N=10), we elicited 69 disclosure designs and implemented four prototypes that visually disclose human-AI collaboration in journalism. We then ran a within-subjects lab study (N=32) to examine how disclosure visualizations (Textual, Role-based Timeline, Task-based Timeline, Chatbot) and collaboration ratios (Primarily Human vs. Primarily AI) influenced visualization perceptions, gaze patterns, and post-experience responses. We found that textual disclosures were least effective in communicating human-AI collaboration, whereas Chatbot offered the most in-depth information. Furthermore, while role-based timelines amplified AI contribution in primarily human articles, task-based timeline shifted perceptions toward human involvement in primarily AI articles. We contribute Human-AI collaboration disclosure visualizations and their evaluation, and cautionary considerations on how visualizations can alter perceptions of AI's actual role during news article creation."}
{"id": "2601.11103", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.11103", "abs": "https://arxiv.org/abs/2601.11103", "authors": ["Minju Park", "Seunghyun Lee", "Juhwan Ma", "Dongwook Yoon"], "title": "AI Twin: Enhancing ESL Speaking Practice through AI Self-Clones of a Better Me", "comment": "CHI 2026", "summary": "Advances in AI have enabled ESL learners to practice speaking through conversational systems. However, most tools rely on explicit correction, which can interrupt the conversation and undermine confidence. Grounded in second language acquisition and motivational psychology, we present AI Twin, a system that rephrases learner utterances into more fluent English and delivers them in the learner's voice. Embodying a more confident and proficient version of the learner, AI Twin reinforces motivation through alignment with their aspirational Ideal L2 Self. Also, its use of implicit feedback through rephrasing preserves conversational flow and fosters an emotionally supportive environment. In a within-subject study with 20 adult ESL learners, we compared AI Twin with explicit correction and a non-personalized rephrasing agent. Results show that AI Twin elicited higher emotional engagement, with participants describing the experience as more motivating. These findings highlight the potential of self-representative AI for personalized, psychologically grounded support in ESL learning."}
{"id": "2601.11171", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.11171", "abs": "https://arxiv.org/abs/2601.11171", "authors": ["Jules Wulms", "Wouter Meulemans", "Bettina Speckmann"], "title": "Noisy Graph Patterns via Ordered Matrices", "comment": null, "summary": "The high-level structure of a graph is a crucial ingredient for the analysis and visualization of relational data. However, discovering the salient graph patterns that form this structure is notoriously difficult for two reasons. (1) Finding important patterns, such as cliques and bicliques, is computationally hard. (2) Real-world graphs contain noise, and therefore do not always exhibit patterns in their pure form. Defining meaningful noisy patterns and detecting them efficiently is a currently unsolved challenge. In this paper, we propose to use well-ordered matrices as a tool to both define and effectively detect noisy patterns. Specifically, we represent a graph as its adjacency matrix and optimally order it using Moran's $I$. Standard graph patterns (cliques, bicliques, and stars) now translate to rectangular submatrices. Using Moran's $I$, we define a permitted level of noise for such patterns. A combination of exact algorithms and heuristics allows us to efficiently decompose the matrix into noisy patterns. We also introduce a novel motif simplification that visualizes noisy patterns while explicitly encoding the level of noise. We showcase our techniques on several real-world data sets."}
{"id": "2601.11218", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.11218", "abs": "https://arxiv.org/abs/2601.11218", "authors": ["Sergio Mascetti", "Matteo Manzoni", "Filippo Corti", "Dragan Ahmetovic"], "title": "Game Accessibility Through Shared Control for People With Upper-Limb Impairments", "comment": "27 pages (excluding references and appendix)", "summary": "Accessing video games is challenging for people with upper-limb impairments, especially when multiple inputs are required in rapid succession. Human cooperation, where a copilot assists the main player, has been proposed as a solution, but relying on a human assistant poses limitations in terms of availability and co-location. An alternative solution is to use partial automation, where the player is assisted by a software agent. In this work, we present a study with 13 participants with upper-limb impairments, comparatively evaluating how participants collaborate with their copilot in human cooperation and partial automation. The experiment is supported by GamePals, a modular framework that enables both human cooperation and partial automation on existing third-party video games."}
{"id": "2601.11284", "categories": ["cs.HC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.11284", "abs": "https://arxiv.org/abs/2601.11284", "authors": ["Markus Bink", "Marten Risius", "Udo Kruschwitz", "David Elsweiler"], "title": "\"Can You Tell Me?\": Designing Copilots to Support Human Judgement in Online Information Seeking", "comment": "Pre-Print accepted at CHIIR 2026", "summary": "Generative AI (GenAI) tools are transforming information seeking, but their fluent, authoritative responses risk overreliance and discourage independent verification and reasoning. Rather than replacing the cognitive work of users, GenAI systems should be designed to support and scaffold it. Therefore, this paper introduces an LLM-based conversational copilot designed to scaffold information evaluation rather than provide answers and foster digital literacy skills. In a pre-registered, randomised controlled trial (N=261) examining three interface conditions including a chat-based copilot, our mixed-methods analysis reveals that users engaged deeply with the copilot, demonstrating metacognitive reflection. However, the copilot did not significantly improve answer correctness or search engagement, largely due to a \"time-on-chat vs. exploration\" trade-off and users' bias toward positive information. Qualitative findings reveal tension between the copilot's Socratic approach and users' desire for efficiency. These results highlight both the promise and pitfalls of pedagogical copilots, and we outline design pathways to reconcile literacy goals with efficiency demands."}
{"id": "2601.11287", "categories": ["cs.HC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.11287", "abs": "https://arxiv.org/abs/2601.11287", "authors": ["Markus Bink", "Marten Risius", "Udo Kruschwitz", "David Elsweiler"], "title": "Seek and You Shall Find: Design & Evaluation of a Context-Aware Interactive Search Companion", "comment": "Pre-Print accepted at CHIIR 2026", "summary": "Many users struggle with effective online search and critical evaluation, especially in high-stakes domains like health, while often overestimating their digital literacy. Thus, in this demo, we present an interactive search companion that seamlessly integrates expert search strategies into existing search engine result pages. Providing context-aware tips on clarifying information needs, improving query formulation, encouraging result exploration, and mitigating biases, our companion aims to foster reflective search behaviour while minimising cognitive burden. A user study demonstrates the companion's successful encouragement of more active and exploratory search, leading users to submit 75 % more queries and view roughly twice as many results, as well as performance gains in difficult tasks. This demo illustrates how lightweight, contextual guidance can enhance search literacy and empower users through micro-learning opportunities. While the vision involves real-time LLM adaptivity, this study utilises a controlled implementation to test the underlying intervention strategies."}
{"id": "2601.11328", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.11328", "abs": "https://arxiv.org/abs/2601.11328", "authors": ["Hanqing Zhou", "Yichuan Zhang", "Zihan Zhang", "Wei Zhang", "Chao Wang", "Pengcheng An"], "title": "ProjecTA: A Semi-Humanoid Robotic Teaching Assistant with In-Situ Projection for Guided Tours", "comment": "35 pages, 12 figures, 2 appendixes, 3 supplementary meterials, to appear in CHI'2026", "summary": "Robotic teaching assistants (TAs) often use body-mounted screens to deliver content. In nomadic, walk-and-talk learning, such as tours in makerspaces, these screens can distract learners from real-world objects, increasing extraneous cognitive load. HCI research lacks empirical comparisons of potential alternatives, such as robots with in-situ projection versus screen-based counterparts; little knowledge has been derived for designing such alternatives. We introduce ProjecTA, a semi-humanoid, gesture-capable TA that guides learners while projecting near-object overlays coordinated with speech and gestures. In a mixed-method study (N=24) in a university makerspace, ProjecTA significantly reduced extraneous load and outperformed its screen-based counterpart in perceived usability, usefulness of visual display, and cross-modal complementarity. Qualitative analyses revealed how ProjecTA's coordinated projections, gestures, and speech anchored explanations in place and time, enhancing understanding in ways a screen could not. We derive key design implications for future robotic TAs leveraging spatial projection to support mobile learning in physical environments."}
{"id": "2601.11365", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.11365", "abs": "https://arxiv.org/abs/2601.11365", "authors": ["Yi Li", "Kadek Ananta Satriadi", "Jiazhou Liu", "Anjali Khurana", "Zhiqing Wu", "Benjamin Tag", "Tim Dwyer"], "title": "Human Factors in Immersive Analytics", "comment": null, "summary": "It has been ten years since the term ''Immersive Analytics'' (IA) was coined and research interest in the topic remains strong. Researchers in this field have produced practical and conceptual knowledge concerning the use of emerging immersive spatial display and interaction technologies for sense-making tasks through a number of papers, surveys, and books. However, a lack of truly physically and psychologically ergonomic techniques, as well as standardized human-centric validation protocols for these, remains a significant barrier to wider acceptance of practical IA systems in ubiquitous applications. Building upon a series of workshops on immersive analytics at various conferences, this workshop aims to explore new approaches and establish standard practices for evaluating immersive analytics systems from a human factors perspective. We will gather immersive analytics researchers and practitioners to look closely at these human factors -- including cognitive and physical functions as well as behaviour and performance -- to see how they inform the design and deployment of immersive analytics techniques and applications and to inform future research."}
{"id": "2601.11387", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.11387", "abs": "https://arxiv.org/abs/2601.11387", "authors": ["Greta Warren", "Jingyi Sun", "Irina Shklovski", "Isabelle Augenstein"], "title": "Show me the evidence: Evaluating the role of evidence and natural language explanations in AI-supported fact-checking", "comment": null, "summary": "Although much research has focused on AI explanations to support decisions in complex information-seeking tasks such as fact-checking, the role of evidence is surprisingly under-researched. In our study, we systematically varied explanation type, AI prediction certainty, and correctness of AI system advice for non-expert participants, who evaluated the veracity of claims and AI system predictions. Participants were provided the option of easily inspecting the underlying evidence. We found that participants consistently relied on evidence to validate AI claims across all experimental conditions. When participants were presented with natural language explanations, evidence was used less frequently although they relied on it when these explanations seemed insufficient or flawed. Qualitative data suggests that participants attempted to infer evidence source reliability, despite source identities being deliberately omitted. Our results demonstrate that evidence is a key ingredient in how people evaluate the reliability of information presented by an AI system and, in combination with natural language explanations, offers valuable support for decision-making. Further research is urgently needed to understand how evidence ought to be presented and how people engage with it in practice."}
{"id": "2601.11417", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.11417", "abs": "https://arxiv.org/abs/2601.11417", "authors": ["Tyler Reinmund", "Lars Kunze", "Marina Jirotka"], "title": "Sociotechnical Challenges of Machine Learning in Healthcare and Social Welfare", "comment": "6 pages, short form, work-in-progress, conceptual paper", "summary": "Sociotechnical challenges of machine learning in healthcare and social welfare are mismatches between how a machine learning tool functions and the structure of care practices. While prior research has documented many such issues, existing accounts often attribute them either to designers' limited social understanding or to inherent technical constraints, offering limited support for systematic description and comparison across settings. In this paper, we present a framework for conceptualizing sociotechnical challenges of machine learning grounded in qualitative fieldwork, a review of longitudinal deployment studies, and co-design workshops with healthcare and social welfare practitioners. The framework comprises (1) a categorization of eleven sociotechnical challenges organized along an ML-enabled care pathway, and (2) a process-oriented account of the conditions through which these challenges emerge across design and use. By providing a parsimonious vocabulary and an explanatory lens focused on practice, this work supports more precise analysis of how machine learning tools function and malfunction within real-world care delivery."}
{"id": "2601.11459", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CY", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.11459", "abs": "https://arxiv.org/abs/2601.11459", "authors": ["Brian Keith"], "title": "Interactive Narrative Analytics: Bridging Computational Narrative Extraction and Human Sensemaking", "comment": "17 pages, 5 figures, published in IEEE Access as open access paper", "summary": "Information overload and misinformation create significant challenges in extracting meaningful narratives from large news collections. This paper defines the nascent field of Interactive Narrative Analytics (INA), which combines computational narrative extraction with interactive visual analytics to support sensemaking. INA approaches enable the interactive exploration of narrative structures through computational methods and visual interfaces that facilitate human interpretation. The field faces challenges in scalability, interactivity, knowledge integration, and evaluation standardization, yet offers promising opportunities across news analysis, intelligence, scientific literature exploration, and social media analysis. Through the combination of computational and human insight, INA addresses complex challenges in narrative sensemaking."}
