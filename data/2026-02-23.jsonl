{"id": "2602.17690", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2602.17690", "abs": "https://arxiv.org/abs/2602.17690", "authors": ["Ziyuan Liu", "Shizhao Sun", "Danqing Huang", "Yingdong Shi", "Meisheng Zhang", "Ji Li", "Jingsong Yu", "Jiang Bian"], "title": "DesignAsCode: Bridging Structural Editability and Visual Fidelity in Graphic Design Generation", "comment": null, "summary": "Graphic design generation demands a delicate balance between high visual fidelity and fine-grained structural editability. However, existing approaches typically bifurcate into either non-editable raster image synthesis or abstract layout generation devoid of visual content. Recent combinations of these two approaches attempt to bridge this gap but often suffer from rigid composition schemas and unresolvable visual dissonances (e.g., text-background conflicts) due to their inexpressive representation and open-loop nature. To address these challenges, we propose DesignAsCode, a novel framework that reimagines graphic design as a programmatic synthesis task using HTML/CSS. Specifically, we introduce a Plan-Implement-Reflect pipeline, incorporating a Semantic Planner to construct dynamic, variable-depth element hierarchies and a Visual-Aware Reflection mechanism that iteratively optimizes the code to rectify rendering artifacts. Extensive experiments demonstrate that DesignAsCode significantly outperforms state-of-the-art baselines in both structural validity and aesthetic quality. Furthermore, our code-native representation unlocks advanced capabilities, including automatic layout retargeting, complex document generation (e.g., resumes), and CSS-based animation."}
{"id": "2602.18319", "categories": ["cs.GR", "cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18319", "abs": "https://arxiv.org/abs/2602.18319", "authors": ["Nam Hee Kim", "Jingjing May Liu", "Jaakko Lehtinen", "Perttu Hämäläinen", "James F. O'Brien", "Xue Bin Peng"], "title": "Robo-Saber: Generating and Simulating Virtual Reality Players", "comment": "13 pages, 15 figures. Accepted to Eurographics 2026. Project page: https://robo-saber.github.io/", "summary": "We present the first motion generation system for playtesting virtual reality (VR) games. Our player model generates VR headset and handheld controller movements from in-game object arrangements, guided by style exemplars and aligned to maximize simulated gameplay score. We train on the large BOXRR-23 dataset and apply our framework on the popular VR game Beat Saber. The resulting model Robo-Saber produces skilled gameplay and captures diverse player behaviors, mirroring the skill levels and movement patterns specified by input style exemplars. Robo-Saber demonstrates promise in synthesizing rich gameplay data for predictive applications and enabling a physics-based whole-body VR playtesting agent."}
{"id": "2602.17905", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.17905", "abs": "https://arxiv.org/abs/2602.17905", "authors": ["Seyed Hossein Alavi", "Zining Wang", "Shruthi Chockkalingam", "Raymond T. Ng", "Vered Shwartz"], "title": "Games That Teach, Chats That Convince: Comparing Interactive and Static Formats for Persuasive Learning", "comment": null, "summary": "Interactive systems such as chatbots and games are increasingly used to persuade and educate on sustainability-related topics, yet it remains unclear how different delivery formats shape learning and persuasive outcomes when content is held constant. Grounding on identical arguments and factual content across conditions, we present a controlled user study comparing three modes of information delivery: static essays, conversational chatbots, and narrative text-based games. Across subjective measures, the chatbot condition consistently outperformed the other modes and increased perceived importance of the topic. However, perceived learning did not reliably align with objective outcomes: participants in the text-based game condition reported learning less than those reading essays, yet achieved higher scores on a delayed (24-hour) knowledge quiz. Additional exploratory analyses further suggest that common engagement proxies, such as verbosity and interaction length, are more closely related to subjective experience than to actual learning. These findings highlight a dissociation between how persuasive experiences feel and what participants retain, and point to important design trade-offs between interactivity, realism, and learning in persuasive systems and serious games."}
{"id": "2602.17738", "categories": ["cs.MA", "cs.IT"], "pdf": "https://arxiv.org/pdf/2602.17738", "abs": "https://arxiv.org/abs/2602.17738", "authors": ["Hyowoon Seo", "Joonho Seon", "Jin Young Kim", "Mehdi Bennis", "Wan Choi", "Dong In Kim"], "title": "Reasoning-Native Agentic Communication for 6G", "comment": "8 pages 4 figures", "summary": "Future 6G networks will interconnect not only devices, but autonomous machines that continuously sense, reason, and act. In such environments, communication can no longer be understood solely as delivering bits or even preserving semantic meaning. Even when two agents interpret the same information correctly, they may still behave inconsistently if their internal reasoning processes evolve differently. We refer to this emerging challenge as belief divergence. This article introduces reasoning native agentic communication, a new paradigm in which communication is explicitly designed to address belief divergence rather than merely transmitting representations. Instead of triggering transmissions based only on channel conditions or data relevance, the proposed framework activates communication according to predicted misalignment in agents internal belief states. We present a reasoning native architecture that augments the conventional communication stack with a coordination plane grounded in a shared knowledge structure and bounded belief modeling. Through enabling mechanisms and representative multi agent scenarios, we illustrate how such an approach can prevent coordination drift and maintain coherent behavior across heterogeneous systems. By reframing communication as a regulator of distributed reasoning, reasoning native agentic communication enables 6G networks to act as an active harmonizer of autonomous intelligence."}
{"id": "2602.17769", "categories": ["cs.MM", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2602.17769", "abs": "https://arxiv.org/abs/2602.17769", "authors": ["Rebecca Salganik", "Teng Tu", "Fei-Yueh Chen", "Xiaohao Liu", "Keifeng Lu", "Ethan Luvisia", "Zhiyao Duan", "Guillaume Salha-Galvan", "Anson Kahng", "Yunshan Ma", "Jian Kang"], "title": "MusicSem: A Semantically Rich Language--Audio Dataset of Natural Music Descriptions", "comment": null, "summary": "Music representation learning is central to music information retrieval and generation. While recent advances in multimodal learning have improved alignment between text and audio for tasks such as cross-modal music retrieval, text-to-music generation, and music-to-text generation, existing models often struggle to capture users' expressed intent in natural language descriptions of music. This observation suggests that the datasets used to train and evaluate these models do not fully reflect the broader and more natural forms of human discourse through which music is described. In this paper, we introduce MusicSem, a dataset of 32,493 language-audio pairs derived from organic music-related discussions on the social media platform Reddit. Compared to existing datasets, MusicSem captures a broader spectrum of musical semantics, reflecting how listeners naturally describe music in nuanced and human-centered ways. To structure these expressions, we propose a taxonomy of five semantic categories: descriptive, atmospheric, situational, metadata-related, and contextual. In addition to the construction, analysis, and release of MusicSem, we use the dataset to evaluate a wide range of multimodal models for retrieval and generation, highlighting the importance of modeling fine-grained semantics. Overall, MusicSem serves as a novel semantics-aware resource to support future research on human-aligned multimodal music representation learning."}
{"id": "2602.17668", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.17668", "abs": "https://arxiv.org/abs/2602.17668", "authors": ["Ömer Elri", "Serkan Savaş"], "title": "Visual Interface Workflow Management System Strengthening Data Integrity and Project Tracking in Complex Processes", "comment": "10th International Conference on Natural and Engineering Sciences", "summary": "Manual notes and scattered messaging applications used in managing business processes compromise data integrity and abstract project tracking. In this study, an integrated system that works simultaneously on web and mobile platforms has been developed to enable individual users and teams to manage their workflows with concrete data. The system architecture integrates MongoDB, which stores data in JSON format, Node.js Express.js on the server side, React.js on the web interface, and React Native technologies on the mobile side. The system interface is designed around visual dashboards that track the status of tasks (To Do-In Progress-Done). The urgency of tasks is distinguished by color-coded labels, and dynamic graphics (Dashboard) have been created for managers to monitor team performance. The usability of the system was tested with a heterogeneous group of 10 people consisting of engineers, engineering students, public employees, branch managers, and healthcare personnel. In analyses conducted using a 5-point Likert scale, the organizational efficiency provided by the system compared to traditional methods was rated 4.90, while the visual dashboards achieved a perfect score of 5.00 with zero variance. Additionally, the ease of interface use was rated 4.65, and overall user satisfaction was calculated as 4.60. The findings show that the developed system simplifies complex work processes and provides a traceable digital working environment for Small and Medium-sized Enterprises and project teams."}
{"id": "2602.17875", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17875", "abs": "https://arxiv.org/abs/2602.17875", "authors": ["Shreshth Rajan"], "title": "MultiVer: Zero-Shot Multi-Agent Vulnerability Detection", "comment": null, "summary": "We present MultiVer, a zero-shot multi-agent system for vulnerability detection that achieves state-of-the-art recall without fine-tuning. A four-agent ensemble (security, correctness, performance, style) with union voting achieves 82.7% recall on PyVul, exceeding fine-tuned GPT-3.5 (81.3%) by 1.4 percentage points -- the first zeroshot system to surpass fine-tuned performance on this benchmark. On SecurityEval, the same architecture achieves 91.7% detection rate, matching specialized systems. The recall improvement comes at a precision cost: 48.8% precision versus 63.9% for fine-tuned baselines, yielding 61.4% F1. Ablation experiments isolate component contributions: the multi-agent ensemble adds 17 percentage points recall over single-agent security analysis. These results demonstrate that for security applications where false negatives are costlier than false positives, zero-shot multi-agent ensembles can match and exceed fine-tuned models on the metric that matters most."}
{"id": "2602.17669", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.17669", "abs": "https://arxiv.org/abs/2602.17669", "authors": ["Jiangtao Gong", "Xiao Wen", "Fengyi Tao", "Xinqi Wang", "Xixi Yang", "Yangrong Tang"], "title": "Evaluating Text-based Conversational Agents for Mental Health: A Systematic Review of Metrics, Methods and Usage Contexts", "comment": "17 pages, 1 figures", "summary": "Text-based conversational agents (CAs) are increasingly used in mental health, yet evaluation practices remain fragmented. We conducted a PRISMA-guided systematic review (May-June 2024) across ACM Digital Library, Scopus, and PsycINFO. From 613 records, 132 studies were included, with dual-coder extraction achieving substantial agreement (Cohen's kappa = 0.77-0.92). We synthesized evaluation approaches across three dimensions: metrics, methods, and usage contexts. Metrics were classified into CA-centric attributes (e.g., reliability, safety, empathy) and user-centric outcomes (experience, knowledge, psychological state, health behavior). Methods included automated analyses, standardized psychometric scales, and qualitative inquiry. Temporal designs ranged from momentary to follow-up assessments. Findings show reliance on Western-developed scales, limited cultural adaptation, predominance of small and short-term samples, and weak links between automated performance metrics and user well-being. We argue for methodological triangulation, temporal rigor, and equity in measurement. This review offers a structured foundation for reliable, safe, and user-centered evaluation of mental health CAs."}
{"id": "2602.18026", "categories": ["cs.MA", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18026", "abs": "https://arxiv.org/abs/2602.18026", "authors": ["Shan Yang"], "title": "Mean-Field Reinforcement Learning without Synchrony", "comment": "21 pages, 5 figures, 1 algorithm", "summary": "Mean-field reinforcement learning (MF-RL) scales multi-agent RL to large populations by reducing each agent's dependence on others to a single summary statistic -- the mean action. However, this reduction requires every agent to act at every time step; when some agents are idle, the mean action is simply undefined. Addressing asynchrony therefore requires a different summary statistic -- one that remains defined regardless of which agents act. The population distribution $μ\\in Δ(\\mathcal{O})$ -- the fraction of agents at each observation -- satisfies this requirement: its dimension is independent of $N$, and under exchangeability it fully determines each agent's reward and transition. Existing MF-RL theory, however, is built on the mean action and does not extend to $μ$. We therefore construct the Temporal Mean Field (TMF) framework around the population distribution $μ$ from scratch, covering the full spectrum from fully synchronous to purely sequential decision-making within a single theory. We prove existence and uniqueness of TMF equilibria, establish an $O(1/\\sqrt{N})$ finite-population approximation bound that holds regardless of how many agents act per step, and prove convergence of a policy gradient algorithm (TMF-PG) to the unique equilibrium. Experiments on a resource selection game and a dynamic queueing game confirm that TMF-PG achieves near-identical performance whether one agent or all $N$ act per step, with approximation error decaying at the predicted $O(1/\\sqrt{N})$ rate."}
{"id": "2602.17670", "categories": ["cs.HC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2602.17670", "abs": "https://arxiv.org/abs/2602.17670", "authors": ["Zak Datson"], "title": "The Dark Side of Dark Mode -- User behaviour rebound effects and consequences for digital energy consumption", "comment": "3 pages (2 + references), 3 figures, 1 table. To be included in the proceedings of the 1st International Workshop on Low Carbon Computing (LOCO) 2024, December 3, 2024, Glasgow/Online", "summary": "User devices are the largest contributor to media related global emissions. For web content, dark mode has been widely recommended as an energy-saving measure for certain display types. However, the energy savings achieved by dark mode may be undermined by user behaviour. This pilot study investigates the unintended consequences of dark mode adoption, revealing a rebound effect wherein users may increase display brightness when interacting with dark-themed web pages. This behaviour may negate the potential energy savings that dark mode offers. Our findings suggest that the energy efficiency benefits of dark mode are not as straightforward as commonly believed for display energy, and the interplay between content colourscheme and user behaviour must be carefully considered in sustainability guidelines and interventions."}
{"id": "2602.17671", "categories": ["cs.HC", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.17671", "abs": "https://arxiv.org/abs/2602.17671", "authors": ["Abdulhadi Shoufan", "Ahmad-Azmi-Abdelhamid Esmaeil"], "title": "AI Hallucination from Students' Perspective: A Thematic Analysis", "comment": null, "summary": "As students increasingly rely on large language models, hallucinations pose a growing threat to learning. To mitigate this, AI literacy must expand beyond prompt engineering to address how students should detect and respond to LLM hallucinations. To support this, we need to understand how students experience hallucinations, how they detect them, and why they believe they occur. To investigate these questions, we asked university students three open-ended questions about their experiences with AI hallucinations, their detection strategies, and their mental models of why hallucinations occur. Sixty-three students responded to the survey. Thematic analysis of their responses revealed that reported hallucination issues primarily relate to incorrect or fabricated citations, false information, overconfident but misleading responses, poor adherence to prompts, persistence in incorrect answers, and sycophancy. To detect hallucinations, students rely either on intuitive judgment or on active verification strategies, such as cross-checking with external sources or re-prompting the model. Students' explanations for why hallucinations occur reflected several mental models, including notable misconceptions. Many described AI as a research engine that fabricates information when it cannot locate an answer in its \"database.\" Others attributed hallucinations to issues with training data, inadequate prompting, or the model's inability to understand or verify information. These findings illuminate vulnerabilities in AI-supported learning and highlight the need for explicit instruction in verification protocols, accurate mental models of generative AI, and awareness of behaviors such as sycophancy and confident delivery that obscure inaccuracy. The study contributes empirical evidence for integrating hallucination awareness and mitigation into AI literacy curricula."}
{"id": "2602.17672", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.17672", "abs": "https://arxiv.org/abs/2602.17672", "authors": ["Vijay Prakash", "Majed Almansoori", "Donghan Hu", "Rahul Chatterjee", "Danny Yuxing Huang"], "title": "Assessing LLM Response Quality in the Context of Technology-Facilitated Abuse", "comment": null, "summary": "Technology-facilitated abuse (TFA) is a pervasive form of intimate partner violence (IPV) that leverages digital tools to control, surveil, or harm survivors. While tech clinics are one of the reliable sources of support for TFA survivors, they face limitations due to staffing constraints and logistical barriers. As a result, many survivors turn to online resources for assistance. With the growing accessibility and popularity of large language models (LLMs), and increasing interest from IPV organizations, survivors may begin to consult LLM-based chatbots before seeking help from tech clinics.\n  In this work, we present the first expert-led manual evaluation of four LLMs - two widely used general-purpose non-reasoning models and two domain-specific models designed for IPV contexts - focused on their effectiveness in responding to TFA-related questions. Using real-world questions collected from literature and online forums, we assess the quality of zero-shot single-turn LLM responses generated with a survivor safety-centered prompt on criteria tailored to the TFA domain. Additionally, we conducted a user study to evaluate the perceived actionability of these responses from the perspective of individuals who have experienced TFA.\n  Our findings, grounded in both expert assessment and user feedback, provide insights into the current capabilities and limitations of LLMs in the TFA context and may inform the design, development, and fine-tuning of future models for this domain. We conclude with concrete recommendations to improve LLM performance for survivor support."}
{"id": "2602.17673", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.17673", "abs": "https://arxiv.org/abs/2602.17673", "authors": ["Fatiha Tali"], "title": "Digital self-Efficacy as a foundation for a generative AI usage framework in faculty's professional practices", "comment": "in French language", "summary": "This research explores the role of digital self-efficacy in the appropriation of generative artificial intelligence (GAI) by higher education faculty. Drawing on Bandura's sociocognitive theory and Flichy's concept of usage framework, our study examines the relationships between levels of digital self-efficacy and GAI usage profiles. A survey of 265 faculty members identified three user profiles (Engaged, Reflective Reserved, Critical Resisters) and validated a three-dimensional digital self-efficacy scale. Results reveal a significant association between self-efficacy profiles and GAI appropriation patterns. Based on these findings, we propose a differentiated usage framework integrating four sociotechnical configurations, appropriation trajectories adapted to self-efficacy profiles, and personalized institutional support mechanisms."}
{"id": "2602.17674", "categories": ["cs.HC", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.17674", "abs": "https://arxiv.org/abs/2602.17674", "authors": ["Bijean Ghafouri", "Emilio Ferrara"], "title": "Lost Before Translation: Social Information Transmission and Survival in AI-AI Communication", "comment": null, "summary": "When AI systems summarize and relay information, they inevitably transform it. But how? We introduce an experimental paradigm based on the telephone game to study what happens when AI talks to AI. Across five studies tracking content through AI transmission chains, we find three consistent patterns. The first is convergence, where texts differing in certainty, emotional intensity, and perspectival balance collapse toward a shared default of moderate confidence, muted affect, and analytical structure. The second is selective survival, where narrative anchors persist while the texture of evidence, hedges, quotes, and attributions is stripped away. The third is competitive filtering, where strong arguments survive while weaker but valid considerations disappear when multiple viewpoints coexist. In downstream experiments, human participants rated AI-transmitted content as more credible and polished. Importantly, however, humans also showed degraded factual recall, reduced perception of balance, and diminished emotional resonance. We show that the properties that make AI-mediated content appear authoritative may systematically erode the cognitive and affective diversity on which informed judgment depends."}
{"id": "2602.17850", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.17850", "abs": "https://arxiv.org/abs/2602.17850", "authors": ["Erik Derner", "Dalibor Kučera", "Aditya Gulati", "Ayoub Bagheri", "Nuria Oliver"], "title": "Mind the Style: Impact of Communication Style on Human-Chatbot Interaction", "comment": null, "summary": "Conversational agents increasingly mediate everyday digital interactions, yet the effects of their communication style on user experience and task success remain unclear. Addressing this gap, we describe the results of a between-subject user study where participants interact with one of two versions of a chatbot called NAVI which assists users in an interactive map-based 2D navigation task. The two chatbot versions differ only in communication style: one is friendly and supportive, while the other is direct and task-focused. Our results show that the friendly style increases subjective satisfaction and significantly improves task completion rates among female participants only, while no baseline differences between female and male participants were observed in a control condition without the chatbot. Furthermore, we find little evidence of users mimicking the chatbot's style, suggesting limited linguistic accommodation. These findings highlight the importance of user- and task-sensitive conversational agents and support that communication style personalization can meaningfully enhance interaction quality and performance."}
{"id": "2602.17864", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.17864", "abs": "https://arxiv.org/abs/2602.17864", "authors": ["Anirban Mukhopadhyay", "Kevin Salubre", "Hifza Javed", "Shashank Mehrotra", "Kumar Akash"], "title": "Exploring The Impact Of Proactive Generative AI Agent Roles In Time-Sensitive Collaborative Problem-Solving Tasks", "comment": "Published in Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems (CHI'26)", "summary": "Collaborative problem-solving under time pressure is common but difficult, as teams must generate ideas quickly, coordinate actions, and track progress. Generative AI offers new opportunities to assist, but we know little about how proactive agents affect the dynamics of real-time, co-located teamwork. We studied two forms of proactive support in digital escape rooms: a facilitator agent that offered summaries and group structures, and a peer agent that proposed ideas and answered queries. In a within-subjects study with 24 participants, we compared group performance and processes across three conditions: no AI, peer, and facilitator. Results show that the peer agent occasionally enhanced problem-solving by offering timely hints and memory support; however, it also disrupted flow, increased workload, and created over-reliance. In comparison, the facilitator agent provided light scaffolding but had a limited impact on outcomes. We provide design considerations for proactive generative AI agents based on our findings."}
{"id": "2602.17891", "categories": ["cs.HC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.17891", "abs": "https://arxiv.org/abs/2602.17891", "authors": ["Suyeon Hwang", "Minkyu Kweon", "Jeongmin Rhee", "Soohyun Lee", "Seokhyeon Park", "Seokweon Jung", "Hyeon Jeon", "Jinwook Seo"], "title": "HookLens: Visual Analytics for Understanding React Hooks Structures", "comment": "IEEE PacificVis 2026, conference track", "summary": "Maintaining and refactoring React web applications is challenging, as React code often becomes complex due to its core API called Hooks. For example, Hooks often lead developers to create complex dependencies among components, making code behavior unpredictable and reducing maintainability, i.e., anti-patterns. To address this challenge, we present HookLens, an interactive visual analytics system that helps developers understand howHooks define dependencies and data flows between components. Informed by an iterative design process with experienced React developers, HookLens supports users to efficiently understand the structure and dependencies between components and to identify anti-patterns. A quantitative user study with 12 React developers demonstrates that HookLens significantly improves participants' accuracy in detecting anti-patterns compared to conventional code editors. Moreover, a comparative study with state-of-the-art LLM-based coding assistants confirms that these improvements even surpass the capabilities of such coding assistants on the same task."}
{"id": "2602.17905", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.17905", "abs": "https://arxiv.org/abs/2602.17905", "authors": ["Seyed Hossein Alavi", "Zining Wang", "Shruthi Chockkalingam", "Raymond T. Ng", "Vered Shwartz"], "title": "Games That Teach, Chats That Convince: Comparing Interactive and Static Formats for Persuasive Learning", "comment": null, "summary": "Interactive systems such as chatbots and games are increasingly used to persuade and educate on sustainability-related topics, yet it remains unclear how different delivery formats shape learning and persuasive outcomes when content is held constant. Grounding on identical arguments and factual content across conditions, we present a controlled user study comparing three modes of information delivery: static essays, conversational chatbots, and narrative text-based games. Across subjective measures, the chatbot condition consistently outperformed the other modes and increased perceived importance of the topic. However, perceived learning did not reliably align with objective outcomes: participants in the text-based game condition reported learning less than those reading essays, yet achieved higher scores on a delayed (24-hour) knowledge quiz. Additional exploratory analyses further suggest that common engagement proxies, such as verbosity and interaction length, are more closely related to subjective experience than to actual learning. These findings highlight a dissociation between how persuasive experiences feel and what participants retain, and point to important design trade-offs between interactivity, realism, and learning in persuasive systems and serious games."}
{"id": "2602.17925", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.17925", "abs": "https://arxiv.org/abs/2602.17925", "authors": ["Neda Barbazi", "Ji Youn Shin", "Gurumurthy Hiremath", "Carlye Anne Lauff"], "title": "Growing With the Condition: Co-Designing Pediatric Technologies that Adapt Across Developmental Stages", "comment": null, "summary": "Children with chronic conditions face evolving challenges in daily activities, peer relationships, and clinical care. Younger children often rely on parental support, while older ones seek independence. Prior studies on chronic conditions explored proxy-based, family-centered, and playful approaches to support children's health, but most technologies treat children as a homogeneous group rather than adapting to their developmental differences. To address this gap, we conducted four co-design workshops with 69 children with congenital heart disease (CHD) at a medically supported camp, spanning elementary, middle, and high school groups. Our analysis reveals distinct coping strategies: elementary children relied on comfort objects and reassurance, middle schoolers used mediated communication and selective disclosure, and high schoolers emphasized agency and direct engagement with peers and providers. Through child-centered participatory design, we contribute empirical insights into how children's management of chronic conditions evolves and propose design implications for pediatric health technologies that adapt across developmental trajectories."}
{"id": "2602.17939", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.17939", "abs": "https://arxiv.org/abs/2602.17939", "authors": ["Daniel Killough", "Tiger F. Ji", "Kexin Zhang", "Yaxin Hu", "Yu Huang", "Ruofei Du", "Yuhang Zhao"], "title": "How Well Can 3D Accessibility Guidelines Support XR Development? An Interview Study with XR Practitioners in Industry", "comment": "ACM CHI 2026 Preprint. Short paper of Killough et al. \"XR for All\" 2024: arXiv:2412.16321", "summary": "While accessibility (a11y) guidelines exist for 3D games and virtual worlds, their applicability to extended reality (XR)'s unique interaction paradigms (e.g., spatial tracking, kinesthetic interactions) remains unexplored. XR practitioners need practical guidance to successfully implement a11y guidelines under real-world constraints. We present the first evaluation of existing 3D a11y guidelines applied to XR development through semi-structured interviews with 25 XR practitioners across diverse organization contexts. We assessed 20 commonly-agreed a11y guidelines from six major resources across visual, motor, cognitive, speech, and hearing domains, comparing practitioners' development practices against guideline applicability to XR. Our investigation reveals that guidelines can be highly effective when designed as transformation catalysts rather than compliance checklists, but fundamental mismatches exist between existing 3D guidelines and XR requirements, creating both implementation barriers and design gaps. This work provides foundational insights towards developing a11y guidelines and support tools that address XR's distinct characteristics."}
{"id": "2602.17961", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.17961", "abs": "https://arxiv.org/abs/2602.17961", "authors": ["Kaori Ikematsu", "Kunihiro Kato"], "title": "DuoTouch: Passive Two-Footprint Attachments Using Binary Sequences to Extend Touch Interaction", "comment": "16 pages, 10 figures. Accepted to the 2026 CHI Conference on Human Factors in Computing Systems (CHI '26)", "summary": "DuoTouch is a passive attachment for capacitive touch panels that adds tangible input while minimizing content occlusion and loss of input area. It uses two contact footprints and two traces to encode motion as binary sequences and runs on unmodified devices through standard touch APIs. We present two configurations with paired decoders: an aligned configuration that maps fixed-length codes to discrete commands and a phase-shifted configuration that estimates direction and distance from relative timing. To characterize the system's reliability, we derive a sampling-limited bound that links actuation speed, internal trace width, and device touch sampling rate. Through technical evaluations on a smartphone and a touchpad, we report performance metrics that describe the relationship between these parameters and decoding accuracy. Finally, we demonstrate the versatility of DuoTouch by embedding the mechanism into various form factors, including a hand strap, a phone ring holder, and touchpad add-ons."}
{"id": "2602.17999", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17999", "abs": "https://arxiv.org/abs/2602.17999", "authors": ["Lorena Amanda Quincoso Lugones", "Christopher Kverne", "Nityam Sharadkumar Bhimani", "Ana Carolina Oliveira", "Agoritsa Polyzou", "Christine Lisetti", "Janki Bhimani"], "title": "Aurora: Neuro-Symbolic AI Driven Advising Agent", "comment": "Accepted to 41st ACM/SIGAPP Symposium On Applied Computing. 8 Pages, 3 Figures", "summary": "Academic advising in higher education is under severe strain, with advisor-to-student ratios commonly exceeding 300:1. These structural bottlenecks limit timely access to guidance, increase the risk of delayed graduation, and contribute to inequities in student support. We introduce Aurora, a modular neuro-symbolic advising agent that unifies retrieval-augmented generation (RAG), symbolic reasoning, and normalized curricular databases to deliver policy-compliant, verifiable recommendations at scale. Aurora integrates three components: (i) a Boyce-Codd Normal Form (BCNF) catalog schema for consistent program rules, (ii) a Prolog engine for prerequisite and credit enforcement, and (iii) an instruction-tuned large language model for natural-language explanations of its recommendations. To assess performance, we design a structured evaluation suite spanning common and edge-case advising scenarios, including short-term scheduling, long-term roadmapping, skill-aligned pathways, and out-of-scope requests. Across this diverse set, Aurora improves semantic alignment with expert-crafted answers from 0.68 (Raw LLM baseline) to 0.93 (+36%), achieves perfect precision and recall in nearly half of in-scope cases, and consistently produces correct fallbacks for unanswerable prompts. On commodity hardware, Aurora delivers sub-second mean latency (0.71s across 20 queries), approximately 83X faster than a Raw LLM baseline (59.2s). By combining symbolic rigor with neural fluency, Aurora advances a paradigm for accurate, explainable, and scalable AI-driven advising."}
{"id": "2602.18352", "categories": ["cs.HC", "cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.18352", "abs": "https://arxiv.org/abs/2602.18352", "authors": ["Tung T. Ngo", "Dai Nguyen Van", "Anh-Minh Nguyen", "Phuong-Anh Do", "Anh Nguyen-Quoc"], "title": "Qualitative Coding Analysis through Open-Source Large Language Models: A User Study and Design Recommendations", "comment": "6 pages. Accepted as Poster to CHI'26", "summary": "Qualitative data analysis is labor-intensive, yet the privacy risks associated with commercial Large Language Models (LLMs) often preclude their use in sensitive research. To address this, we introduce ChatQDA, an on-device framework powered by open-source LLMs designed for privacy-preserving open coding. Our mixed-methods user study reveals that while participants rated the system highly for usability and perceived efficiency, they exhibited \"conditional trust\", valuing the tool for surface-level extraction while questioning its interpretive nuance and consistency. Furthermore, despite the technical security of local deployment, participants reported epistemic uncertainty regarding data protection, suggesting that invisible security measures are insufficient to foster trust. We conclude with design recommendations for local-first analysis tools that prioritize verifiable privacy and methodological rigor."}
{"id": "2602.18372", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18372", "abs": "https://arxiv.org/abs/2602.18372", "authors": ["Alexandra Neagu", "Marcus Messer", "Peter Johnson", "Rhodri Nelson"], "title": "\"How Do I ...?\": Procedural Questions Predominate Student-LLM Chatbot Conversations", "comment": "14 pages, 2 figures", "summary": "Providing scaffolding through educational chatbots built on Large Language Models (LLM) has potential risks and benefits that remain an open area of research. When students navigate impasses, they ask for help by formulating impasse-driven questions. Within interactions with LLM chatbots, such questions shape the user prompts and drive the pedagogical effectiveness of the chatbot's response. This paper focuses on such student questions from two datasets of distinct learning contexts: formative self-study, and summative assessed coursework. We analysed 6,113 messages from both learning contexts, using 11 different LLMs and three human raters to classify student questions using four existing schemas. On the feasibility of using LLMs as raters, results showed moderate-to-good inter-rater reliability, with higher consistency than human raters. The data showed that 'procedural' questions predominated in both learning contexts, but more so when students prepare for summative assessment. These results provide a basis on which to use LLMs for classification of student questions. However, we identify clear limitations in both the ability to classify with schemas and the value of doing so: schemas are limited and thus struggle to accommodate the semantic richness of composite prompts, offering only partial understanding the wider risks and benefits of chatbot integration. In the future, we recommend an analysis approach that captures the nuanced, multi-turn nature of conversation, for example, by applying methods from conversation analysis in discursive psychology."}
{"id": "2602.18415", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.18415", "abs": "https://arxiv.org/abs/2602.18415", "authors": ["Cathy Mengying Fang", "Sheer Karny", "Chayapatr Archiwaranguprok", "Yasith Samaradivakara", "Pat Pataranutaporn", "Pattie Maes"], "title": "AI-Wrapped: Participatory, Privacy-Preserving Measurement of Longitudinal LLM Use In-the-Wild", "comment": null, "summary": "Alignment research on large language models (LLMs) increasingly depends on understanding how these systems are used in everyday contexts. yet naturalistic interaction data is difficult to access due to privacy constraints and platform control. We present AI-Wrapped, a prototype workflow for collecting naturalistic LLM usage data while providing participants with an immediate ``wrapped''-style report on their usage statistics, top topics, and safety-relevant behavioral patterns. We report findings from an initial deployment with 82 U.S.-based adults across 48,495 conversations from their 2025 histories. Participants used LLMs for both instrumental and reflective purposes, including creative work, professional tasks, and emotional or existential themes. Some usage patterns were consistent with potential over-reliance or perfectionistic refinement, while heavier users showed comparatively more reflective exchanges than primarily transactional ones. Methodologically, even with zero data retention and PII removal, participants may remain hesitant to share chat data due to perceived privacy and judgment risks, underscoring the importance of trust, agency, and transparent design when building measurement infrastructure for alignment research."}
{"id": "2602.18319", "categories": ["cs.GR", "cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18319", "abs": "https://arxiv.org/abs/2602.18319", "authors": ["Nam Hee Kim", "Jingjing May Liu", "Jaakko Lehtinen", "Perttu Hämäläinen", "James F. O'Brien", "Xue Bin Peng"], "title": "Robo-Saber: Generating and Simulating Virtual Reality Players", "comment": "13 pages, 15 figures. Accepted to Eurographics 2026. Project page: https://robo-saber.github.io/", "summary": "We present the first motion generation system for playtesting virtual reality (VR) games. Our player model generates VR headset and handheld controller movements from in-game object arrangements, guided by style exemplars and aligned to maximize simulated gameplay score. We train on the large BOXRR-23 dataset and apply our framework on the popular VR game Beat Saber. The resulting model Robo-Saber produces skilled gameplay and captures diverse player behaviors, mirroring the skill levels and movement patterns specified by input style exemplars. Robo-Saber demonstrates promise in synthesizing rich gameplay data for predictive applications and enabling a physics-based whole-body VR playtesting agent."}
