{"id": "2601.09295", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.09295", "abs": "https://arxiv.org/abs/2601.09295", "authors": ["Handi Chen", "Running Zhao", "Xiuzhe Wu", "Edith C. H. Ngai"], "title": "MACRO-LLM: LLM-Empowered Multi-Agent Collaborative Reasoning under Spatiotemporal Partial Observability", "comment": null, "summary": "Large Language Model (LLM) agents deployed in complex real-world scenarios typically operate as spatially distributed entities. However, this physical dispersion constrains agents to limited local perception and finite temporal horizons. We characterize this bottleneck as spatiotemporal partial observability. Given such fragmented awareness, distributed agents struggle to coordinate efficiently. To bridge this gap, we introduce MACRO-LLM, LLM-empowered multi-agent collaborative reasoning under spatiotemporal partial observability. The architecture addresses spatiotemporal constraints via three modules: (1) the CoProposer mitigates temporal uncertainty by verifying candidate actions via predictive rollouts; (2) the Negotiator overcomes spatial myopia by resolving conflicts through mean-field statistical aggregation; and (3) the Introspector ensures continuous adaptation by analyzing historical experience to refine strategies via semantic gradient descent. Extensive evaluations on two complex long-horizon tasks, cooperative adaptive cruise control and pandemic control, demonstrate that our framework effectively mitigates spatiotemporal partial observability through spatial and temporal strategies, enabling robust coordination."}
{"id": "2601.09434", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.09434", "abs": "https://arxiv.org/abs/2601.09434", "authors": ["Di Zhao", "Longhui Ma", "Siwei Wang", "Miao Wang", "Yi Kong"], "title": "SC-MAS: Constructing Cost-Efficient Multi-Agent Systems with Edge-Level Heterogeneous Collaboration", "comment": null, "summary": "Large Language Model (LLM)-based Multi-Agent Systems (MAS) enhance complex problem solving through multi-agent collaboration, but often incur substantially higher costs than single-agent systems. Recent MAS routing methods aim to balance performance and overhead by dynamically selecting agent roles and language models. However, these approaches typically rely on a homogeneous collaboration mode, where all agents follow the same interaction pattern, limiting collaboration flexibility across different roles. Motivated by Social Capital Theory, which emphasizes that different roles benefit from distinct forms of collaboration, we propose SC-MAS, a framework for constructing heterogeneous and cost-efficient multi-agent systems. SC-MAS models MAS as directed graphs, where edges explicitly represent pairwise collaboration strategies, allowing different agent pairs to interact through tailored communication patterns. Given an input query, a unified controller progressively constructs an executable MAS by selecting task-relevant agent roles, assigning edge-level collaboration strategies, and allocating appropriate LLM backbones to individual agents. Experiments on multiple benchmarks demonstrate the effectiveness of SC-MAS. In particular, SC-MAS improves accuracy by 3.35% on MMLU while reducing inference cost by 15.38%, and achieves a 3.53% accuracy gain with a 12.13% cost reduction on MBPP. These results validate the feasibility of SC-MAS and highlight the effectiveness of heterogeneous collaboration in multi-agent systems."}
{"id": "2601.09291", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2601.09291", "abs": "https://arxiv.org/abs/2601.09291", "authors": ["Sooyeun Yang", "Cheyul Im", "Jee Won Lee", "Jongseong Brad Choi"], "title": "TIDI-GS: Floater Suppression in 3D Gaussian Splatting for Enhanced Indoor Scene Fidelity", "comment": null, "summary": "3D Gaussian Splatting (3DGS) is a technique to create high-quality, real-time 3D scenes from images. This method often produces visual artifacts known as floaters--nearly transparent, disconnected elements that drift in space away from the actual surface. This geometric inaccuracy undermines the reliability of these models for practical applications, which is critical. To address this issue, we introduce TIDI-GS, a new training framework designed to eliminate these floaters. A key benefit of our approach is that it functions as a lightweight plugin for the standard 3DGS pipeline, requiring no major architectural changes and adding minimal overhead to the training process. The core of our method is a floater pruning algorithm--TIDI--that identifies and removes floaters based on several criteria: their consistency across multiple viewpoints, their spatial relationship to other elements, and an importance score learned during training. The framework includes a mechanism to preserve fine details, ensuring that important high-frequency elements are not mistakenly removed. This targeted cleanup is supported by a monocular depth-based loss function that helps improve the overall geometric structure of the scene. Our experiments demonstrate that TIDI-GS improves both the perceptual quality and geometric integrity of reconstructions, transforming them into robust digital assets, suitable for high-fidelity applications."}
{"id": "2601.09037", "categories": ["cs.ET", "cond-mat.dis-nn", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.09037", "abs": "https://arxiv.org/abs/2601.09037", "authors": ["M Mahmudul Hasan Sajeeb", "Corentin Delacour", "Kevin Callahan-Coray", "Sanjay Seshan", "Tathagata Srimani", "Kerem Y. Camsari"], "title": "Probabilistic Computers for MIMO Detection: From Sparsification to 2D Parallel Tempering", "comment": null, "summary": "Probabilistic computers built from p-bits offer a promising path for combinatorial optimization, but the dense connectivity required by real-world problems scales poorly in hardware. Here, we address this through graph sparsification with auxiliary copy variables and demonstrate a fully on-chip parallel tempering solver on an FPGA. Targeting MIMO detection, a dense, NP-hard problem central to wireless communications, we fit 15 temperature replicas of a 128-node sparsified system (1,920 p-bits) entirely on-chip and achieve bit error rates significantly below conventional linear detectors. We report complete end-to-end solution times of 4.7 ms per instance, with all loading, sampling, readout, and verification overheads included. ASIC projections in 7 nm technology indicate about 90 MHz operation with less than 200 mW power dissipation, suggesting that massive parallelism across multiple chips could approach the throughput demands of next-generation wireless systems. However, sparsification introduces sensitivity to the copy-constraint strength. Employing Two-Dimensional Parallel Tempering (2D-PT), which exchanges replicas across both temperature and constraint dimensions, we demonstrate over 10X faster convergence without manual parameter tuning. These results establish an on-chip p-bit architecture and a scalable algorithmic framework for dense combinatorial optimization."}
{"id": "2601.09417", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2601.09417", "abs": "https://arxiv.org/abs/2601.09417", "authors": ["Qibiao Li", "Yuxuan Wang", "Youcheng Cai", "Huangsheng Du", "Ligang Liu"], "title": "Variable Basis Mapping for Real-Time Volumetric Visualization", "comment": "11 pages. Under review", "summary": "Real-time visualization of large-scale volumetric data remains challenging, as direct volume rendering and voxel-based methods suffer from prohibitively high computational cost. We propose Variable Basis Mapping (VBM), a framework that transforms volumetric fields into 3D Gaussian Splatting (3DGS) representations through wavelet-domain analysis. First, we precompute a compact Wavelet-to-Gaussian Transition Bank that provides optimal Gaussian surrogates for canonical wavelet atoms across multiple scales. Second, we perform analytical Gaussian construction that maps discrete wavelet coefficients directly to 3DGS parameters using a closed-form, mathematically principled rule. Finally, a lightweight image-space fine-tuning stage further refines the representation to improve rendering fidelity. Experiments on diverse datasets demonstrate that VBM significantly accelerates convergence and enhances rendering quality, enabling real-time volumetric visualization."}
{"id": "2601.08954", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.08954", "abs": "https://arxiv.org/abs/2601.08954", "authors": ["Sumin Hong", "Jewoong Moon", "Taeyeon Eom", "Juno Hwang", "Jibeom Seo"], "title": "Leveraging learning analytics to enhance immersive teacher simulations: Challenges and opportunities", "comment": "30 pages, 10 figures. This chapter examines immersive teacher simulations and multimodal analytics. Project website: https://teachergenai.github.io/", "summary": "This chapter examines how data analytics can be leveraged to enhance immersive teacher simulations, situating this inquiry within the broader learning sciences discourse on embodied cognition, data-informed feedback, and teacher professional learning. It explores both conceptual foundations and empirical cases to illustrate how analytics serve as mediational tools that connect immersive experiences with reflective teaching practice. The chapter unfolds in multiple sections: (1) The Innovation Journey: An Overview of Immersive Teacher Simulations outlines the evolution from traditional simulations to XR-based environments, highlighting the need for professional decision-making under realistic constraints. (2) Innovation in Existing Research and Practice situates teacher analytics within the trajectory from descriptive observation to multimodal and predictive modeling. (3) Study Approach and Design details how multimodal data-discourse, behavior, and gaze-from the TeacherGen@i simulation were collected and organized to reveal cognitive distribution of pedagogical discourse and interaction patterns. (4) Findings present the cognitive distribution of preservice teachers' pedagogical discourse and the sequential interaction patterns that emerge in exchange, illustrating how multimodal analytics make pedagogical reasoning processes visible within immersive simulations. (5) Understanding Innovative Practices in Teacher Education examines teaching analytics to enhance immersive teacher simulation based on the findings of the study. (6) Key Takeaways of the Innovation Journey identifies research challenges and design implications for scalable, analytics-enhanced teacher education. Together, these sections position immersive teacher simulations as a pivotal testbed for aligning learning analytics, professional learning, and next-generation immersive learning environment design."}
{"id": "2601.09033", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.09033", "abs": "https://arxiv.org/abs/2601.09033", "authors": ["Yejoon Song", "Bandi Kim", "Yeju Kwon", "Sung Park"], "title": "Exploring the Effects of Generative AI Assistance on Writing Self-Efficacy", "comment": null, "summary": "Generative AI (GenAI) is increasingly used in academic writing, yet its effects on students' writing self-efficacy remain contingent on how assistance is configured. This pilot study investigates how ideation-level, sentence-level, full-process, and no AI support differentially shape undergraduate writers' self-efficacy using a 2 by 2 experimental design with Korean undergraduates completing argumentative writing tasks. Results indicate that AI assistance does not uniformly enhance self-efficacy full AI support produced high but stable self-efficacy alongside signs of reduced ownership, sentence-level AI support led to consistent self-efficacy decline, and ideation-level AI support was associated with both high self-efficacy and positive longitudinal change. These findings suggest that the locus of AI intervention, rather than the amount of assistance, is critical in fostering writing self-efficacy while preserving learner agency."}
{"id": "2601.09045", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.09045", "abs": "https://arxiv.org/abs/2601.09045", "authors": ["Hasan Tarik Akbaba", "Efe Bozkir", "Anna Puhl", "Süleyman Özdel", "Enkelejda Kasneci"], "title": "Exploring Organizational Readiness and Ecosystem Coordination for Industrial XR", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Extended Reality (XR) offers transformative potential for industrial support, training, and maintenance; yet, widespread adoption lags despite demonstrated occupational value and hardware maturity. Organizations successfully implement XR in isolated pilots, yet struggle to scale these into sustained operational deployment, a phenomenon we characterize as the ``Pilot Trap.'' This study examines this phenomenon through a qualitative ecosystem analysis of 17 expert interviews across technology providers, solution integrators, and industrial adopters. We identify a ``Great Inversion'' in adoption barriers: critical constraints have shifted from technological maturity to organizational readiness (e.g., change management, key performance indicator alignment, and political resistance). While hardware ergonomics and usability remain relevant, our findings indicate that systemic misalignments between stakeholder incentives are the primary cause of friction preventing enterprise integration. We conclude that successful industrial XR adoption requires a shift from technology-centric piloting to a problem-first, organizational transformation approach, necessitating explicit ecosystem-level coordination."}
{"id": "2601.09048", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.09048", "abs": "https://arxiv.org/abs/2601.09048", "authors": ["Yuki Kobayashi", "Koichi Toida"], "title": "Immersive XR That Moves People: How XR Advertising Transforms Comprehension, Empathy, and Behavioural Intention", "comment": "8 pages, 3 figures. Experimental study comparing immersive XR and non-immersive 2D advertising", "summary": "Extended Reality (XR) affords an enhanced sense of bodily presence that supports experiential modes of comprehension and affective engagement which exceed the possibilities of conventional information delivery. Nevertheless, the psychological processes engendered by XR, and the manner in which these processes inform subsequent behavioural intentions, remain only partially delineated. The present study addresses this issue within an applied context by comparing non-immersive 2D viewing advertising with immersive XR experiential advertising. We examined whether XR strengthens internal responses to a product, specifically perceived comprehension and empathy, and whether these responses, in turn, influence the behavioural outcome of purchase intention. A repeated-measures two-way ANOVA demonstrated a significant main effect of advertising modality, with XR yielding higher ratings on all evaluative dimensions. Mediation analysis further indicated that the elevation in purchase intention was mediated by empathy, whereas no significant mediating effect was observed for comprehension within the scope of this study. These findings suggest that immersive XR experiences augment empathic engagement with virtual products, and that this enhanced empathy plays a pivotal role in shaping subsequent behavioural intentions."}
{"id": "2601.09053", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.09053", "abs": "https://arxiv.org/abs/2601.09053", "authors": ["Haiyi Li", "Yutong Li", "Yiheng Chi", "Alison Deslandes", "Mathew Leonardi", "Shay Freger", "Yuan Zhang", "Jodie Avery", "M. Louise Hull", "Hsiang-Ting Chen"], "title": "Evaluating local large language models for structured extraction from endometriosis-specific transvaginal ultrasound reports", "comment": null, "summary": "In this study, we evaluate a locally-deployed large-language model (LLM) to convert unstructured endometriosis transvaginal ultrasound (eTVUS) scan reports into structured data for imaging informatics workflows. Across 49 eTVUS reports, we compared three LLMs (7B/8B and a 20B-parameter model) against expert human extraction. The 20B model achieved a mean accuracy of 86.02%, substantially outperforming smaller models and confirming the importance of scale in handling complex clinical text. Crucially, we identified a highly complementary error profile: the LLM excelled at syntactic consistency (e.g., date/numeric formatting) where humans faltered, while human experts provided superior semantic and contextual interpretation. We also found that the LLM's semantic errors were fundamental limitations that could not be mitigated by simple prompt engineering. These findings strongly support a human-in-the-loop (HITL) workflow in which the on-premise LLM serves as a collaborative tool, not a full replacement. It automates routine structuring and flags potential human errors, enabling imaging specialists to focus on high-level semantic validation. We discuss implications for structured reporting and interactive AI systems in clinical practice."}
{"id": "2601.09150", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.09150", "abs": "https://arxiv.org/abs/2601.09150", "authors": ["Jianwen Sun", "Yukang Feng", "Kaining Ying", "Chuanhao Li", "Zizhen Li", "Fanrui Zhang", "Jiaxin Ai", "Yifan Chang", "Yu Dai", "Yifei Huang", "Kaipeng Zhang"], "title": "World Craft: Agentic Framework to Create Visualizable Worlds via Text", "comment": null, "summary": "Large Language Models (LLMs) motivate generative agent simulation (e.g., AI Town) to create a ``dynamic world'', holding immense value across entertainment and research. However, for non-experts, especially those without programming skills, it isn't easy to customize a visualizable environment by themselves. In this paper, we introduce World Craft, an agentic world creation framework to create an executable and visualizable AI Town via user textual descriptions. It consists of two main modules, World Scaffold and World Guild. World Scaffold is a structured and concise standardization to develop interactive game scenes, serving as an efficient scaffolding for LLMs to customize an executable AI Town-like environment. World Guild is a multi-agent framework to progressively analyze users' intents from rough descriptions, and synthesizes required structured contents (\\eg environment layout and assets) for World Scaffold . Moreover, we construct a high-quality error-correction dataset via reverse engineering to enhance spatial knowledge and improve the stability and controllability of layout generation, while reporting multi-dimensional evaluation metrics for further analysis. Extensive experiments demonstrate that our framework significantly outperforms existing commercial code agents (Cursor and Antigravity) and LLMs (Qwen3 and Gemini-3-Pro). in scene construction and narrative intent conveyance, providing a scalable solution for the democratization of environment creation."}
{"id": "2601.09208", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09208", "abs": "https://arxiv.org/abs/2601.09208", "authors": ["Miki Ueno"], "title": "Mikasa: A Character-Driven Emotional AI Companion Inspired by Japanese Oshi Culture", "comment": "11 pages, 1 figure", "summary": "Recent progress in large language models and multimodal interaction has made it possible to develop AI companions that can have fluent and emotionally expressive conversations. However, many of these systems have problems keeping users satisfied and engaged over long periods. This paper argues that these problems do not come mainly from weak models, but from poor character design and unclear definitions of the user-AI relationship. I present Mikasa, an emotional AI companion inspired by Japanese Oshi culture-specifically its emphasis on long-term, non-exclusive commitment to a stable character-as a case study of character-driven companion design. Mikasa does not work as a general-purpose assistant or a chatbot that changes roles. Instead, Mikasa is designed as a coherent character with a stable personality and a clearly defined relationship as a partner. This relationship does not force exclusivity or obligation. Rather, it works as a reference point that stabilizes interaction norms and reduces the work users must do to keep redefining the relationship. Through an exploratory evaluation, I see that users describe their preferences using surface-level qualities such as conversational naturalness, but they also value relationship control and imaginative engagement in ways they do not state directly. These results suggest that character coherence and relationship definition work as latent structural elements that shape how good the interaction feels, without users recognizing them as main features. The contribution of this work is to show that character design is a functional part of AI companion systems, not just decoration. Mikasa is one example based on a specific cultural context, but the design principles-commitment to a consistent personality and clear relationship definition-can be used for many emotionally grounded AI companions."}
{"id": "2601.09610", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.09610", "abs": "https://arxiv.org/abs/2601.09610", "authors": ["Marie Luisa Fiedler", "Christian Merz", "Jonathan Tschanter", "Carolin Wienrich", "Marc Erich Latoschik"], "title": "Technological Advances in Two Generations of Consumer-Grade VR Systems: Effects on User Experience and Task Performance", "comment": "12 pages, 4 figures, 7 tables", "summary": "Integrated VR (IVR) systems consist of a head-mounted display (HMD) and body-tracking capabilities. They enable users to translate their physical movements into corresponding avatar movements in real-time, allowing them to perceive their avatars via the displays. Consumer-grade IVR systems have been available for 10 years, significantly fostering VR research worldwide. However, the effects of even apparently significant technological advances of IVR systems on user experience and the overall validity of prior embodiment research using such systems often remain unclear. We ran a user-centered study comparing two comparable IVR generations: a nearly 10-year-old hardware (HTC Vive, 6-point tracking) and a modern counterpart (HTC Vive Pro 2, 6-point tracking). To ensure ecological validity, we evaluated the systems in their commercially available, as-is configurations. In a 2x5 mixed design, participants completed five tasks covering different use cases on either the old or new system. We assessed presence, sense of embodiment, appearance and behavior plausibility, workload, task performance, and gathered qualitative feedback. Results showed no significant system differences, with only small effect sizes. Bayesian analysis further supported the null hypothesis, suggesting that the investigated generational hardware improvements offer limited benefits for user experience and task performance. For the 10-year generational step examined here, excluding potential technological progress in the necessary software components, this supports the validity of conclusions from prior work and underscores the applicability of older configurations for research in embodied VR."}
{"id": "2601.09620", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09620", "abs": "https://arxiv.org/abs/2601.09620", "authors": ["Pooja Prajod", "Hannes Cools", "Thomas Röggla", "Karthikeya Puttur Venkatraj", "Amber Kusters", "Alia ElKattan", "Pablo Cesar", "Abdallah El Ali"], "title": "Full Disclosure, Less Trust? How the Level of Detail about AI Use in News Writing Affects Readers' Trust", "comment": null, "summary": "As artificial intelligence (AI) is increasingly integrated into news production, calls for transparency about the use of AI have gained considerable traction. Recent studies suggest that AI disclosures can lead to a ``transparency dilemma'', where disclosure reduces readers' trust. However, little is known about how the \\textit{level of detail} in AI disclosures influences trust and contributes to this dilemma within the news context. In this 3$\\times$2$\\times$2 mixed factorial study with 40 participants, we investigate how three levels of AI disclosures (none, one-line, detailed) across two types of news (politics and lifestyle) and two levels of AI involvement (low and high) affect news readers' trust. We measured trust using the News Media Trust questionnaire, along with two decision behaviors: source-checking and subscription decisions. Questionnaire responses and subscription rates showed a decline in trust only for detailed AI disclosures, whereas source-checking behavior increased for both one-line and detailed disclosures, with the effect being more pronounced for detailed disclosures. Insights from semi-structured interviews suggest that source-checking behavior was primarily driven by interest in the topic, followed by trust, whereas trust was the main factor influencing subscription decisions. Around two-thirds of participants expressed a preference for detailed disclosures, while most participants who preferred one-line indicated a need for detail-on-demand disclosure formats. Our findings show that not all AI disclosures lead to a transparency dilemma, but instead reflect a trade-off between readers' desire for more transparency and their trust in AI-assisted news content."}
{"id": "2601.09632", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.09632", "abs": "https://arxiv.org/abs/2601.09632", "authors": ["Rose Connolly", "Victor Zordan", "Rachel McDonnell"], "title": "Perceptually-Guided Adjusted Teleporting: Perceptual Thresholds for Teleport Displacements in Virtual Environments", "comment": "9 pages. to be published in IEEE VR conference proceedings 2026", "summary": "Teleportation is one of the most common locomotion techniques in virtual reality, yet its perceptual properties remain underexplored. While redirected walking research has shown that users' movements can be subtly manipulated without detection, similar imperceptible adjustments for teleportation have not been systematically investigated. This study examines the thresholds at which teleportation displacements become noticeable to users. We conducted a repeated-measures experiment in which participants' selected teleport destinations were altered in both direction (forwards, backwards) and at different ranges (small, large). Detection thresholds for these positional adjustments were estimated using a psychophysical staircase method with a two-alternative forced choice (2AFC) task. Results show that teleport destinations can be shifted without detection, with larger tolerances for backward adjustments and across longer teleport ranges. These findings establish baseline perceptual limits for redirected teleportation and highlight its potential as a design technique. Applications include supporting interpersonal distance management in social VR, guiding players toward objectives in games, and assisting novice users with navigation. By identifying the limits of imperceptible teleportation adjustments, this work extends redirection principles beyond walking to teleportation and opens new opportunities for adaptive and socially aware VR locomotion systems."}
